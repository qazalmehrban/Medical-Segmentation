{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UNET.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/qazalmehrban/Medical-Segmentation/blob/develop/UNET.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJeS1cyb1W6E"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "from skimage.transform import resize\n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "import os \n",
        "\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfR6URnCEmgZ"
      },
      "source": [
        "heaight, width = 200,200"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOg-Ae_7YeAq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a299b814-686d-4f8a-ab27-f18c7389fb9a"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-zMk0jg6Dla"
      },
      "source": [
        "samples = '/content/drive/MyDrive/samples/'\n",
        "patients = next(os.walk(samples))[2]\n",
        "labels = '/content/drive/MyDrive/segmentation/'\n",
        "segmentations =next(os.walk(labels))[2]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGOkj2tK9UNI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6138e86e-dc17-4eda-fca6-a96de768773a"
      },
      "source": [
        "segmentations.sort()\n",
        "segmentations"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Case00_segmentation.nii.gz',\n",
              " 'Case01_segmentation.nii.gz',\n",
              " 'Case02_segmentation.nii.gz',\n",
              " 'Case03_segmentation.nii.gz',\n",
              " 'Case04_segmentation.nii.gz',\n",
              " 'Case05_segmentation.nii.gz',\n",
              " 'Case06_segmentation.nii.gz',\n",
              " 'Case07_segmentation.nii.gz',\n",
              " 'Case08_segmentation.nii.gz',\n",
              " 'Case09_segmentation.nii.gz',\n",
              " 'Case10_segmentation.nii.gz',\n",
              " 'Case11_segmentation.nii.gz',\n",
              " 'Case12_segmentation.nii.gz',\n",
              " 'Case13_segmentation.nii.gz',\n",
              " 'Case14_segmentation.nii.gz',\n",
              " 'Case15_segmentation.nii.gz',\n",
              " 'Case16_segmentation.nii.gz',\n",
              " 'Case17_segmentation.nii.gz',\n",
              " 'Case18_segmentation.nii.gz',\n",
              " 'Case19_segmentation.nii.gz',\n",
              " 'Case20_segmentation.nii.gz',\n",
              " 'Case21_segmentation.nii.gz',\n",
              " 'Case22_segmentation.nii.gz',\n",
              " 'Case23_segmentation.nii.gz',\n",
              " 'Case24_segmentation.nii.gz',\n",
              " 'Case25_segmentation.nii.gz',\n",
              " 'Case26_segmentation.nii.gz',\n",
              " 'Case27_segmentation.nii.gz',\n",
              " 'Case28_segmentation.nii.gz',\n",
              " 'Case29_segmentation.nii.gz',\n",
              " 'Case30_segmentation.nii.gz',\n",
              " 'Case31_segmentation.nii.gz',\n",
              " 'Case32_segmentation.nii.gz',\n",
              " 'Case33_segmentation.nii.gz',\n",
              " 'Case34_segmentation.nii.gz',\n",
              " 'Case35_segmentation.nii.gz',\n",
              " 'Case36_segmentation.nii.gz',\n",
              " 'Case37_segmentation.nii.gz',\n",
              " 'Case38_segmentation.nii.gz',\n",
              " 'Case39_segmentation.nii.gz',\n",
              " 'Case40_segmentation.nii.gz',\n",
              " 'Case41_segmentation.nii.gz',\n",
              " 'Case42_segmentation.nii.gz',\n",
              " 'Case43_segmentation.nii.gz',\n",
              " 'Case44_segmentation.nii.gz',\n",
              " 'Case45_segmentation.nii.gz',\n",
              " 'Case46_segmentation.nii.gz',\n",
              " 'Case47_segmentation.nii.gz',\n",
              " 'Case48_segmentation.nii.gz',\n",
              " 'Case49_segmentation.nii.gz',\n",
              " 'Case50_segmentation.nii.gz',\n",
              " 'Case51_segmentation.nii.gz',\n",
              " 'Case52_segmentation.nii.gz']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKTBy8mh9vru",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b06c9b8-43aa-4d0a-fc83-fc0e9cf06256"
      },
      "source": [
        "patients.sort()\n",
        "patients"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Case00.nii.gz',\n",
              " 'Case01.nii.gz',\n",
              " 'Case02.nii.gz',\n",
              " 'Case03.nii.gz',\n",
              " 'Case04.nii.gz',\n",
              " 'Case05.nii.gz',\n",
              " 'Case06.nii.gz',\n",
              " 'Case07.nii.gz',\n",
              " 'Case08.nii.gz',\n",
              " 'Case09.nii.gz',\n",
              " 'Case10.nii.gz',\n",
              " 'Case11.nii.gz',\n",
              " 'Case12.nii.gz',\n",
              " 'Case13.nii.gz',\n",
              " 'Case14.nii.gz',\n",
              " 'Case15.nii.gz',\n",
              " 'Case16.nii.gz',\n",
              " 'Case17.nii.gz',\n",
              " 'Case18.nii.gz',\n",
              " 'Case19.nii.gz',\n",
              " 'Case20.nii.gz',\n",
              " 'Case21.nii.gz',\n",
              " 'Case22.nii.gz',\n",
              " 'Case23.nii.gz',\n",
              " 'Case24.nii.gz',\n",
              " 'Case25.nii.gz',\n",
              " 'Case26.nii.gz',\n",
              " 'Case27.nii.gz',\n",
              " 'Case28.nii.gz',\n",
              " 'Case29.nii.gz',\n",
              " 'Case30.nii.gz',\n",
              " 'Case31.nii.gz',\n",
              " 'Case32.nii.gz',\n",
              " 'Case33.nii.gz',\n",
              " 'Case34.nii.gz',\n",
              " 'Case35.nii.gz',\n",
              " 'Case36.nii.gz',\n",
              " 'Case37.nii.gz',\n",
              " 'Case38.nii.gz',\n",
              " 'Case39.nii.gz',\n",
              " 'Case40.nii.gz',\n",
              " 'Case41.nii.gz',\n",
              " 'Case42.nii.gz',\n",
              " 'Case43.nii.gz',\n",
              " 'Case44.nii.gz',\n",
              " 'Case45.nii.gz',\n",
              " 'Case46.nii.gz',\n",
              " 'Case47.nii.gz',\n",
              " 'Case48.nii.gz',\n",
              " 'Case49.nii.gz',\n",
              " 'Case50.nii.gz',\n",
              " 'Case51.nii.gz',\n",
              " 'Case52.nii.gz']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_747rKG6Dlb"
      },
      "source": [
        "def make_box(mask):\n",
        "    box = []\n",
        "    obj_ids = np.unique(mask)\n",
        "    if mask.dtype == bool:\n",
        "        if len(np.unique(mask))==2:\n",
        "            \n",
        "            y_min = np.nonzero(mask)[0].min()\n",
        "            y_max = np.nonzero(mask)[0].max()\n",
        "            x_min = np.nonzero(mask)[1].min()\n",
        "            x_max = np.nonzero(mask)[1].max()\n",
        "            box.append([x_min, y_min, x_max, y_max])\n",
        "    else :\n",
        "        \n",
        "        for i in  obj_ids[1:]:\n",
        "            y_min = np.nonzero(mask==i)[0].min()\n",
        "            y_max = np.nonzero(mask==i)[0].max()\n",
        "            x_min = np.nonzero(mask==i)[1].min()\n",
        "            x_max = np.nonzero(mask==i)[1].max()\n",
        "            box.append([x_min, y_min, x_max, y_max])\n",
        "    return dict(zip([f\"label{int(i)}\" for i in obj_ids[1:]],box))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-C7UIR_6Ur2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "fe4898df-00c6-408d-b046-3ed8bfceb4b9"
      },
      "source": [
        "Masks = nib.load((labels + segmentations[0]))    \n",
        "Masks = np.array(Masks.dataobj)\n",
        "print('shape', Masks.shape)\n",
        "slices =0\n",
        "Masks_2d = Masks[:,:,slices]\n",
        "print(f'labels_slice_{slices}', np.unique(Masks_2d))\n",
        "print('bounding_box', make_box(Masks_2d))\n",
        "plt.imshow(Masks_2d)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shape (384, 384, 15)\n",
            "labels_slice_0 [0. 2.]\n",
            "bounding_box {'label2': [163, 185, 190, 216]}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f0cf6cd14e0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2SuytaH6Uzg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "7a646e8c-289e-40a6-c3e6-709b9b19f5f6"
      },
      "source": [
        "Masks = nib.load((labels + segmentations[0]))    \n",
        "Masks = np.array(Masks.dataobj)\n",
        "print('shape', Masks.shape)\n",
        "slices =1\n",
        "Masks_2d = Masks[:,:,slices]\n",
        "print(f'labels_slice_{slices}', np.unique(Masks_2d))\n",
        "print('bounding_box', make_box(Masks_2d))\n",
        "plt.imshow(Masks_2d)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shape (384, 384, 15)\n",
            "labels_slice_1 [0. 1. 2.]\n",
            "bounding_box {'label1': [169, 179, 203, 217], 'label2': [164, 186, 189, 209]}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f0cf679dd30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsC0PO1G6U2J",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "be8570b9-9257-476b-9f68-ef369bc1aab9"
      },
      "source": [
        "Masks = nib.load((labels + segmentations[1]))    \n",
        "Masks = np.array(Masks.dataobj)\n",
        "print('shape', Masks.shape)\n",
        "slices =0\n",
        "Masks_2d = Masks[:,:,slices]\n",
        "print(f'labels_slice_{slices}', np.unique(Masks_2d))\n",
        "print('bounding_box', make_box(Masks_2d))\n",
        "plt.imshow(Masks_2d)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shape (512, 512, 29)\n",
            "labels_slice_0 [0]\n",
            "bounding_box {}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f0cf6787438>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQYAAAD8CAYAAACVSwr3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAANUElEQVR4nO3cb8yddX3H8fdn/Yf/C8iapm1WiE0MDzYgDWIwi4O4YGcsD9BgzGhMkyYbSzAucWVLtpjsgeyBKMmia4ZZXVRgqKEhbAwLZtkDgSr/YcgtgdAGbVRAFyMD/e7B+dUd+ivep73PdZ9zZ+9XcnJ+/859fU9799Prus51nVQVkjTut2ZdgKT5YzBI6hgMkjoGg6SOwSCpYzBI6gwSDEkuS/JkkoUke4fYhqThZNrXMSRZBXwPeB9wGLgf+EhVPT7VDUkazBB7DBcCC1X1dFX9D3ATsHOA7UgayOoBfuYm4Lmx/mHgXb/pBWuzrk7jTQOUIumYn/HCj6rqrEnWDhEME0myB9gDcBpv5F25dFalSP8vfLNufXbStUMcShwBtoz1N7ex16iqfVW1vaq2r2HdAGVIOlVDBMP9wLYkZydZC1wJHBhgO5IGMvVDiap6NcmfAXcCq4AvVtVj096OpOEMco6hqu4A7hjiZ0sanlc+SuoYDJI6BoOkjsEgqWMwSOoYDJI6BoOkjsEgqWMwSOoYDJI6BoOkjsEgqWMwSOoYDJI6BoOkjsEgqWMwSOoYDJI6BoOkjsEgqWMwSOoYDJI6BoOkjsEgqWMwSOoYDJI6BoOkjsEgqWMwSOoYDJI6BoOkjsEgqWMwSOoYDJI6iwZDki8mOZrk0bGxM5LcleSp9nx6G0+SG5IsJHk4yQVDFi9pGJPsMfwTcNlxY3uBg1W1DTjY+gDvB7a1xx7g89MpU9JyWjQYquo/gJ8cN7wT2N/a+4HLx8a/VCPfBtYn2TitYiUtj1M9x7Chqp5v7R8AG1p7E/Dc2LrDbayTZE+SQ0kOvcLLp1iGpCEs+eRjVRVQp/C6fVW1vaq2r2HdUsuQNEWnGgw/PHaI0J6PtvEjwJaxdZvbmKQV5FSD4QCwq7V3AbeNjV/VPp24CHhp7JBD0gqxerEFSb4KvBd4e5LDwN8AnwZuSbIbeBb4cFt+B7ADWAB+DnxsgJolDWzRYKiqj7zO1KUnWFvA1UstStJseeWjpI7BIKljMEjqGAySOgaDpI7BIKljMEjqGAySOgaDpI7BIKljMEjqGAySOgaDpI7BIKljMEjqGAySOgaDpI7BIKljMEjqGAySOgaDpI7BIKljMEjqGAySOgaDpI7BIKljMEjqGAySOgaDpI7BIKljMEjqGAySOgaDpM6iwZBkS5J7kjye5LEk17TxM5LcleSp9nx6G0+SG5IsJHk4yQVDvwlJ0zXJHsOrwJ9X1bnARcDVSc4F9gIHq2obcLD1Ad4PbGuPPcDnp161pEEtGgxV9XxVfbe1fwY8AWwCdgL727L9wOWtvRP4Uo18G1ifZOPUK5c0mJM6x5BkK3A+cC+woaqeb1M/ADa09ibgubGXHW5jklaIiYMhyZuBrwEfr6qfjs9VVQF1MhtOsifJoSSHXuHlk3mppIFNFAxJ1jAKhS9X1dfb8A+PHSK056Nt/AiwZezlm9vYa1TVvqraXlXb17DuVOuXNIBJPpUIcCPwRFV9ZmzqALCrtXcBt42NX9U+nbgIeGnskEPSCrB6gjUXA38MPJLkwTb2l8CngVuS7AaeBT7c5u4AdgALwM+Bj021YkmDWzQYquo/gbzO9KUnWF/A1UusS9IMeeWjpI7BIKljMEjqGAySOgaDpI7BIKljMEjqGAySOgaDpI7BIKljMEjqGAySOgaDpI7BIKljMEjqGAySOgaDpI7BIKljMEjqGAySOgaDpI7BIKljMEjqGAySOgaDpI7BIKljMEjqGAySOgaDpI7BIKljMEjqGAySOgaDpI7BIKmzaDAkOS3JfUkeSvJYkk+18bOT3JtkIcnNSda28XWtv9Dmtw77FiRN2yR7DC8Dl1TV7wHnAZcluQi4Dri+qt4BvADsbut3Ay+08evbOkkryKLBUCP/3bpr2qOAS4Bb2/h+4PLW3tn6tPlLk2RqFUsa3ETnGJKsSvIgcBS4C/g+8GJVvdqWHAY2tfYm4DmANv8ScOYJfuaeJIeSHHqFl5f2LiRN1UTBUFW/rKrzgM3AhcA7l7rhqtpXVduravsa1i31x0maopP6VKKqXgTuAd4NrE+yuk1tBo609hFgC0Cbfxvw46lUK2lZTPKpxFlJ1rf2G4D3AU8wCogr2rJdwG2tfaD1afN3V1VNs2hJw1q9+BI2AvuTrGIUJLdU1e1JHgduSvK3wAPAjW39jcA/J1kAfgJcOUDdkga0aDBU1cPA+ScYf5rR+Ybjx38BfGgq1UmaCa98lNQxGCR1DAZJHYNBUsdgkNQxGCR1DAZJHYNBUsdgkNQxGCR1DAZJHYNBUsdgkNQxGCR1DAZJHYNBUsdgkNQxGCR1DAZJHYNBUsdgkNQxGCR1DAZJHYNBUsdgkNQxGCR1DAZJHYNBUsdgkNQxGCR1DAZJHYNBUsdgkNSZOBiSrEryQJLbW//sJPcmWUhyc5K1bXxd6y+0+a3DlC5pKCezx3AN8MRY/zrg+qp6B/ACsLuN7wZeaOPXt3WSVpCJgiHJZuCPgH9s/QCXALe2JfuBy1t7Z+vT5i9t6yWtEJPuMXwW+CTwq9Y/E3ixql5t/cPAptbeBDwH0OZfautfI8meJIeSHHqFl0+xfElDWDQYknwAOFpV35nmhqtqX1Vtr6rta1g3zR8taYlWT7DmYuCDSXYApwFvBT4HrE+yuu0VbAaOtPVHgC3A4SSrgbcBP5565ZIGs+geQ1VdW1Wbq2orcCVwd1V9FLgHuKIt2wXc1toHWp82f3dV1VSrljSopVzH8BfAJ5IsMDqHcGMbvxE4s41/Ati7tBIlLbdJDiV+raq+BXyrtZ8GLjzBml8AH5pCbZJmxCsfJXUMBkkdg0FSx2CQ1DEYJHUMBkkdg0FSx2CQ1DEYJHUMBkkdg0FSx2CQ1DEYJHUMBkkdg0FSx2CQ1DEYJHUMBkkdg0FSx2CQ1DEYJHUMBkkdg0FSx2CQ1DEYJHUMBkkdg0FSx2CQ1DEYJHUMBkkdg0FSx2CQ1DEYJHUMBkmdiYIhyTNJHknyYJJDbeyMJHcleao9n97Gk+SGJAtJHk5ywZBvQNL0ncwewx9U1XlVtb319wIHq2obcLD1Ad4PbGuPPcDnp1WspOWxlEOJncD+1t4PXD42/qUa+TawPsnGJWxH0jKbNBgK+Pck30myp41tqKrnW/sHwIbW3gQ8N/baw23sNZLsSXIoyaFXePkUSpc0lNUTrntPVR1J8tvAXUn+a3yyqipJncyGq2ofsA/grTnjpF4raVgT7TFU1ZH2fBT4BnAh8MNjhwjt+WhbfgTYMvbyzW1M0gqxaDAkeVOStxxrA38IPAocAHa1ZbuA21r7AHBV+3TiIuClsUMOSSvAJIcSG4BvJDm2/itV9W9J7gduSbIbeBb4cFt/B7ADWAB+Dnxs6lVLGlSqZn94n+RnwJOzrmNCbwd+NOsiJrBS6oSVU+tKqRNOXOvvVNVZk7x40pOPQ3ty7PqIuZbk0EqodaXUCSun1pVSJyy9Vi+JltQxGCR15iUY9s26gJOwUmpdKXXCyql1pdQJS6x1Lk4+Spov87LHIGmOzDwYklyW5Ml2m/bexV8xaC1fTHI0yaNjY3N5e3mSLUnuSfJ4kseSXDOP9SY5Lcl9SR5qdX6qjZ+d5N5Wz81J1rbxda2/0Oa3LkedY/WuSvJAktvnvM5hvwqhqmb2AFYB3wfOAdYCDwHnzrCe3wcuAB4dG/s7YG9r7wWua+0dwL8CAS4C7l3mWjcCF7T2W4DvAefOW71te29u7TXAvW37twBXtvEvAH/S2n8KfKG1rwRuXuY/108AXwFub/15rfMZ4O3HjU3t737Z3sjrvLl3A3eO9a8Frp1xTVuPC4YngY2tvZHRNRcA/wB85ETrZlT3bcD75rle4I3Ad4F3Mbr4ZvXxvwfAncC7W3t1W5dlqm8zo+8WuQS4vf1Dmrs62zZPFAxT+7uf9aHERLdoz9iSbi9fDm039nxG/xvPXb1t9/xBRjfa3cVoL/HFqnr1BLX8us42/xJw5nLUCXwW+CTwq9Y/c07rhAG+CmHcvFz5uCJUnfzt5UNL8mbga8DHq+qn7Z4WYH7qrapfAuclWc/o7tx3zrikTpIPAEer6jtJ3jvreiYw9a9CGDfrPYaVcIv23N5enmQNo1D4clV9vQ3Pbb1V9SJwD6Nd8vVJjv3HNF7Lr+ts828DfrwM5V0MfDDJM8BNjA4nPjeHdQLDfxXCrIPhfmBbO/O7ltFJnAMzrul4c3l7eUa7BjcCT1TVZ+a13iRntT0FkryB0XmQJxgFxBWvU+ex+q8A7q52YDykqrq2qjZX1VZGv4d3V9VH561OWKavQliukyW/4STKDkZn1L8P/NWMa/kq8DzwCqPjsN2MjhsPAk8B3wTOaGsD/H2r+xFg+zLX+h5Gx5kPAw+2x455qxf4XeCBVuejwF+38XOA+xjdnv8vwLo2flrrL7T5c2bwe/Be/u9Tibmrs9X0UHs8duzfzTT/7r3yUVJn1ocSkuaQwSCpYzBI6hgMkjoGg6SOwSCpYzBI6hgMkjr/C6FpmSKZ8SIgAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lX1R79lr6Dlc"
      },
      "source": [
        "crop_size = 160\n",
        "p_seg = []\n",
        "p_im = []\n",
        "for i, i1 in zip(segmentations, patients):\n",
        "    im = nib.load(os.path.join(samples, i1))    \n",
        "    im = np.array(im.dataobj)\n",
        "\n",
        "    Masks = nib.load(os.path.join(labels, i))    \n",
        "    Masks = np.array(Masks.dataobj)\n",
        "    Masks.shape\n",
        "    for  j in range(Masks.shape[2]):\n",
        "        \n",
        "        k=make_box(Masks[:,:,j].astype(np.bool))\n",
        "        if len(k)!=0:\n",
        "            b_list = k['label1']\n",
        "            x_min, y_min, x_max, y_max = b_list\n",
        "            \n",
        "            length_x = x_max -x_min + 1\n",
        "            length_y = y_max - y_min + 1\n",
        "            del_x = crop_size - length_x \n",
        "            del_y = crop_size - length_y \n",
        "\n",
        "            if del_x%2==0:\n",
        "                kx = del_x//2\n",
        "                sx=0\n",
        "            else:\n",
        "                kx = del_x//2\n",
        "\n",
        "                sx = 1\n",
        "            if del_y%2==0:\n",
        "                ky = del_y//2\n",
        "                sy=0\n",
        "            else:\n",
        "                ky = del_y//2\n",
        "                sy = 1\n",
        "            crop = Masks[ y_min - ky - sy : y_max + ky + 1, x_min - kx - sx : x_max + kx  + 1,j ]\n",
        "            crop_im = im[ y_min - ky - sy : y_max + ky + 1, x_min - kx - sx : x_max + kx  + 1,j ]\n",
        "            p_seg.append(crop)\n",
        "            p_im.append(crop_im)\n",
        "   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDUY2DLw6Dld"
      },
      "source": [
        "segment_numpy = np.stack(p_seg,2)\n",
        "image_numpy = np.stack(p_im, 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_mcwDyL6Dld"
      },
      "source": [
        "train = image_numpy/image_numpy.max()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLji_MDe6Dle"
      },
      "source": [
        "tra  = np.transpose(train,(2,0,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77vNW0js6Dle"
      },
      "source": [
        "seg = np.transpose(segment_numpy,(2,0,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZ1-7XrJyHL9"
      },
      "source": [
        "\n",
        "def gen():\n",
        "  samples = '/content/drive/MyDrive/samples/'\n",
        "  patients = next(os.walk(samples))[2]\n",
        "  patients.sort()\n",
        "  labels = '/content/drive/MyDrive/segmentation/'\n",
        "  segmentations =next(os.walk(labels))[2]\n",
        "  segmentations.sort()\n",
        "  for i,j in zip(patients,segmentations):\n",
        "    Images = nib.load((samples + i))\n",
        "    im = np.array(Images.dataobj)\n",
        "    Masks = nib.load((labels + j))    \n",
        "    Masks = np.array(Masks.dataobj)\n",
        "    img_resize = resize(im,\n",
        "               (IMG_HEIGHT, IMG_WIDTH),\n",
        "             mode = 'constant',\n",
        "              anti_aliasing=True,\n",
        "               preserve_range=True)\n",
        "    mask_resize = resize(Masks,\n",
        "               (IMG_HEIGHT, IMG_WIDTH),\n",
        "             mode = 'constant',\n",
        "              anti_aliasing=True,\n",
        "               preserve_range=True)\n",
        "    for k in range(im.shape[2]):\n",
        "      im1 = np.expand_dims(img_resize[:,:,k],2)\n",
        "      ma = np.expand_dims(mask_resize[:,:,k],2)\n",
        "\n",
        "      yield {'Image':im1, 'Mask':ma}\n",
        "      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtNu_XsM0336"
      },
      "source": [
        "dat = tf.data.Dataset.from_generator(gen, output_types ={\"Image\": tf.float32, \"Mask\": tf.float32}).batch(45)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsdAxDawytkh"
      },
      "source": [
        "it=iter(dat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxynfBewJV7Y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "76f60e80-1b30-4cb2-fc85-510d6ab4e473"
      },
      "source": [
        "dataset = next(it)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "UnknownError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mexecution_mode\u001b[0;34m(mode)\u001b[0m\n\u001b[1;32m   2112\u001b[0m       \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecutor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecutor_new\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2113\u001b[0;31m       \u001b[0;32myield\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2114\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    732\u001b[0m           \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 733\u001b[0;31m           output_shapes=self._flat_output_shapes)\n\u001b[0m\u001b[1;32m    734\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   2578\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2579\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2580\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6861\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6862\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6863\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
            "\u001b[0;31mUnknownError\u001b[0m: NameError: name 'IMG_HEIGHT' is not defined\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/script_ops.py\", line 249, in __call__\n    ret = func(*args)\n\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\", line 620, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\", line 891, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"<ipython-input-20-6dec3f3427b8>\", line 15, in gen\n    (IMG_HEIGHT, IMG_WIDTH),\n\nNameError: name 'IMG_HEIGHT' is not defined\n\n\n\t [[{{node PyFunc}}]] [Op:IteratorGetNext]",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-011e1c3fbd6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    745\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 747\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    748\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    737\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_element_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_from_compatible_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 739\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_compatible_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_element_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     97\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m                 \u001b[0;31m# Suppress StopIteration *unless* it's the same exception that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mexecution_mode\u001b[0;34m(mode)\u001b[0m\n\u001b[1;32m   2114\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2115\u001b[0m       \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecutor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecutor_old\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2116\u001b[0;31m       \u001b[0mexecutor_new\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/executor.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     67\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;34m\"\"\"Waits for ops dispatched in this executor to finish.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0mpywrap_tfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFE_ExecutorWaitForAllPendingNodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mclear_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnknownError\u001b[0m: NameError: name 'IMG_HEIGHT' is not defined\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/script_ops.py\", line 249, in __call__\n    ret = func(*args)\n\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\", line 620, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\", line 891, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"<ipython-input-20-6dec3f3427b8>\", line 15, in gen\n    (IMG_HEIGHT, IMG_WIDTH),\n\nNameError: name 'IMG_HEIGHT' is not defined\n\n\n\t [[{{node PyFunc}}]]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANu52n8z6Dlj"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6C8awsS6Dlj"
      },
      "source": [
        "img_size = (160, 160)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FgtbWU36Dlj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4881bac-fc65-4761-b501-d0343031b2a4"
      },
      "source": [
        "\n",
        "\n",
        "def get_model(img_size, num_classes):\n",
        "    inputs = keras.Input(shape=img_size + (1,))\n",
        "\n",
        "    ### [First half of the network: downsampling inputs] ###\n",
        "\n",
        "    # Entry block\n",
        "    x = layers.Conv2D(32, 3, strides=2, padding=\"same\")(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "    previous_block_activation = x  # Set aside residual\n",
        "\n",
        "    # Blocks 1, 2, 3 are identical apart from the feature depth.\n",
        "    for filters in [64, 128, 256]:\n",
        "        x = layers.Activation(\"relu\")(x)\n",
        "        x = layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "\n",
        "        x = layers.Activation(\"relu\")(x)\n",
        "        x = layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "\n",
        "        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
        "\n",
        "        # Project residual\n",
        "        residual = layers.Conv2D(filters, 1, strides=2, padding=\"same\")(\n",
        "            previous_block_activation\n",
        "        )\n",
        "        x = layers.add([x, residual])  # Add back residual\n",
        "        previous_block_activation = x  # Set aside next residual\n",
        "\n",
        "    ### [Second half of the network: upsampling inputs] ###\n",
        "\n",
        "    for filters in [256, 128, 64, 32]:\n",
        "        x = layers.Activation(\"relu\")(x)\n",
        "        x = layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "\n",
        "        x = layers.Activation(\"relu\")(x)\n",
        "        x = layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "\n",
        "        x = layers.UpSampling2D(2)(x)\n",
        "\n",
        "        # Project residual\n",
        "        residual = layers.UpSampling2D(2)(previous_block_activation)\n",
        "        residual = layers.Conv2D(filters, 1, padding=\"same\")(residual)\n",
        "        x = layers.add([x, residual])  # Add back residual\n",
        "        previous_block_activation = x  # Set aside next residual\n",
        "\n",
        "    # Add a per-pixel classification layer\n",
        "    outputs = layers.Conv2D(num_classes, 3, activation=\"softmax\", padding=\"same\")(x)\n",
        "\n",
        "    # Define the model\n",
        "    model = keras.Model(inputs, outputs)\n",
        "    return model\n",
        "\n",
        "\n",
        "# Free up RAM in case the model definition cells were run multiple times\n",
        "keras.backend.clear_session()\n",
        "\n",
        "# Build model\n",
        "model = get_model(img_size, 3)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 160, 160, 1) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 80, 80, 32)   320         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 80, 80, 32)   128         conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 80, 80, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 80, 80, 32)   0           activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d (SeparableConv (None, 80, 80, 64)   2400        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 80, 80, 64)   256         separable_conv2d[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 80, 80, 64)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_1 (SeparableCo (None, 80, 80, 64)   4736        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 80, 80, 64)   256         separable_conv2d_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 40, 40, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 40, 40, 64)   2112        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 40, 40, 64)   0           max_pooling2d[0][0]              \n",
            "                                                                 conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 40, 40, 64)   0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_2 (SeparableCo (None, 40, 40, 128)  8896        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 40, 40, 128)  512         separable_conv2d_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 40, 40, 128)  0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_3 (SeparableCo (None, 40, 40, 128)  17664       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 40, 40, 128)  512         separable_conv2d_3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 20, 20, 128)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 20, 20, 128)  8320        add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 20, 20, 128)  0           max_pooling2d_1[0][0]            \n",
            "                                                                 conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 20, 20, 128)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_4 (SeparableCo (None, 20, 20, 256)  34176       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 20, 20, 256)  1024        separable_conv2d_4[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 20, 20, 256)  0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_5 (SeparableCo (None, 20, 20, 256)  68096       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 20, 20, 256)  1024        separable_conv2d_5[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 10, 10, 256)  0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 10, 10, 256)  33024       add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 10, 10, 256)  0           max_pooling2d_2[0][0]            \n",
            "                                                                 conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 10, 10, 256)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose (Conv2DTranspo (None, 10, 10, 256)  590080      activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 10, 10, 256)  1024        conv2d_transpose[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 10, 10, 256)  0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTrans (None, 10, 10, 256)  590080      activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 10, 10, 256)  1024        conv2d_transpose_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2D)  (None, 20, 20, 256)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d (UpSampling2D)    (None, 20, 20, 256)  0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 20, 20, 256)  65792       up_sampling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 20, 20, 256)  0           up_sampling2d[0][0]              \n",
            "                                                                 conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 20, 20, 256)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTrans (None, 20, 20, 128)  295040      activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 20, 20, 128)  512         conv2d_transpose_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 20, 20, 128)  0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_3 (Conv2DTrans (None, 20, 20, 128)  147584      activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 20, 20, 128)  512         conv2d_transpose_3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_3 (UpSampling2D)  (None, 40, 40, 256)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2D)  (None, 40, 40, 128)  0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 40, 40, 128)  32896       up_sampling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 40, 40, 128)  0           up_sampling2d_2[0][0]            \n",
            "                                                                 conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 40, 40, 128)  0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_4 (Conv2DTrans (None, 40, 40, 64)   73792       activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 40, 40, 64)   256         conv2d_transpose_4[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 40, 40, 64)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_5 (Conv2DTrans (None, 40, 40, 64)   36928       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 40, 40, 64)   256         conv2d_transpose_5[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_5 (UpSampling2D)  (None, 80, 80, 128)  0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_4 (UpSampling2D)  (None, 80, 80, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 80, 80, 64)   8256        up_sampling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 80, 80, 64)   0           up_sampling2d_4[0][0]            \n",
            "                                                                 conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 80, 80, 64)   0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_6 (Conv2DTrans (None, 80, 80, 32)   18464       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 80, 80, 32)   128         conv2d_transpose_6[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 80, 80, 32)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_7 (Conv2DTrans (None, 80, 80, 32)   9248        activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 80, 80, 32)   128         conv2d_transpose_7[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_7 (UpSampling2D)  (None, 160, 160, 64) 0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_6 (UpSampling2D)  (None, 160, 160, 32) 0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 160, 160, 32) 2080        up_sampling2d_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 160, 160, 32) 0           up_sampling2d_6[0][0]            \n",
            "                                                                 conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 160, 160, 3)  867         add_6[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 2,058,403\n",
            "Trainable params: 2,054,627\n",
            "Non-trainable params: 3,776\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-iGbhyz6Dll"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxhAdMrk6Dlm"
      },
      "source": [
        "# train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GndrAX_b6Dln",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc2b5ba0-a46b-4118-d072-e96d22550409"
      },
      "source": [
        "# Configure the model for training.\n",
        "# We use the \"sparse\" version of categorical_crossentropy\n",
        "# because our target data is integers.\n",
        "model.compile(optimizer=\"rmsprop\", loss=\"sparse_categorical_crossentropy\")\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"oxford_segmentation.h5\", save_best_only=True)\n",
        "]\n",
        "\n",
        "# Train the model, doing validation at the end of each epoch.\n",
        "epochs = 15\n",
        "model.fit(tra, seg, epochs=epochs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "24/24 [==============================] - 176s 7s/step - loss: 2.7671\n",
            "Epoch 2/15\n",
            "24/24 [==============================] - 171s 7s/step - loss: 0.5054\n",
            "Epoch 3/15\n",
            "24/24 [==============================] - 171s 7s/step - loss: 0.3718\n",
            "Epoch 4/15\n",
            "24/24 [==============================] - 174s 7s/step - loss: 0.3454\n",
            "Epoch 5/15\n",
            "24/24 [==============================] - 171s 7s/step - loss: 0.2610\n",
            "Epoch 6/15\n",
            "24/24 [==============================] - 170s 7s/step - loss: 0.2673\n",
            "Epoch 7/15\n",
            "24/24 [==============================] - 170s 7s/step - loss: 0.2054\n",
            "Epoch 8/15\n",
            "24/24 [==============================] - 169s 7s/step - loss: 0.2481\n",
            "Epoch 9/15\n",
            "24/24 [==============================] - 170s 7s/step - loss: 0.2206\n",
            "Epoch 10/15\n",
            "24/24 [==============================] - 169s 7s/step - loss: 0.1645\n",
            "Epoch 11/15\n",
            "24/24 [==============================] - 168s 7s/step - loss: 0.1656\n",
            "Epoch 12/15\n",
            "24/24 [==============================] - 169s 7s/step - loss: 0.1327\n",
            "Epoch 13/15\n",
            "24/24 [==============================] - 169s 7s/step - loss: 0.1609\n",
            "Epoch 14/15\n",
            "24/24 [==============================] - 168s 7s/step - loss: 0.1198\n",
            "Epoch 15/15\n",
            "24/24 [==============================] - 168s 7s/step - loss: 0.1403\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0cf144a518>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEhKJBwu6Dln"
      },
      "source": [
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2d7JJ-x6Dlo"
      },
      "source": [
        "root = \"home\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wN2tmpZ_6Dlo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "2a8328a1-2394-4584-e277-fb638ee1804f"
      },
      "source": [
        "al_gen = OxfordPets(batch_size, img_size, val_input_img_paths, val_target_img_paths)\n",
        "val_preds = model.predict(val_gen)\n",
        "\n",
        "\n",
        "\n",
        "# Display results for validation image #10\n",
        "i = 10\n",
        "\n",
        "# Display input image\n",
        "display(Image(filename=val_input_img_paths[i]))\n",
        "\n",
        "# Display ground-truth target mask\n",
        "img = PIL.ImageOps.autocontrast(load_img(val_target_img_paths[i]))\n",
        "display(img)\n",
        "\n",
        "# Display mask predicted by our model\n",
        "display_mask(i)  # Note that the model only sees inputs at 150x150."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-8ca55ff98886>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mal_gen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOxfordPets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_input_img_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_target_img_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mval_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'OxfordPets' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvgCH9Qg6Dlp"
      },
      "source": [
        "\n",
        "def display_mask(i):\n",
        "    \"\"\"Quick utility to display a model's prediction.\"\"\"\n",
        "    mask = np.argmax(val_preds[i], axis=-1)\n",
        "    mask = np.expand_dims(mask, axis=-1)\n",
        "    img = PIL.ImageOps.autocontrast(keras.preprocessing.image.array_to_img(mask))\n",
        "    display(img)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QG7thh5H6Dlp"
      },
      "source": [
        "pr = model.predict(tra[:670])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwiFzQV-6Dlq"
      },
      "source": [
        "mask1 = np.argmax(pr[20], axis=-1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNbQGR5J6Dlq"
      },
      "source": [
        "plt.imshow(mask1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gk433_XH6Dlq"
      },
      "source": [
        "pr[2]"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}