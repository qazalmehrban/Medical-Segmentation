{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOD2H//gmDty9f3FedcZoUa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/qazalmehrban/Medical-Segmentation/blob/develop/Untitled3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCwSRzSsvMoM"
      },
      "source": [
        "# 1. Import Required Modules\r\n",
        "\r\n",
        "import os\r\n",
        "import glob\r\n",
        "import keras\r\n",
        "import random\r\n",
        "import numpy as np\r\n",
        "import tensorflow as tf\r\n",
        "from keras.layers import *\r\n",
        "import keras.backend as k\r\n",
        "from keras.models import *\r\n",
        "from keras.optimizers import *\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from skimage.transform import resize\r\n",
        "from skimage.io import imread, imshow, imsave\r\n",
        "from keras.losses import categorical_crossentropy\r\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# 2. Define Train & Test Path (Images + Mask Path for Train and Test Stages)\r\n",
        "\r\n",
        "TRAIN_IMAGE_PATH = ''\r\n",
        "TRAIN_MASK_PATH = ''\r\n",
        "TEST_IMAGE_PATH = ''\r\n",
        "TEST_MASK_PATH = ''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbVPhB_D3-hs"
      },
      "source": [
        "# 3. Initialize Images and Mask Size\r\n",
        "\r\n",
        "IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS = 255, 255, 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KB_lmCsl4Ekx"
      },
      "source": [
        "# 4. Define Pre_Processing Function (Region of Interest Extraction _ ROI)\r\n",
        "  \r\n",
        "Train_Mask_List = sorted(next(os.walk(TRAIN_MASK_PATH))[1])\r\n",
        "Test_Mask_List = sorted(next(os.walk(TEST_MASK_PATH))[1])\r\n",
        "\r\n",
        "def Data_Proprocessing_Train():\r\n",
        "    \r\n",
        "    Init_Image = np.zeros((len(Train_Mask_List), 384, 384, 3), dtype = np.uint8)\r\n",
        "    Init_Mask = np.zeros((len(Train_Mask_List), 384, 384), dtype = np.bool)\r\n",
        "    Train_X = np.zeros((len(Train_Mask_List), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype = np.uint8)\r\n",
        "    Train_Y = np.zeros((len(Train_Mask_List), IMG_HEIGHT, IMG_WIDTH, 1), dtype = np.bool)\r\n",
        "    \r\n",
        "    n = 0\r\n",
        "    \r\n",
        "    for mask_path in glob.glob('{}'.format(TRAIN_MASK_PATH)):\r\n",
        "        \r\n",
        "        base = os.path.basename(mask_path)\r\n",
        "        image_ID, ext = os.path.splitext(base)\r\n",
        "        image_path = '{}/{}'.format(TRAIN_IMAGE_PATH, image_ID)\r\n",
        "        mask = imread(mask_path)\r\n",
        "        image = imread(image_path)\r\n",
        "        \r\n",
        "        y_coord, x_coord = np.where(mask == 255)\r\n",
        "        \r\n",
        "        y_min = min(y_coord) \r\n",
        "        y_max = max(y_coord)\r\n",
        "        x_min = min(x_coord)\r\n",
        "        x_max = max(x_coord)\r\n",
        "        \r\n",
        "        cropped_image = image[y_min:y_max, x_min:x_max]\r\n",
        "        cropped_mask = mask[y_min:y_max, x_min:x_max]\r\n",
        "        \r\n",
        "        Train_X[n] = resize(cropped_image[:,:,:IMG_CHANNELS],\r\n",
        "               (IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS),\r\n",
        "               mode = 'constant',\r\n",
        "               anti_aliasing=True,\r\n",
        "               preserve_range=True)\r\n",
        "        \r\n",
        "        Train_Y[n] = np.expand_dims(resize(cropped_mask, \r\n",
        "               (IMG_HEIGHT, IMG_WIDTH),\r\n",
        "               mode = 'constant',\r\n",
        "               anti_aliasing=True,\r\n",
        "               preserve_range=True), axis = -1)\r\n",
        "        \r\n",
        "        Init_Image[n] = image\r\n",
        "        Init_Mask[n] = mask\r\n",
        "        \r\n",
        "        n+=1\r\n",
        "        \r\n",
        "    return Train_X, Train_Y, Init_Image, Init_Mask\r\n",
        "\r\n",
        "Train_Inputs, Train_Masks, Init_Image, Init_Mask = Data_Proprocessing_Train()\r\n",
        "\r\n",
        "\r\n",
        "def Data_Proprocessing_Test():\r\n",
        "    \r\n",
        "\r\n",
        "    Test_X = np.zeros((len(Test_Mask_List), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype = np.uint8)\r\n",
        "    Test_Y = np.zeros((len(Test_Mask_List), IMG_HEIGHT, IMG_WIDTH, 1), dtype = np.bool)\r\n",
        "    \r\n",
        "    n = 0\r\n",
        "    \r\n",
        "    for mask_path in glob.glob('{}'.format(TEST_MASK_PATH)):\r\n",
        "        \r\n",
        "        base = os.path.basename(mask_path)\r\n",
        "        image_ID, ext = os.path.splitext(base)\r\n",
        "        image_path = '{}/{}'.format(TEST_IMAGE_PATH, image_ID)\r\n",
        "        mask = imread(mask_path)\r\n",
        "        image = imread(image_path)\r\n",
        "        \r\n",
        "        y_coord, x_coord = np.where(mask == 255)\r\n",
        "        \r\n",
        "        y_min = min(y_coord) \r\n",
        "        y_max = max(y_coord)\r\n",
        "        x_min = min(x_coord)\r\n",
        "        x_max = max(x_coord)\r\n",
        "        \r\n",
        "        cropped_image = image[y_min:y_max, x_min:x_max]\r\n",
        "        cropped_mask = mask[y_min:y_max, x_min:x_max]\r\n",
        "        \r\n",
        "        Test_X[n] = resize(cropped_image[:,:,:IMG_CHANNELS],\r\n",
        "               (IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS),\r\n",
        "               mode = 'constant',\r\n",
        "               anti_aliasing=True,\r\n",
        "               preserve_range=True)\r\n",
        "        \r\n",
        "        Test_Y[n] = np.expand_dims(resize(cropped_mask, \r\n",
        "               (IMG_HEIGHT, IMG_WIDTH),\r\n",
        "               mode = 'constant',\r\n",
        "               anti_aliasing=True,\r\n",
        "               preserve_range=True), axis = -1)\r\n",
        "        \r\n",
        "        \r\n",
        "        n+=1\r\n",
        "        \r\n",
        "    return Test_X, Test_Y\r\n",
        "\r\n",
        "Test_Inputs, Test_Masks = Data_Proprocessing_Test()\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48ZrsOdA6F38"
      },
      "source": [
        "# 4.1. Show The Results in Preprocessing Stage\r\n",
        "    \r\n",
        "print('Original_Image')\r\n",
        "imshow(Init_Image[0])\r\n",
        "plt.show()\r\n",
        "\r\n",
        "print('Original_Mask')\r\n",
        "imshow(Init_Mask[0])\r\n",
        "plt.show()\r\n",
        "\r\n",
        "print('Region_of_Interest_Image')\r\n",
        "imshow(Train_Inputs[0])\r\n",
        "plt.show()\r\n",
        "\r\n",
        "print('Region_of_Interest_Mask')\r\n",
        "imshow(np.squeeze(Train_Masks[0]))\r\n",
        "plt.show()\r\n",
        "\r\n",
        "rows = 1\r\n",
        "columns = 4\r\n",
        "Figure = plt.figure(figsize=(15,15))\r\n",
        "Image_List = [Init_Image[0], Init_Mask[0], Train_Inputs[0], Train_Masks[0]]\r\n",
        "\r\n",
        "for i in range(1, rows*columns + 1):\r\n",
        "    Image = Image_List[i-1]\r\n",
        "    Sub_Plot_Image = Figure.add_subplot(rows, columns, i)\r\n",
        "    Sub_Plot_Image.imshow(np.squeeze(Image))\r\n",
        "plt.show()\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyzVX48J6Oe8"
      },
      "source": [
        "# 5. Implementation of U_NET Model for Semantic Segmentation\r\n",
        "\r\n",
        "def U_Net_Segmentation(input_size=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)):\r\n",
        "    \r\n",
        "    inputs = Input(input_size)\r\n",
        "    n = Lambda(lambda x:x/255)(inputs)\r\n",
        "    \r\n",
        "    \r\n",
        "    c1 = Conv2D(16, (3,3), activation='elu', kernel_initializer='he_normal',\r\n",
        "                padding='same')(n)\r\n",
        "    c1 = Dropout(0.1)(c1)\r\n",
        "    c1 = Conv2D(16, (3,3), activation='elu', kernel_initializer='he_normal',\r\n",
        "                padding='same')(c1)\r\n",
        "    p1 = MaxPooling2D((2,2))(c1)\r\n",
        "\r\n",
        "\r\n",
        "    c2 = Conv2D(32, (3,3), activation='elu', kernel_initializer='he_normal',\r\n",
        "                padding='same')(p1)\r\n",
        "    c2 = Dropout(0.1)(c2)\r\n",
        "    c2 = Conv2D(32, (3,3), activation='elu', kernel_initializer='he_normal',\r\n",
        "                padding='same')(c2)\r\n",
        "    p2 = MaxPooling2D((2,2))(c2)\r\n",
        "\r\n",
        "\r\n",
        "    c3 = Conv2D(64, (3,3), activation='elu', kernel_initializer='he_normal',\r\n",
        "                padding='same')(p2)\r\n",
        "    c3 = Dropout(0.2)(c3)\r\n",
        "    c3 = Conv2D(64, (3,3), activation='elu', kernel_initializer='he_normal',\r\n",
        "                padding='same')(c3)\r\n",
        "    p3 = MaxPooling2D((2,2))(c3)\r\n",
        "\r\n",
        "\r\n",
        "    c4 = Conv2D(128, (3,3), activation='elu', kernel_initializer='he_normal',\r\n",
        "                padding='same')(p3)\r\n",
        "    c4 = Dropout(0.2)(c4)\r\n",
        "    c4 = Conv2D(128, (3,3), activation='elu', kernel_initializer='he_normal',\r\n",
        "                padding='same')(c4)\r\n",
        "    p4 = MaxPooling2D((2,2))(c4)\r\n",
        "\r\n",
        "\r\n",
        "    c5 = Conv2D(256, (3,3), activation='elu', kernel_initializer='he_normal',\r\n",
        "                padding='same')(p4)\r\n",
        "    c5 = Dropout(0.3)(c5)\r\n",
        "    c5 = Conv2D(256, (3,3), activation='elu', kernel_initializer='he_normal',\r\n",
        "                padding='same')(c5)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "    u6 = Conv2DTranspose(128, (2,2), strides=(2,2), padding='same')(c5)\r\n",
        "    u6 = concatenate([u6, c4])\r\n",
        "    c6 = Conv2D(128, (3,3), activation='elu', kernel_initializer='he_normal',\r\n",
        "                padding='same')(u6)\r\n",
        "    c6 = Dropout(0.2)(c6)\r\n",
        "    c6 = Conv2D(128, (3,3), activation='elu', kernel_initializer='he_normal',\r\n",
        "                padding='same')(c6)   \r\n",
        "\r\n",
        "\r\n",
        "    u7 = Conv2DTranspose(64, (2,2), strides=(2,2), padding='same')(c6)\r\n",
        "    u7 = concatenate([u7, c3])\r\n",
        "    c7 = Conv2D(64, (3,3), activation='elu', kernel_initializer='he_normal',\r\n",
        "                padding='same')(u7)\r\n",
        "    c7 = Dropout(0.2)(c7)\r\n",
        "    c7 = Conv2D(64, (3,3), activation='elu', kernel_initializer='he_normal',\r\n",
        "                padding='same')(c7) \r\n",
        "\r\n",
        "    u8 = Conv2DTranspose(32, (2,2), strides=(2,2), padding='same')(c7)\r\n",
        "    u8 = concatenate([u8, c2])\r\n",
        "    c8 = Conv2D(32, (3,3), activation='elu', kernel_initializer='he_normal',\r\n",
        "                padding='same')(u8)\r\n",
        "    c8 = Dropout(0.1)(c8)\r\n",
        "    c8 = Conv2D(32, (3,3), activation='elu', kernel_initializer='he_normal',\r\n",
        "                padding='same')(c8) \r\n",
        "    \r\n",
        "    \r\n",
        "    u9 = Conv2DTranspose(16, (2,2), strides=(2,2), padding='same')(c8)\r\n",
        "    u9 = concatenate([u9, c1], axis = 3)\r\n",
        "    c9 = Conv2D(16, (3,3), activation='elu', kernel_initializer='he_normal',\r\n",
        "                padding='same')(u9)\r\n",
        "    c9 = Dropout(0.1)(c9)\r\n",
        "    c9 = Conv2D(16, (3,3), activation='elu', kernel_initializer='he_normal',\r\n",
        "                padding='same')(c9) \r\n",
        "    \r\n",
        "    outputs = Conv2D(1,(1,1), activation='sigmoid')(c9)\r\n",
        "    \r\n",
        "    model = Model(inputs=[inputs], outputs=[outputs])\r\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', \r\n",
        "                  metrics=[Mean_IOU_Evaluator])\r\n",
        "    model.summary()\r\n",
        "    return model\r\n",
        "    \r\n",
        "   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soSEtUSX6q6b"
      },
      "source": [
        "# 6. Define U_NET Model Evaluator (Intersection Over Union _ IOU)\r\n",
        "\r\n",
        "def Mean_IOU_Evaluator(y_true, y_pred):\r\n",
        "    \r\n",
        "    prec = []\r\n",
        "    \r\n",
        "    for t in np.arange(0.5, 1, 0.05):\r\n",
        "        \r\n",
        "        y_pred_ = tf.to_int32(y_pred>t)\r\n",
        "        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\r\n",
        "        k.get_session().run(tf.local_variables_initializer())\r\n",
        "        with tf.control_dependencies([up_opt]):\r\n",
        "            score = tf.identity(score)\r\n",
        "        prec.append(score)\r\n",
        "    return k.mean(k.stack(prec), axis = 0)\r\n",
        "\r\n",
        "model = U_Net_Segmentation()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDlaPTPx6yjL"
      },
      "source": [
        "# 7. Show The Results per Epoch\r\n",
        "\r\n",
        "class loss_history(keras.callbacks.Callback):\r\n",
        "    \r\n",
        "    def __init__ (self, x=4):\r\n",
        "        self.x = x\r\n",
        "        \r\n",
        "    def on_epoch_begin(self, epoch, logs={}):\r\n",
        "        \r\n",
        "        imshow(Train_Inputs[self.x])\r\n",
        "        plt.show()\r\n",
        "        \r\n",
        "        imshow(np.squeeze(Train_Masks[self.x]))\r\n",
        "        plt.show()\r\n",
        "        \r\n",
        "        preds_train = self.model.predict(np.expand_dims(Train_Inputs[self.x], axis = 0))\r\n",
        "        imshow(np.squeeze(preds_train[0]))\r\n",
        "        plt.show()\r\n",
        "  \r\n",
        "\r\n",
        "imageset = 'BCC'\r\n",
        "backbone = 'UNET'\r\n",
        "version = 'v1.0'\r\n",
        "model_h5 = 'model-{imageset}-{backbone}-{version}.h5'.format(imageset=imageset, \r\n",
        "                  backbone = backbone, version = version)\r\n",
        "model_h5_checkpoint = '{model_h5}.checkpoint'.format(model_h5=model_h5)\r\n",
        "\r\n",
        "earlystopper = EarlyStopping(patience=7, verbose=1)\r\n",
        "checkpointer = ModelCheckpoint(model_h5_checkpoint, verbose = 1, save_best_only=True)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ze66iE6e66ab"
      },
      "source": [
        "# 8. Train U_NET Model using Training Samples\r\n",
        "\r\n",
        "results = model.fit(Train_Inputs, Train_Masks, \r\n",
        "                    validation_split=0.1, \r\n",
        "                    batch_size=2,\r\n",
        "                    epochs=50,\r\n",
        "                    callbacks=[earlystopper, checkpointer, loss_history()])\r\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0Z8tGTe69Y0"
      },
      "source": [
        "# 9. U_NET Model Evaluation using Test Samples\r\n",
        "\r\n",
        "preds_train = model.predict(Train_Inputs, verbose=1)\r\n",
        "preds_train_t = (preds_train>0.5).astype(np.uint8)\r\n",
        "preds_test = model.predict(Test_Inputs, verbose=1)\r\n",
        "preds_test_t = (preds_test>0.5).astype(np.uint8)\r\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecJLLP8U7Anr"
      },
      "source": [
        "# 10. Show Final Results (Segmented Images)\r\n",
        "\r\n",
        "ix = random.randint(0, len(Train_Inputs)-1)\r\n",
        "\r\n",
        "print(ix)\r\n",
        "\r\n",
        "print('Train_Image')\r\n",
        "imshow(Train_Inputs[ix])\r\n",
        "plt.show()\r\n",
        "\r\n",
        "print('Train_Mask')\r\n",
        "imshow(np.squeeze(Train_Masks[ix]))\r\n",
        "plt.show()\r\n",
        "\r\n",
        "print('Segmented_Image')\r\n",
        "imshow(np.squeeze(preds_train[ix]))\r\n",
        "plt.show()\r\n",
        "\r\n",
        "\r\n",
        "iix = random.randint(0,1)\r\n",
        "print(iix)\r\n",
        "\r\n",
        "print('Test_Image')\r\n",
        "imshow(Test_Inputs[iix])\r\n",
        "plt.show()\r\n",
        "\r\n",
        "print('Test_Mask')\r\n",
        "imshow(np.squeeze(Test_Masks[iix]))\r\n",
        "plt.show()\r\n",
        "\r\n",
        "print('Segmented_Test_Mask')\r\n",
        "imshow(np.squeeze(preds_test[iix]))\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gt4qntau7FJV"
      },
      "source": [
        "# 11. Show Loss and IOU Plots\r\n",
        "\r\n",
        "\r\n",
        "# 11.1. Summarize History for Loss\r\n",
        "\r\n",
        "plt.plot(results.history['loss'])\r\n",
        "plt.plot(results.history['val_loss'])\r\n",
        "plt.title('Model Loss')\r\n",
        "plt.ylabel('loss')\r\n",
        "plt.xlabel('epochs')\r\n",
        "plt.legend(['Training','Validation'], loc = 'upper left')\r\n",
        "plt.show()\r\n",
        "\r\n",
        "\r\n",
        "# 11.1. Summarize History for IOU\r\n",
        "\r\n",
        "plt.plot(results.history['Mean_IOU_Evaluator'])\r\n",
        "plt.plot(results.history['val_Mean_IOU_Evaluator'])\r\n",
        "plt.title('Intersection Over Union')\r\n",
        "plt.ylabel('IOU')\r\n",
        "plt.xlabel('epochs')\r\n",
        "plt.legend(['Training','Validation'], loc = 'upper left')\r\n",
        "plt.show()\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}