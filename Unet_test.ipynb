{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/qazalmehrban/Medical-Segmentation/blob/ghazal/kera_dataloader.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "SJeS1cyb1W6E"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from skimage.transform import resize\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import os \n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QfR6URnCEmgZ"
   },
   "outputs": [],
   "source": [
    "heaight, width = 200,200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "Z-zMk0jg6Dla"
   },
   "outputs": [],
   "source": [
    "samples = '/content/drive/MyDrive/samples/'\n",
    "patients = next(os.walk(samples))[2]\n",
    "labels = '/content/drive/MyDrive/segmentation/'\n",
    "segmentations =next(os.walk(labels))[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def description(samples):\n",
    "  unique_spational = set()\n",
    "  all_spational_slice = []\n",
    "  patients = os.listdir(samples)\n",
    "  patients.sort()\n",
    "  for number_file, image_id  in enumerate(patients):\n",
    "    im = nib.load(os.path.join(samples, image_id))    \n",
    "    im = np.array(im.dataobj)\n",
    "    unique_spational.add(im.shape[:2])\n",
    "    for slices in range(im.shape[2]):\n",
    "\n",
    "      all_spational_slice.append(im.shape[:2])\n",
    "  print(f\"there are {len(unique_spational)} unique spational dimension\")\n",
    "  print(f\"there are {number_file} patient image\")\n",
    "  for i in unique_spational:\n",
    "   print(f'there are {all_spational_slice.count(i)} slice with shape {i}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def description_mask(labels):\n",
    "  segmentations = os.listdir(labels)\n",
    "  segmentations.sort()\n",
    "\n",
    "  k = set()\n",
    "  num = []\n",
    "  for i1 in segmentations:\n",
    "    \n",
    "    Masks = nib.load(os.path.join(labels, i1))    \n",
    "    Masks = np.array(Masks.dataobj)\n",
    "    for  j in range(Masks.shape[2]):\n",
    "      u = np.unique(Masks[:,:,j])\n",
    "      u = tuple(u.astype(np.int))\n",
    "      k.add(u)\n",
    "      num.append(u)\n",
    "  for i in k :\n",
    "    print(f'there are {num.count(i)} slice with label {i}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "4_747rKG6Dlb"
   },
   "outputs": [],
   "source": [
    "def make_box(mask):\n",
    "    box = []\n",
    "    obj_ids = np.unique(mask)\n",
    "    if mask.dtype == bool:\n",
    "        if len(np.unique(mask))==2:\n",
    "            \n",
    "            y_min = np.nonzero(mask)[0].min()\n",
    "            y_max = np.nonzero(mask)[0].max()\n",
    "            x_min = np.nonzero(mask)[1].min()\n",
    "            x_max = np.nonzero(mask)[1].max()\n",
    "            box.append([x_min, y_min, x_max, y_max])\n",
    "    else :\n",
    "        \n",
    "        for i in  obj_ids[1:]:\n",
    "            y_min = np.nonzero(mask==i)[0].min()\n",
    "            y_max = np.nonzero(mask==i)[0].max()\n",
    "            x_min = np.nonzero(mask==i)[1].min()\n",
    "            x_max = np.nonzero(mask==i)[1].max()\n",
    "            box.append([x_min, y_min, x_max, y_max])\n",
    "    return dict(zip([f\"label{int(i)}\" for i in obj_ids[1:]],box))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "id": "A2SuytaH6Uzg",
    "outputId": "9dc22755-d5dc-421a-d481-8ca1723f799e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape (384, 384, 15)\n",
      "labels_slice_1 [0. 1. 2.]\n",
      "bounding_box {'label1': [169, 179, 203, 217], 'label2': [164, 186, 189, 209]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f46d22a4390>"
      ]
     },
     "execution_count": 74,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Masks = nib.load((labels + segmentations[0]))    \n",
    "Masks = np.array(Masks.dataobj)\n",
    "print('shape', Masks.shape)\n",
    "slices =1\n",
    "Masks_2d = Masks[:,:,slices]\n",
    "print(f'labels_slice_{slices}', np.unique(Masks_2d))\n",
    "print('bounding_box', make_box(Masks_2d))\n",
    "plt.imshow(Masks_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a1TUX6dj6U4z"
   },
   "outputs": [],
   "source": [
    "def crop_specific(im, mask, crop_size):\n",
    "        \n",
    "        k=make_box(mask.astype(np.bool))\n",
    "        if len(k)!=0:\n",
    "            b_list = k\n",
    "            x_min, y_min, x_max, y_max = b_list\n",
    "            \n",
    "            length_x = x_max -x_min + 1\n",
    "            length_y = y_max - y_min + 1\n",
    "            del_x = crop_size - length_x \n",
    "            del_y = crop_size - length_y \n",
    "\n",
    "            if del_x%2==0:\n",
    "                kx = del_x//2\n",
    "                sx=0\n",
    "            else:\n",
    "                kx = del_x//2\n",
    "\n",
    "                sx = 1\n",
    "            if del_y%2==0:\n",
    "                ky = del_y//2\n",
    "                sy=0\n",
    "            else:\n",
    "                ky = del_y//2\n",
    "                sy = 1\n",
    "            crop = mask[ y_min - ky - sy : y_max + ky + 1, x_min - kx - sx : x_max + kx  + 1]\n",
    "            crop_im = im[ y_min - ky - sy : y_max + ky + 1, x_min - kx - sx : x_max + kx  + 1]\n",
    "            return crop_im, crop, \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N3h1lZMG6U7r"
   },
   "outputs": [],
   "source": [
    "crop_size = 192\n",
    "p_seg = []\n",
    "p_im = []\n",
    "for i, i1 in zip(segmentations, patients):\n",
    "    im = nib.load(os.path.join(samples, i1))    \n",
    "    im = np.array(im.dataobj)\n",
    "\n",
    "    Masks = nib.load(os.path.join(labels, i))    \n",
    "    Masks = np.array(Masks.dataobj)\n",
    "    Masks.shape\n",
    "    for  j in range(Masks.shape[2]):\n",
    "      k=make_box(Masks[:,:,j].astype(np.bool))\n",
    "      if len(k)!=0:\n",
    "        crop_im , crop = crop_specific(im[:,:,j], Masks[:,:,j], crop_size= crop_size)\n",
    "        p_seg.append(crop)\n",
    "        p_im.append(crop_im)\n",
    "\n",
    "\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IDUY2DLw6Dld"
   },
   "outputs": [],
   "source": [
    "segment_numpy = np.stack(p_seg,2)\n",
    "image_numpy = np.stack(p_im, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S_mcwDyL6Dld"
   },
   "outputs": [],
   "source": [
    "train = image_numpy/image_numpy.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oLji_MDe6Dle"
   },
   "outputs": [],
   "source": [
    "tra  = np.transpose(train,(2,0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "77vNW0js6Dle"
   },
   "outputs": [],
   "source": [
    "seg = np.transpose(segment_numpy,(2,0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PftZTqrl6Dle"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ANu52n8z6Dlj"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H6C8awsS6Dlj"
   },
   "outputs": [],
   "source": [
    "img_size = (crop_size, crop_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0FgtbWU36Dlj",
    "outputId": "8e269a2f-a4a0-41f8-9d9e-f0bc69272a25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 160, 160, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 80, 80, 32)   320         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 80, 80, 32)   128         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 80, 80, 32)   0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 80, 80, 32)   0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d (SeparableConv (None, 80, 80, 64)   2400        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 80, 80, 64)   256         separable_conv2d[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 80, 80, 64)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_1 (SeparableCo (None, 80, 80, 64)   4736        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 80, 80, 64)   256         separable_conv2d_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 40, 40, 64)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 40, 40, 64)   2112        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 40, 40, 64)   0           max_pooling2d[0][0]              \n",
      "                                                                 conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 40, 40, 64)   0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2 (SeparableCo (None, 40, 40, 128)  8896        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 40, 40, 128)  512         separable_conv2d_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 40, 40, 128)  0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_3 (SeparableCo (None, 40, 40, 128)  17664       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 40, 40, 128)  512         separable_conv2d_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 20, 20, 128)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 20, 20, 128)  8320        add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 20, 20, 128)  0           max_pooling2d_1[0][0]            \n",
      "                                                                 conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 20, 20, 128)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_4 (SeparableCo (None, 20, 20, 256)  34176       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 20, 20, 256)  1024        separable_conv2d_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 20, 20, 256)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_5 (SeparableCo (None, 20, 20, 256)  68096       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 20, 20, 256)  1024        separable_conv2d_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 10, 10, 256)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 10, 10, 256)  33024       add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 10, 10, 256)  0           max_pooling2d_2[0][0]            \n",
      "                                                                 conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 10, 10, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose (Conv2DTranspo (None, 10, 10, 256)  590080      activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 10, 10, 256)  1024        conv2d_transpose[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 10, 10, 256)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 10, 10, 256)  590080      activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 10, 10, 256)  1024        conv2d_transpose_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 20, 20, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d (UpSampling2D)    (None, 20, 20, 256)  0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 20, 20, 256)  65792       up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 20, 20, 256)  0           up_sampling2d[0][0]              \n",
      "                                                                 conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 20, 20, 256)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 20, 20, 128)  295040      activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 20, 20, 128)  512         conv2d_transpose_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 20, 20, 128)  0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 20, 20, 128)  147584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 20, 20, 128)  512         conv2d_transpose_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 40, 40, 256)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 40, 40, 128)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 40, 40, 128)  32896       up_sampling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 40, 40, 128)  0           up_sampling2d_2[0][0]            \n",
      "                                                                 conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 40, 40, 128)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTrans (None, 40, 40, 64)   73792       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 40, 40, 64)   256         conv2d_transpose_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 40, 40, 64)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTrans (None, 40, 40, 64)   36928       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 40, 40, 64)   256         conv2d_transpose_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 80, 80, 128)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 80, 80, 64)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 80, 80, 64)   8256        up_sampling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 80, 80, 64)   0           up_sampling2d_4[0][0]            \n",
      "                                                                 conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 80, 80, 64)   0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTrans (None, 80, 80, 32)   18464       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 80, 80, 32)   128         conv2d_transpose_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 80, 80, 32)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_7 (Conv2DTrans (None, 80, 80, 32)   9248        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 80, 80, 32)   128         conv2d_transpose_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_7 (UpSampling2D)  (None, 160, 160, 64) 0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_6 (UpSampling2D)  (None, 160, 160, 32) 0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 160, 160, 32) 2080        up_sampling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 160, 160, 32) 0           up_sampling2d_6[0][0]            \n",
      "                                                                 conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 160, 160, 3)  867         add_6[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 2,058,403\n",
      "Trainable params: 2,054,627\n",
      "Non-trainable params: 3,776\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def get_model(img_size, num_classes):\n",
    "    inputs = keras.Input(shape=img_size + (1,))\n",
    "\n",
    "    ### [First half of the network: downsampling inputs] ###\n",
    "\n",
    "    # Entry block\n",
    "    x = layers.Conv2D(32, 3, strides=2, padding=\"same\")(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    previous_block_activation = x  # Set aside residual\n",
    "\n",
    "    # Blocks 1, 2, 3 are identical apart from the feature depth.\n",
    "    for filters in [64, 128, 256]:\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "\n",
    "        # Project residual\n",
    "        residual = layers.Conv2D(filters, 1, strides=2, padding=\"same\")(\n",
    "            previous_block_activation\n",
    "        )\n",
    "        x = layers.add([x, residual])  # Add back residual\n",
    "        previous_block_activation = x  # Set aside next residual\n",
    "\n",
    "    ### [Second half of the network: upsampling inputs] ###\n",
    "\n",
    "    for filters in [256, 128, 64, 32]:\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.UpSampling2D(2)(x)\n",
    "\n",
    "        # Project residual\n",
    "        residual = layers.UpSampling2D(2)(previous_block_activation)\n",
    "        residual = layers.Conv2D(filters, 1, padding=\"same\")(residual)\n",
    "        x = layers.add([x, residual])  # Add back residual\n",
    "        previous_block_activation = x  # Set aside next residual\n",
    "\n",
    "    # Add a per-pixel classification layer\n",
    "    outputs = layers.Conv2D(num_classes, 3, activation=\"softmax\", padding=\"same\")(x)\n",
    "\n",
    "    # Define the model\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "# Free up RAM in case the model definition cells were run multiple times\n",
    "keras.backend.clear_session()\n",
    "\n",
    "# Build model\n",
    "model = get_model(img_size, 3)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z-iGbhyz6Dll"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LxhAdMrk6Dlm"
   },
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GndrAX_b6Dln"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "model.compile(optimizer=optimizer, loss=\"sparse_categorical_crossentropy\")\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"unet_seg.h5\", save_best_only=True)\n",
    "]\n",
    "\n",
    "epochs = 50\n",
    "model.fit(tra, seg, epochs=epochs, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dvgCH9Qg6Dlp"
   },
   "outputs": [],
   "source": [
    "\n",
    "def display_mask(i):\n",
    "    \"\"\"Quick utility to display a model's prediction.\"\"\"\n",
    "    mask = np.argmax(val_preds[i], axis=-1)\n",
    "    mask = np.expand_dims(mask, axis=-1)\n",
    "    img = PIL.ImageOps.autocontrast(keras.preprocessing.image.array_to_img(mask))\n",
    "    display(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QG7thh5H6Dlp"
   },
   "outputs": [],
   "source": [
    "pr = model.predict(tra[:670])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UwiFzQV-6Dlq"
   },
   "outputs": [],
   "source": [
    "mask1 = np.argmax(pr[20], axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tNbQGR5J6Dlq"
   },
   "outputs": [],
   "source": [
    "plt.imshow(mask1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gk433_XH6Dlq"
   },
   "outputs": [],
   "source": [
    "pr[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traditional Unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS = 192, 192, 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def U_Net_Segmentation(input_size=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)):\n",
    "    \n",
    "    inputs = Input(input_size)\n",
    "    n = Lambda(lambda x:x/255)(inputs)\n",
    "    \n",
    "    \n",
    "    c1 = Conv2D(16, (3,3), activation='relu', kernel_initializer='he_normal',\n",
    "                padding='same')(n)\n",
    "    c1 = Dropout(0.1)(c1)\n",
    "    c1 = Conv2D(16, (3,3), activation='relu', kernel_initializer='he_normal',\n",
    "                padding='same')(c1)\n",
    "    p1 = MaxPooling2D((2,2))(c1)\n",
    "\n",
    "\n",
    "    c2 = Conv2D(32, (3,3), activation='relu', kernel_initializer='he_normal',\n",
    "                padding='same')(p1)\n",
    "    c2 = Dropout(0.1)(c2)\n",
    "    c2 = Conv2D(32, (3,3), activation='relu', kernel_initializer='he_normal',\n",
    "                padding='same')(c2)\n",
    "    p2 = MaxPooling2D((2,2))(c2)\n",
    "\n",
    "\n",
    "    c3 = Conv2D(64, (3,3), activation='relu', kernel_initializer='he_normal',\n",
    "                padding='same')(p2)\n",
    "    c3 = Dropout(0.2)(c3)\n",
    "    c3 = Conv2D(64, (3,3), activation='relu', kernel_initializer='he_normal',\n",
    "                padding='same')(c3)\n",
    "    p3 = MaxPooling2D((2,2))(c3)\n",
    "\n",
    "\n",
    "    c4 = Conv2D(128, (3,3), activation='relu', kernel_initializer='he_normal',\n",
    "                padding='same')(p3)\n",
    "    c4 = Dropout(0.2)(c4)\n",
    "    c4 = Conv2D(128, (3,3), activation='relu', kernel_initializer='he_normal',\n",
    "                padding='same')(c4)\n",
    "    p4 = MaxPooling2D((2,2))(c4)\n",
    "\n",
    "\n",
    "    c5 = Conv2D(256, (3,3), activation='relu', kernel_initializer='he_normal',\n",
    "                padding='same')(p4)\n",
    "    c5 = Dropout(0.3)(c5)\n",
    "    c5 = Conv2D(256, (3,3), activation='relu', kernel_initializer='he_normal',\n",
    "                padding='same')(c5)\n",
    "\n",
    "\n",
    "\n",
    "    u6 = Conv2DTranspose(128, (2,2), strides=(2,2), padding='same')(c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    c6 = Conv2D(128, (3,3), activation='relu', kernel_initializer='he_normal',\n",
    "                padding='same')(u6)\n",
    "    c6 = Dropout(0.2)(c6)\n",
    "    c6 = Conv2D(128, (3,3), activation='relu', kernel_initializer='he_normal',\n",
    "                padding='same')(c6)   \n",
    "\n",
    "\n",
    "    u7 = Conv2DTranspose(64, (2,2), strides=(2,2), padding='same')(c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    c7 = Conv2D(64, (3,3), activation='relu', kernel_initializer='he_normal',\n",
    "                padding='same')(u7)\n",
    "    c7 = Dropout(0.2)(c7)\n",
    "    c7 = Conv2D(64, (3,3), activation='relu', kernel_initializer='he_normal',\n",
    "                padding='same')(c7) \n",
    "\n",
    "    u8 = Conv2DTranspose(32, (2,2), strides=(2,2), padding='same')(c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    c8 = Conv2D(32, (3,3), activation='relu', kernel_initializer='he_normal',\n",
    "                padding='same')(u8)\n",
    "    c8 = Dropout(0.1)(c8)\n",
    "    c8 = Conv2D(32, (3,3), activation='relu', kernel_initializer='he_normal',\n",
    "                padding='same')(c8) \n",
    "    \n",
    "    \n",
    "    u9 = Conv2DTranspose(16, (2,2), strides=(2,2), padding='same')(c8)\n",
    "    u9 = concatenate([u9, c1], axis = 3)\n",
    "    c9 = Conv2D(16, (3,3), activation='relu', kernel_initializer='he_normal',\n",
    "                padding='same')(u9)\n",
    "    c9 = Dropout(0.1)(c9)\n",
    "    c9 = Conv2D(16, (3,3), activation='relu', kernel_initializer='he_normal',\n",
    "                padding='same')(c9) \n",
    "    \n",
    "    outputs = Conv2D(3,(1,1), activation=\"softmax\",)(c9)\n",
    "    \n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    model.compile(optimizer='adam', loss=\"sparse_categorical_crossentropy\"\n",
    "                 )\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = U_Net_Segmentation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.fit(tra, seg,\n",
    "                    shuffle = True, \n",
    "                    validation_split=0.1, \n",
    "                    batch_size=2,\n",
    "                    epochs=50)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "Copy of Untitled1.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
