{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Untitled1.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/qazalmehrban/Medical-Segmentation/blob/ghazal/Unet_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJeS1cyb1W6E"
      },
      "source": [
        "import numpy as np\n",
        "import nibabel as nib\n",
        "import os \n",
        "import glob\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from skimage.transform import resize\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrCxsKNFlhqX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f61a5fa6-72c6-4352-e898-afbe404d6129"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-zMk0jg6Dla"
      },
      "source": [
        "samples = '/content/drive/MyDrive/samples/'\n",
        "labels = '/content/drive/MyDrive/segmentation/'\n",
        "mix = '/content/drive/MyDrive/New folder/'\n",
        "#patients = next(os.walk(samples))[2]\n",
        "\n",
        "#segmentations =next(os.walk(labels))[2]\n"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "un4n53f0NGXh"
      },
      "source": [
        "#patients_object = os.scandir(samples)\n",
        "#patients_list = [i.path for i in patients_object]\n",
        "patients_list = glob.glob(mix + '*[0-9].*')\n",
        "patients_list.sort()\n",
        "\n",
        "#segment_object = os.scandir(labels)\n",
        "#segment_list = [i.path for i in segment_object]\n",
        "segment_list = glob.glob(mix + '*n.*')\n",
        "segment_list.sort()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEEHHdWWOBuV",
        "outputId": "a304b3c8-bfdb-49e1-d057-05006025ca61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "source": [
        "len(segment_list)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-2c562eefd82f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegment_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'segment_list' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61Sk_JxNOBw9"
      },
      "source": [
        "def slice_label(masks):\n",
        "\n",
        "  l0 = []\n",
        "  l1_0 =[]\n",
        "  l2_0 = []\n",
        "  l2_1_0 = []\n",
        "  for i in range(masks.shape[-1]):\n",
        "    uni = np.unique(masks[:,:,i])\n",
        "\n",
        "    if len(uni) ==1:\n",
        "      l0.append(i)\n",
        "    elif (0 in uni) and (1 in uni) and not (2 in uni):\n",
        "      l1_0.append(i)\n",
        "    elif (0 in uni) and (2 in uni) and not (1 in uni):\n",
        "      l2_0.append(i)\n",
        "    else :\n",
        "      l2_1_0.append(i)\n",
        "  return {'label_0':l0, 'label_1_0':l1_0,'label_2_0': l2_0, 'label_2_1_0': l2_1_0}"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqv_R470OBzp",
        "outputId": "96349939-05d9-47de-bfdd-d62f7c2e90ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "m = nib.load(segment_list[70])\n",
        "m=np.array(m.dataobj)\n",
        "slice_label(m)"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'label_0': [0],\n",
              " 'label_1_0': [],\n",
              " 'label_2_0': [1, 2, 3, 4, 13, 14, 15, 16, 17, 18, 19],\n",
              " 'label_2_1_0': [5, 6, 7, 8, 9, 10, 11, 12]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8PazLG7T1T0"
      },
      "source": [
        "unique, counts = np.unique(m[:,:,12], return_counts=True)\n"
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDdjPEORUHlt",
        "outputId": "3e01eebf-1aab-4b84-9449-ec4dfc018bd0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "unique"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1., 2.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P314gEfHUIxA",
        "outputId": "a063cad8-2145-40d0-c9e4-8df5a9abdd42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "counts"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([139939,    677,   6840])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gn8_6BisS7Yp",
        "outputId": "945408dc-fce8-4c16-bc22-a361c2b28239",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "plt.imshow(m[:,:,13])"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f09a9248450>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7wD80aZR_Y8"
      },
      "source": [
        "test = []\n",
        "for i in segment_list:\n",
        "  m = nib.load(i)\n",
        "  m=np.array(m.dataobj)\n",
        "  j = slice_label(m)\n",
        "  test.extend(j['label_1_0'])\n",
        "\n"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mxfrzbMR_bS",
        "outputId": "3930dcc8-30ce-413e-d2cb-60dfef408f84",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "test"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[7,\n",
              " 8,\n",
              " 9,\n",
              " 10,\n",
              " 11,\n",
              " 12,\n",
              " 13,\n",
              " 14,\n",
              " 15,\n",
              " 16,\n",
              " 17,\n",
              " 18,\n",
              " 19,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 4,\n",
              " 5,\n",
              " 6,\n",
              " 7,\n",
              " 8,\n",
              " 9,\n",
              " 10,\n",
              " 11,\n",
              " 12,\n",
              " 13,\n",
              " 2,\n",
              " 3,\n",
              " 4,\n",
              " 5,\n",
              " 6,\n",
              " 7,\n",
              " 8,\n",
              " 9,\n",
              " 10,\n",
              " 11,\n",
              " 12,\n",
              " 13,\n",
              " 14,\n",
              " 15,\n",
              " 16,\n",
              " 17,\n",
              " 6,\n",
              " 7,\n",
              " 8,\n",
              " 9,\n",
              " 10,\n",
              " 11,\n",
              " 12,\n",
              " 13,\n",
              " 14,\n",
              " 15,\n",
              " 16,\n",
              " 17,\n",
              " 18,\n",
              " 6,\n",
              " 7,\n",
              " 8,\n",
              " 9,\n",
              " 10,\n",
              " 11,\n",
              " 12,\n",
              " 13,\n",
              " 14,\n",
              " 15,\n",
              " 16,\n",
              " 17,\n",
              " 18,\n",
              " 9,\n",
              " 10,\n",
              " 11,\n",
              " 12,\n",
              " 13,\n",
              " 14,\n",
              " 15,\n",
              " 16,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 4,\n",
              " 5,\n",
              " 6,\n",
              " 7,\n",
              " 8,\n",
              " 9,\n",
              " 10,\n",
              " 11,\n",
              " 12,\n",
              " 13,\n",
              " 14,\n",
              " 15,\n",
              " 16,\n",
              " 4,\n",
              " 5,\n",
              " 6,\n",
              " 7,\n",
              " 8,\n",
              " 9,\n",
              " 10,\n",
              " 11,\n",
              " 12,\n",
              " 13,\n",
              " 14,\n",
              " 15,\n",
              " 16,\n",
              " 17,\n",
              " 4,\n",
              " 5,\n",
              " 6,\n",
              " 7,\n",
              " 8,\n",
              " 9,\n",
              " 10,\n",
              " 11,\n",
              " 12,\n",
              " 13,\n",
              " 14,\n",
              " 15,\n",
              " 16,\n",
              " 3,\n",
              " 4,\n",
              " 5,\n",
              " 6,\n",
              " 7,\n",
              " 8,\n",
              " 9,\n",
              " 10,\n",
              " 11,\n",
              " 12,\n",
              " 13,\n",
              " 14,\n",
              " 15,\n",
              " 16,\n",
              " 17,\n",
              " 2,\n",
              " 3,\n",
              " 4,\n",
              " 5,\n",
              " 6,\n",
              " 7,\n",
              " 8,\n",
              " 9,\n",
              " 10,\n",
              " 11,\n",
              " 12,\n",
              " 13,\n",
              " 14,\n",
              " 15,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 4,\n",
              " 5,\n",
              " 6,\n",
              " 7,\n",
              " 8,\n",
              " 9,\n",
              " 10,\n",
              " 11,\n",
              " 12,\n",
              " 13,\n",
              " 14,\n",
              " 15,\n",
              " 16,\n",
              " 17,\n",
              " 18,\n",
              " 19,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 4,\n",
              " 5,\n",
              " 6,\n",
              " 7,\n",
              " 8,\n",
              " 9,\n",
              " 10,\n",
              " 11,\n",
              " 12,\n",
              " 13,\n",
              " 14,\n",
              " 15,\n",
              " 16,\n",
              " 17,\n",
              " 5,\n",
              " 6,\n",
              " 7,\n",
              " 8,\n",
              " 9,\n",
              " 10,\n",
              " 11,\n",
              " 12,\n",
              " 13,\n",
              " 14,\n",
              " 15,\n",
              " 16,\n",
              " 17,\n",
              " 18,\n",
              " 19,\n",
              " 20,\n",
              " 6,\n",
              " 7,\n",
              " 8,\n",
              " 9,\n",
              " 10,\n",
              " 11,\n",
              " 12,\n",
              " 13,\n",
              " 14,\n",
              " 15,\n",
              " 16,\n",
              " 17,\n",
              " 5,\n",
              " 6,\n",
              " 7,\n",
              " 8,\n",
              " 9,\n",
              " 10,\n",
              " 11,\n",
              " 12,\n",
              " 13,\n",
              " 14,\n",
              " 15,\n",
              " 16,\n",
              " 17,\n",
              " 18,\n",
              " 2,\n",
              " 3,\n",
              " 4,\n",
              " 5,\n",
              " 6,\n",
              " 7,\n",
              " 8,\n",
              " 9,\n",
              " 10,\n",
              " 11,\n",
              " 12,\n",
              " 13,\n",
              " 14,\n",
              " 15,\n",
              " 16,\n",
              " 17,\n",
              " 5,\n",
              " 6,\n",
              " 7,\n",
              " 8,\n",
              " 9,\n",
              " 10,\n",
              " 11,\n",
              " 12,\n",
              " 13,\n",
              " 14,\n",
              " 15,\n",
              " 16,\n",
              " 17,\n",
              " 3,\n",
              " 4,\n",
              " 5,\n",
              " 6,\n",
              " 7,\n",
              " 8,\n",
              " 9,\n",
              " 10,\n",
              " 11,\n",
              " 12,\n",
              " 13,\n",
              " 14,\n",
              " 15,\n",
              " 16,\n",
              " 17,\n",
              " 18,\n",
              " 19,\n",
              " 6,\n",
              " 7,\n",
              " 8,\n",
              " 9,\n",
              " 10,\n",
              " 11,\n",
              " 12,\n",
              " 13,\n",
              " 14,\n",
              " 15,\n",
              " 16,\n",
              " 5,\n",
              " 6,\n",
              " 7,\n",
              " 8,\n",
              " 9,\n",
              " 10,\n",
              " 11,\n",
              " 12,\n",
              " 13,\n",
              " 14,\n",
              " 15,\n",
              " 16,\n",
              " 17,\n",
              " 6,\n",
              " 7,\n",
              " 8,\n",
              " 9,\n",
              " 10,\n",
              " 11,\n",
              " 12,\n",
              " 13,\n",
              " 14,\n",
              " 15,\n",
              " 16,\n",
              " 5,\n",
              " 6,\n",
              " 7,\n",
              " 8,\n",
              " 9,\n",
              " 10,\n",
              " 11,\n",
              " 12,\n",
              " 13,\n",
              " 14,\n",
              " 15,\n",
              " 16,\n",
              " 17,\n",
              " 18,\n",
              " 4,\n",
              " 5,\n",
              " 6,\n",
              " 7,\n",
              " 8,\n",
              " 9,\n",
              " 10,\n",
              " 11,\n",
              " 12,\n",
              " 13,\n",
              " 14,\n",
              " 15,\n",
              " 5,\n",
              " 6,\n",
              " 7,\n",
              " 8,\n",
              " 9,\n",
              " 10,\n",
              " 11,\n",
              " 12,\n",
              " 13,\n",
              " 14,\n",
              " 15,\n",
              " 16,\n",
              " 17,\n",
              " 5,\n",
              " 6,\n",
              " 7,\n",
              " 8,\n",
              " 9,\n",
              " 10,\n",
              " 11,\n",
              " 12,\n",
              " 13,\n",
              " 14,\n",
              " 15,\n",
              " 16,\n",
              " 17,\n",
              " 18,\n",
              " 3,\n",
              " 4,\n",
              " 5,\n",
              " 6,\n",
              " 7,\n",
              " 8,\n",
              " 9,\n",
              " 10,\n",
              " 11,\n",
              " 12,\n",
              " 13,\n",
              " 14,\n",
              " 15,\n",
              " 16,\n",
              " 3,\n",
              " 4,\n",
              " 5,\n",
              " 6,\n",
              " 7,\n",
              " 8,\n",
              " 9,\n",
              " 10,\n",
              " 11,\n",
              " 12,\n",
              " 13,\n",
              " 14,\n",
              " 15,\n",
              " 16,\n",
              " 7,\n",
              " 8,\n",
              " 9,\n",
              " 10,\n",
              " 11,\n",
              " 12,\n",
              " 13,\n",
              " 14,\n",
              " 15,\n",
              " 16,\n",
              " 17,\n",
              " 2,\n",
              " 3,\n",
              " 4,\n",
              " 5,\n",
              " 6,\n",
              " 7,\n",
              " 8,\n",
              " 9,\n",
              " 10,\n",
              " 11,\n",
              " 12,\n",
              " 13,\n",
              " 14,\n",
              " 15,\n",
              " 16,\n",
              " 17,\n",
              " 18,\n",
              " 19,\n",
              " 20,\n",
              " 21,\n",
              " 22,\n",
              " 23,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 4,\n",
              " 5,\n",
              " 6,\n",
              " 7,\n",
              " 8,\n",
              " 9,\n",
              " 10,\n",
              " 11,\n",
              " 12,\n",
              " 13,\n",
              " 14,\n",
              " 5,\n",
              " 6,\n",
              " 7,\n",
              " 8,\n",
              " 9,\n",
              " 10,\n",
              " 11,\n",
              " 12,\n",
              " 13,\n",
              " 14,\n",
              " 15,\n",
              " 5,\n",
              " 6,\n",
              " 7,\n",
              " 8,\n",
              " 9,\n",
              " 10,\n",
              " 11,\n",
              " 12,\n",
              " 13,\n",
              " 14,\n",
              " 15,\n",
              " 6,\n",
              " 7,\n",
              " 8,\n",
              " 9,\n",
              " 10,\n",
              " 11,\n",
              " 12,\n",
              " 13,\n",
              " 14,\n",
              " 15,\n",
              " 16,\n",
              " 6,\n",
              " 7,\n",
              " 8,\n",
              " 9,\n",
              " 10,\n",
              " 11,\n",
              " 12,\n",
              " 13,\n",
              " 14,\n",
              " 15,\n",
              " 16,\n",
              " 17,\n",
              " 7,\n",
              " 8,\n",
              " 9,\n",
              " 10,\n",
              " 11,\n",
              " 12,\n",
              " 13,\n",
              " 14,\n",
              " 15,\n",
              " 16,\n",
              " 17,\n",
              " 18,\n",
              " 19,\n",
              " 4,\n",
              " 5,\n",
              " 6,\n",
              " 7,\n",
              " 8,\n",
              " 9,\n",
              " 10,\n",
              " 11,\n",
              " 12,\n",
              " 13,\n",
              " 14,\n",
              " 6,\n",
              " 7,\n",
              " 8,\n",
              " 7,\n",
              " 8,\n",
              " 9,\n",
              " 7]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ImcID8COB2W",
        "outputId": "d7c9098d-ffb5-4829-8466-7505c30607bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "slice_label(m)"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'label_0': [0,\n",
              "  1,\n",
              "  2,\n",
              "  3,\n",
              "  4,\n",
              "  5,\n",
              "  6,\n",
              "  7,\n",
              "  21,\n",
              "  22,\n",
              "  23,\n",
              "  24,\n",
              "  25,\n",
              "  26,\n",
              "  27,\n",
              "  28,\n",
              "  29,\n",
              "  30,\n",
              "  31],\n",
              " 'label_1_0': [],\n",
              " 'label_2_0': [8, 20],\n",
              " 'label_2_1_0': [9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDxVO418R2qH"
      },
      "source": [
        "k=[]\n",
        "k.extend([])"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7v6iNeQR73-",
        "outputId": "21fda299-c061-4503-8e90-c7ace88668b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "k"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_747rKG6Dlb"
      },
      "source": [
        "\"def make_box(mask):\n",
        "    '''\n",
        "    this function return dict object contain bounding box of each pixel label and bbox of true value in bolean array\n",
        "    '''\n",
        "    box = []\n",
        "    box_bool=[]\n",
        "    obj_ids = np.unique(mask)\n",
        "    if mask.dtype == bool:\n",
        "        if len(np.unique(mask))==2:\n",
        "            \n",
        "            y_min = np.nonzero(mask)[0].min()\n",
        "            y_max = np.nonzero(mask)[0].max()\n",
        "            x_min = np.nonzero(mask)[1].min()\n",
        "            x_max = np.nonzero(mask)[1].max()\n",
        "            box=[x_min, y_min, x_max, y_max]\n",
        "    else :\n",
        "        mask_bool = mask.astype(np.bool)\n",
        "        if len(np.unique(mask_bool))==2:\n",
        "            \n",
        "            y_min = np.nonzero(mask_bool)[0].min()\n",
        "            y_max = np.nonzero(mask_bool)[0].max()\n",
        "            x_min = np.nonzero(mask_bool)[1].min()\n",
        "            x_max = np.nonzero(mask_bool)[1].max()\n",
        "            box_bool=[x_min, y_min, x_max, y_max]\n",
        "        \n",
        "        for i in  obj_ids[1:]:\n",
        "            y_min = np.nonzero(mask==i)[0].min()\n",
        "            y_max = np.nonzero(mask==i)[0].max()\n",
        "            x_min = np.nonzero(mask==i)[1].min()\n",
        "            x_max = np.nonzero(mask==i)[1].max()\n",
        "            box.append([x_min, y_min, x_max, y_max])\n",
        "    return_object = {'bbox_bool': box} if mask.dtype ==bool else {'bbox_label': dict(zip([f\"label{int(i)}\" for i in obj_ids[1:]],box)), 'bbox_bool' : box_bool}\n",
        "    return return_object"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECG9I6T4JN1e"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iv1RZR4pS8d"
      },
      "source": [
        "def bounding_box_plot(Masks_2d):\n",
        "  \n",
        "  print(f'labels_slice_{slices}', np.unique(Masks_2d))\n",
        "  print('bounding_box', make_box(Masks_2d.astype(bool)))\n",
        "\n",
        "  fig=px.imshow(Masks_2d)\n",
        "\n",
        "  li = make_box(Masks_2d.astype(bool))\n",
        "\n",
        "  k = dict(x0= li[0], x1= li[2], y0= li[1], y1= li[3])\n",
        "  fig.add_shape(\n",
        "    type='rect',\n",
        "    **k,\n",
        "    xref='x', yref='y',\n",
        "    line_color='cyan'\n",
        "  )\n",
        "  fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1TUX6dj6U4z"
      },
      "source": [
        "def crop_specific(im, mask, crop_size):\n",
        "        \n",
        "        k=make_box(mask.astype(np.bool))\n",
        "        if len(k['bbox_bool'])!=0:\n",
        "            b_list = k['bbox_bool']\n",
        "            x_min, y_min, x_max, y_max = b_list\n",
        "            \n",
        "            length_x = x_max -x_min + 1\n",
        "            length_y = y_max - y_min + 1\n",
        "            del_x = crop_size - length_x \n",
        "            del_y = crop_size - length_y \n",
        "\n",
        "            if del_x%2==0:\n",
        "                kx = del_x//2\n",
        "                sx=0\n",
        "            else:\n",
        "                kx = del_x//2\n",
        "\n",
        "                sx = 1\n",
        "            if del_y%2==0:\n",
        "                ky = del_y//2\n",
        "                sy=0\n",
        "            else:\n",
        "                ky = del_y//2\n",
        "                sy = 1\n",
        "            \n",
        "            crop = mask[ y_min - ky - sy : y_max + ky + 1, x_min - kx - sx : x_max + kx  + 1]\n",
        "            crop_im = im[ y_min - ky - sy : y_max + ky + 1, x_min - kx - sx : x_max + kx  + 1]\n",
        "            return crop_im, crop, \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3h1lZMG6U7r"
      },
      "source": [
        "crop_size = 192\n",
        "p_seg = []\n",
        "p_im = []\n",
        "for patient_file, segment_file in zip( patients_list[:60], segment_list[:60]):\n",
        "    im = nib.load(patient_file)    \n",
        "    im = np.array(im.dataobj)\n",
        "\n",
        "    Masks = nib.load(segment_file)    \n",
        "    Masks = np.array(Masks.dataobj)\n",
        "    Masks.shape\n",
        "    for  j in range(Masks.shape[2]):\n",
        "      k=make_box(Masks[:,:,j].astype(np.bool))\n",
        "      if len(k['bbox_bool'])!=0:\n",
        "        crop_im , crop = crop_specific(im[:,:,j], Masks[:,:,j], crop_size= crop_size)\n",
        "        p_seg.append(crop)\n",
        "        p_im.append(crop_im)\n",
        "\n",
        "\n",
        "    \n",
        "   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQrg3Z4cad1j"
      },
      "source": [
        "crop_size = 192\n",
        "p_seg_t = []\n",
        "p_im_t = []\n",
        "for patient_file, segment_file in zip( patients_list[60:], segment_list[60:]):\n",
        "    im = nib.load(patient_file)    \n",
        "    im = np.array(im.dataobj)\n",
        "\n",
        "    Masks = nib.load(segment_file)    \n",
        "    Masks = np.array(Masks.dataobj)\n",
        "    Masks.shape\n",
        "    for  j in range(Masks.shape[2]):\n",
        "      k=make_box(Masks[:,:,j].astype(np.bool))\n",
        "      if len(k['bbox_bool'])!=0:\n",
        "        crop_im , crop = crop_specific(im[:,:,j], Masks[:,:,j], crop_size= crop_size)\n",
        "        p_seg_t.append(crop)\n",
        "        p_im_t.append(crop_im)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDUY2DLw6Dld"
      },
      "source": [
        "segment_numpy = np.stack(p_seg,0)\n",
        "image_numpy = np.stack(p_im, 0)\n",
        "\n",
        "segment_numpy_t = np.stack(p_seg_t,0)\n",
        "image_numpy_t = np.stack(p_im_t, 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_mcwDyL6Dld"
      },
      "source": [
        "train = image_numpy/image_numpy.max()\n",
        "test = image_numpy_t/image_numpy.max()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PftZTqrl6Dle"
      },
      "source": [
        "train_seg_bolean = segment_numpy.astype(bool)\n",
        "test_seg_bolean = segment_numpy_t.astype(bool)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fiHgm90TbbG"
      },
      "source": [
        "test_seg_f = np.float32(test_seg_bolean)\n",
        "train_seg_f = np.float32(train_seg_bolean)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejmgY4FAojSc"
      },
      "source": [
        "# Pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rxoyUEtpmKL"
      },
      "source": [
        "train_image_torch = np.expand_dims(train,1)\n",
        "train_seg_torch  = np.expand_dims(train_seg_f,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODZSxdP-omWt"
      },
      "source": [
        "def conv3x3_bn_relu(inp_activation, output_activation, BN=True, activation = True):\n",
        "    \"con 3x3 + Batchnormalization + relu\"\n",
        "    layer = [nn.Conv2d(inp_activation, output_activation, 3, padding = 1)]\n",
        "    for i, j in zip([nn.BatchNorm2d(output_activation), nn.ReLU(inplace=True)],[BN, activation]):\n",
        "        if j==True:\n",
        "            layer.append(i)\n",
        "    return nn.Sequential(*layer)\n",
        "    \n",
        "    \n",
        "    \n",
        "class conv_block(nn.Module):\n",
        "    \n",
        "    def __init__(self, inp_activation, list_filter, BN = False):\n",
        "        super().__init__()\n",
        "        self.conv3x3_1 = conv3x3_bn_relu(inp_activation, list_filter, BN=BN)\n",
        "        self.conv3x3_2 = conv3x3_bn_relu(list_filter, list_filter, BN=BN)\n",
        "    def forward(self , inp):\n",
        "        c = self.conv3x3_1(inp)\n",
        "        c = self.conv3x3_2(c)\n",
        "        return c\n",
        "        \n",
        "class Unet(nn.Module):\n",
        "    def __init__(self, n_class):\n",
        "        \n",
        "        super().__init__()\n",
        "        self.en_block1 = conv_block(1,32)\n",
        "        self.en_block2 = conv_block(32,64)\n",
        "        self.en_block3 = conv_block(64,128)\n",
        "        self.en_block4 = conv_block(128,256)\n",
        "        self.en_block5 = conv_block(256,512)\n",
        "        self.en_block6 = conv_block(512, 1024)\n",
        "\n",
        "        \n",
        "        self.transpose5 = nn.ConvTranspose2d(1024,512,2,2)\n",
        "        self.transpose4 = nn.ConvTranspose2d(512,256,2,2)\n",
        "\n",
        "        self.transpose3 = nn.ConvTranspose2d(256,128,2,2)\n",
        "        self.transpose2 = nn.ConvTranspose2d(128,64,2,2)\n",
        "        self.transpose1 = nn.ConvTranspose2d(64,32,2,2)\n",
        "        \n",
        "        self.de_block1 = conv_block(64,32)\n",
        "        self.de_block2 = conv_block(128,64)\n",
        "        self.de_block3 = conv_block(256,128)\n",
        "\n",
        "        self.de_block4 = conv_block(512, 256)\n",
        "        self.de_block5 = conv_block(1024, 512)\n",
        "        self.out_conv = nn.Conv2d(32, 1, 1)\n",
        "\n",
        "        \n",
        "    \n",
        "\n",
        "    def forward(self, inp):\n",
        "        el1 = self.en_block1(inp) #  (32,h,w)\n",
        "        #print('el1',el1.shape)\n",
        "        max1 = nn.MaxPool2d(2)(el1) # (32,h//2, w//2)\n",
        "        #print('max1',max1.shape)\n",
        "\n",
        "        el2 = self.en_block2(max1)    #(64, h//2, w//2)\n",
        "        #print('el2',el2.shape)\n",
        "\n",
        "        max2 = nn.MaxPool2d(2)(el2)  #(64, h//4, w//4)\n",
        "        #print('max2',max2.shape)\n",
        "\n",
        "        el3 = self.en_block3(max2)    #(128, h//4, w//4)\n",
        "        #print('el3',el3.shape)\n",
        "\n",
        "        max3 = nn.MaxPool2d(2)(el3)  #(128, h//8, w//8)\n",
        "        #print('max3',max3.shape)\n",
        "\n",
        "\n",
        "        el4 = self.en_block4(max3)    #(256, h//8, w//8)\n",
        "        #print('el4',el4.shape)\n",
        "\n",
        "        max4 = nn.MaxPool2d(2)(el4)  #(256, h//16, w//16)\n",
        "        #print('max4',max4.shape)\n",
        "\n",
        "        el5 = self.en_block5(max4)  #(512, h//16, w//16)\n",
        "        #print('el5',el5.shape)\n",
        "\n",
        "        max5 = nn.MaxPool2d(2)(el5)  #(512, h//32, w//32)\n",
        "        #print('max5',max5.shape)\n",
        "\n",
        "        \n",
        "        el6 = self.en_block6(max5)  #(1024, h//32, w//32)\n",
        "        #print('el6',el6.shape)\n",
        "\n",
        "\n",
        "        tl5 = self.transpose5(el6)  #(512, h//16, w//16)\n",
        "        #print('tl5',tl5.shape)\n",
        "\n",
        "        cat5 = torch.cat([tl5, el5], 1) #(1024, h//16, h//16 )\n",
        "        #print('cat5',cat5.shape)\n",
        "\n",
        "        d5 =  self.de_block5(cat5)      #(512, h//16, w//16\n",
        "        #print('d5',d5.shape)\n",
        "\n",
        "        \n",
        "        tl4 = self.transpose4(d5)       #(256, h//8, w//8)\n",
        "        cat4 = torch.cat([tl4, el4], 1) #(512, h//8, w//8)\n",
        "        d4 =  self.de_block4(cat4)     #(256, h//8, w//8)\n",
        "        \n",
        "        tl3 = self.transpose3(d4)        #(128, h//4, w//4)\n",
        "        cat3 = torch.cat([tl3, el3], 1)  #(256, h//4, w//4)\n",
        "        d3 =  self.de_block3(cat3)        #(128, h//4, w//4)\n",
        "        \n",
        "        \n",
        "        tl2 = self.transpose2(d3)          #(64, h//2, w//2)\n",
        "        cat2 = torch.cat([tl2, el2], 1)   #(128, h//2, w//2)\n",
        "        d2 =  self.de_block2(cat2)         #(64, h//2, w//2)\n",
        "        \n",
        "        tl1 = self.transpose1(d2)          #(32, h, w)\n",
        "        cat1 = torch.cat([tl1, el1], 1) #(64, h, w)\n",
        "        d1 =  self.de_block1(cat1)        #(32, h, w)\n",
        "        output = self.out_conv(d1) \n",
        "\n",
        "        return output\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVa5_ABxomZA"
      },
      "source": [
        "m = Unet(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjAqSjH3afAY"
      },
      "source": [
        "X = torch.rand(4,1,192,192)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFMO4LZh0i1k"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzRz9ZnHafCx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ff62123-3c73-4c52-e504-a1538641e107"
      },
      "source": [
        "m(X.to(device)).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 1, 192, 192])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgkKIAeyafFC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-n2VxIr2afHb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqhsugxLafJ_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wROsnyqJRERc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ed5ffa5-eb73-454f-8eb3-aa136c88d614"
      },
      "source": [
        "m.to(torch.device('cuda'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Unet(\n",
              "  (en_block1): conv_block(\n",
              "    (conv3x3_1): Sequential(\n",
              "      (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): ReLU(inplace=True)\n",
              "    )\n",
              "    (conv3x3_2): Sequential(\n",
              "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (en_block2): conv_block(\n",
              "    (conv3x3_1): Sequential(\n",
              "      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): ReLU(inplace=True)\n",
              "    )\n",
              "    (conv3x3_2): Sequential(\n",
              "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (en_block3): conv_block(\n",
              "    (conv3x3_1): Sequential(\n",
              "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): ReLU(inplace=True)\n",
              "    )\n",
              "    (conv3x3_2): Sequential(\n",
              "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (en_block4): conv_block(\n",
              "    (conv3x3_1): Sequential(\n",
              "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): ReLU(inplace=True)\n",
              "    )\n",
              "    (conv3x3_2): Sequential(\n",
              "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (en_block5): conv_block(\n",
              "    (conv3x3_1): Sequential(\n",
              "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): ReLU(inplace=True)\n",
              "    )\n",
              "    (conv3x3_2): Sequential(\n",
              "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (en_block6): conv_block(\n",
              "    (conv3x3_1): Sequential(\n",
              "      (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): ReLU(inplace=True)\n",
              "    )\n",
              "    (conv3x3_2): Sequential(\n",
              "      (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (transpose5): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n",
              "  (transpose4): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
              "  (transpose3): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
              "  (transpose2): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
              "  (transpose1): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))\n",
              "  (de_block1): conv_block(\n",
              "    (conv3x3_1): Sequential(\n",
              "      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): ReLU(inplace=True)\n",
              "    )\n",
              "    (conv3x3_2): Sequential(\n",
              "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (de_block2): conv_block(\n",
              "    (conv3x3_1): Sequential(\n",
              "      (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): ReLU(inplace=True)\n",
              "    )\n",
              "    (conv3x3_2): Sequential(\n",
              "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (de_block3): conv_block(\n",
              "    (conv3x3_1): Sequential(\n",
              "      (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): ReLU(inplace=True)\n",
              "    )\n",
              "    (conv3x3_2): Sequential(\n",
              "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (de_block4): conv_block(\n",
              "    (conv3x3_1): Sequential(\n",
              "      (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): ReLU(inplace=True)\n",
              "    )\n",
              "    (conv3x3_2): Sequential(\n",
              "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (de_block5): conv_block(\n",
              "    (conv3x3_1): Sequential(\n",
              "      (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): ReLU(inplace=True)\n",
              "    )\n",
              "    (conv3x3_2): Sequential(\n",
              "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (out_conv): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3uVtkvdo5R3"
      },
      "source": [
        "d_tr = torch.utils.data.DataLoader(train_image_torch,32)\n",
        "d_seg = torch.utils.data.DataLoader(train_seg_torch,32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpmNmtNoo5VP"
      },
      "source": [
        "device = torch.device('cuda')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMHst6GdRwWl"
      },
      "source": [
        "opt = torch.optim.Adam(m.parameters())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juKjnCuSR_53"
      },
      "source": [
        "loss = torch.nn.BCEWithLogitsLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8jctKgaq30l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfcbc412-a320-47c9-b9da-62e7e3a50c65"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxAp80mv1xuw"
      },
      "source": [
        "ep=30"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtvE06B4o5bg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "00e8094b-f4ae-4ec5-d1ca-c09cfc3415f3"
      },
      "source": [
        "for epoch in range(ep):\n",
        "  for im , segi in zip(d_tr, d_seg):\n",
        "    im = im.to(device=device)\n",
        "    segi =segi.to(device)\n",
        "    yh = m(im)\n",
        "    l = loss(yh, segi)\n",
        "    opt.zero_grad()\n",
        "    l.backward()\n",
        "    opt.step()\n",
        "  print(f\"epoch{epoch} loss is :\", l)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch30 loss is : tensor(0.5245, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "epoch30 loss is : tensor(0.5317, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "epoch30 loss is : tensor(0.5307, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "epoch30 loss is : tensor(0.5326, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-194242e18765>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mim\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0msegi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_seg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0msegi\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0msegi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0myh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGq2CgdbgKmk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e94d343-3505-4aa3-852e-7a0ea04b648b"
      },
      "source": [
        "torch.cuda.current_device()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgJM2fMjg-sd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "736de1fa-6905-449a-de7d-bff2045ce5ec"
      },
      "source": [
        "torch.cuda.is_available()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjTmUmKOhDiq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10afa6c8-95c1-41a5-c47d-224fd1e465fc"
      },
      "source": [
        "torch.cuda.device_count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXx7-kecQufp"
      },
      "source": [
        "# tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oswpYrSC_yyS"
      },
      "source": [
        "IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS  =crop_size, crop_size, 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11C8uTN4B-vx"
      },
      "source": [
        "def conv_block(channel, drop = None, l2 = True):\n",
        "  seq = keras.Sequential()\n",
        "  seq.add(layers.Conv2D(channel, (3,3), activation='relu',kernel_regularizer='l2', kernel_initializer='he_normal',\n",
        "                padding='same'))\n",
        "  if drop!= None:\n",
        "    seq.add(\n",
        "    layers.Dropout(drop))\n",
        "  seq.add(layers.Conv2D(channel, (3,3), activation='relu', kernel_initializer='he_normal',\n",
        "                padding='same'))\n",
        "    \n",
        "  return seq\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R64Qgwthibtq"
      },
      "source": [
        "def conv_block(channel, drop = None, l2 = True):\n",
        "  seq = keras.Sequential()\n",
        "  seq.add(layers.Conv2D(channel, (1,1), activation='relu',kernel_regularizer='l2', kernel_initializer='he_normal',\n",
        "                padding='same'))\n",
        "  if drop!= None:\n",
        "    seq.add(\n",
        "    layers.Dropout(drop))\n",
        "  seq.add(layers.Conv2D(channel, (3,3), activation='relu', kernel_initializer='he_normal',\n",
        "                padding='same'))\n",
        "  seq.add(layers.Conv2D(channel, (1,1), activation='relu', kernel_initializer='he_normal',\n",
        "                padding='same'))\n",
        "    \n",
        "  return seq\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqqSO_STlAuq"
      },
      "source": [
        "del conv_block"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWAxDkhxixV_"
      },
      "source": [
        "class conv_block(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self, channel, **kwargs):\n",
        "        super(conv_block, self).__init__(**kwargs)\n",
        "        self.c1x1 = layers.Conv2D(channel, (1,1), activation='relu', kernel_initializer='he_normal',\n",
        "                padding='same')\n",
        "        self.c3x3 = layers.Conv2D(channel, (3,3), activation='relu', kernel_initializer='he_normal',\n",
        "                padding='same')\n",
        "        self.c1x1_2 = layers.Conv2D(channel, (1,1), activation='relu', kernel_initializer='he_normal',\n",
        "                padding='same')\n",
        "        self.co =  layers.Conv2D(channel, (1,1), activation='relu', kernel_initializer='he_normal',\n",
        "                padding='same')\n",
        "\n",
        "\n",
        "  def call(self, inputs, training=None):\n",
        "    l1 = self.c1x1(inputs)\n",
        "    l1 = self.c3x3(l1)\n",
        "    l1 = self.c1x1_2(l1)\n",
        "    inp_mod = self.co(inputs)\n",
        "    out = l1 + inp_mod\n",
        "    return out\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5uMExEjkw47"
      },
      "source": [
        "j = conv_block(34)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dccobyPvMyHS"
      },
      "source": [
        "x = tf.random.normal((20, 39,39,7))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3CXhrnTM7Ar",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4b582ff-398b-42ca-9cd3-063d974041e4"
      },
      "source": [
        "j(x).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([20, 39, 39, 34])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HwKB9ujk2iL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSbqTxXRk2ke"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukefGLzYWZMd"
      },
      "source": [
        "def U_Net_Segmentation(input_size=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), drop = None, l2 = True):\n",
        "    \n",
        "    inputs = tf.keras.Input(input_size)\n",
        "    \n",
        "    \n",
        "    c1=conv_block(16, drop=drop, l2=l2)(inputs)\n",
        "    p1 = layers.MaxPooling2D((2,2))(c1)\n",
        "\n",
        "\n",
        "    c2 = conv_block(32, drop=drop, l2=l2)(p1)\n",
        "    p2 = layers.MaxPooling2D((2,2))(c2)\n",
        "\n",
        "\n",
        "    c3 = conv_block(64, drop=drop, l2=l2)(p2)\n",
        "    p3 = layers.MaxPooling2D((2,2))(c3)\n",
        "\n",
        "\n",
        "    c4 = conv_block(128, drop=drop, l2=l2)(p3)\n",
        "    p4 = layers.MaxPooling2D((2,2))(c4)\n",
        "\n",
        "\n",
        "    c5 = conv_block(256, drop=drop, l2=l2)(p4)\n",
        "    p5 = layers.MaxPooling2D((2,2))(c5)\n",
        "\n",
        "    c6 = conv_block(256, drop=drop, l2=l2)(p5)\n",
        "\n",
        "\n",
        "\n",
        "    u7 = layers.Conv2DTranspose(256, (2,2), strides=(2,2), padding='same')(c6)\n",
        "    u7 = layers.concatenate([u7, c5])\n",
        "    c7 = layers.Conv2D(256, (3,3), activation='relu', kernel_initializer='he_normal',\n",
        "                padding='same')(u7)\n",
        "\n",
        "    c7 = layers.Dropout(0.2)(c7)\n",
        "    c7 = layers.Conv2D(256, (3,3), activation='relu', kernel_initializer='he_normal',\n",
        "                padding='same')(c7)   \n",
        "\n",
        "    u6 = layers.Conv2DTranspose(128, (2,2), strides=(2,2), padding='same')(c5)\n",
        "    u6 = layers.concatenate([u6, c4])\n",
        "    c6 = layers.Conv2D(128, (3,3), activation='relu', kernel_initializer='he_normal',\n",
        "                padding='same')(u6)\n",
        "    c6 = layers.Dropout(0.2)(c6)\n",
        "    c6 = layers.Conv2D(128, (3,3), activation='relu', kernel_initializer='he_normal',\n",
        "                padding='same')(c6)   \n",
        "\n",
        "\n",
        "    u7 = layers.Conv2DTranspose(64, (2,2), strides=(2,2), padding='same')(c6)\n",
        "    u7 = layers.concatenate([u7, c3])\n",
        "    c7 = layers.Conv2D(64, (3,3), activation='relu', kernel_initializer='he_normal',\n",
        "                padding='same')(u7)\n",
        "    c7 = layers.Dropout(0.2)(c7)\n",
        "    c7 = layers.Conv2D(64, (3,3), activation='relu', kernel_initializer='he_normal',\n",
        "                padding='same')(c7) \n",
        "\n",
        "    u8 = layers.Conv2DTranspose(32, (2,2), strides=(2,2), padding='same')(c7)\n",
        "    u8 = layers.concatenate([u8, c2])\n",
        "    c8 = layers.Conv2D(32, (3,3), activation='relu', kernel_initializer='he_normal',\n",
        "                padding='same')(u8)\n",
        "    c8 = layers.Dropout(0.1)(c8)\n",
        "    c8 = layers.Conv2D(32, (3,3), activation='relu', kernel_initializer='he_normal',\n",
        "                padding='same')(c8) \n",
        "    \n",
        "    \n",
        "    u9 = layers.Conv2DTranspose(16, (2,2), strides=(2,2), padding='same')(c8)\n",
        "    u9 = layers.concatenate([u9, c1], axis = 3)\n",
        "    c9 = layers.Conv2D(16, (3,3), activation='relu', kernel_initializer='he_normal',\n",
        "                padding='same')(u9)\n",
        "    c9 = layers.Dropout(0.1)(c9)\n",
        "    c9 = layers.Conv2D(16, (3,3), activation='relu', kernel_initializer='he_normal',\n",
        "                padding='same')(c9) \n",
        "    \n",
        "    outputs = layers.Conv2D(2,(1,1), activation=\"softmax\",)(c9)\n",
        "    \n",
        "    model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjIL8qN3UTzC"
      },
      "source": [
        "def Dice(y_true, y_pred):\n",
        "\n",
        "    \n",
        "    \n",
        "  mask1 = tf.math.argmax(y_pred, axis=-1)\n",
        "\n",
        "  y_pred= tf.cast(mask1, tf.float32)\n",
        "  inter = tf.reduce_sum(y_pred * y_true, [1,2])\n",
        "  uni = tf.reduce_sum(y_pred , [1,2])+ tf.reduce_sum( y_true, [1,2])\n",
        "\n",
        "  des = tf.reduce_mean(2*inter/uni)\n",
        "       \n",
        "  return des\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAdi8upuQCYd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "d630dd69-ba87-42b8-b10a-8c9ed9d0f278"
      },
      "source": [
        "model = U_Net_Segmentation()\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-a848e8db9350>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mU_Net_Segmentation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-47-6300895381b0>\u001b[0m in \u001b[0;36mU_Net_Segmentation\u001b[0;34m(input_size, drop, l2)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mc1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconv_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ml2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mp1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-33-e4d83ce7ef77>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, channel, **kwargs)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv_block\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         self.c1x1 = layers.Conv2D(channel, (1,1), activation='relu', kernel_initializer='he_normal',\n\u001b[1;32m      6\u001b[0m                 padding='same')\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    515\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, trainable, name, dtype, dynamic, **kwargs)\u001b[0m\n\u001b[1;32m    338\u001b[0m     }\n\u001b[1;32m    339\u001b[0m     \u001b[0;31m# Validate optional keyword arguments.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m     \u001b[0mgeneric_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallowed_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[0;31m# Mutable properties\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mvalidate_kwargs\u001b[0;34m(kwargs, allowed_kwargs, error_message)\u001b[0m\n\u001b[1;32m    806\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mkwarg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkwarg\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mallowed_kwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 808\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_message\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwarg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    809\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: ('Keyword argument not understood:', 'drop')"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhGKRs6ffUAk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0n1dij5Xvd0"
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_CY0xwtXvgg"
      },
      "source": [
        "model.compile(optimizer=optimizer, loss=\"sparse_categorical_crossentropy\", metrics=[Dice])\n",
        "                 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8o9U5SBAznQ"
      },
      "source": [
        "# This function keeps the initial learning rate for the first ten epochs\n",
        "# and decreases it exponentially after that.\n",
        "def scheduler(epoch, lr):\n",
        "  if epoch < 30:\n",
        "    return lr\n",
        "  else:\n",
        "    return lr * 0.1\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAFB8l7DBAWv"
      },
      "source": [
        "callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dS7V2D1KXvin",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "846b7617-06ea-4d94-c4cc-b95ceebd08a1"
      },
      "source": [
        "results = model.fit(train, train_seg_f,\n",
        "                    shuffle = True,\n",
        "                    validation_split = 0.1,\n",
        "                    batch_size=32,\n",
        "                    epochs=70)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/70\n",
            "24/24 [==============================] - 6s 196ms/step - loss: 0.5122 - Dice: 0.0136 - val_loss: 0.3897 - val_Dice: 0.0000e+00\n",
            "Epoch 2/70\n",
            "24/24 [==============================] - 4s 180ms/step - loss: 0.3501 - Dice: 0.0000e+00 - val_loss: 0.2719 - val_Dice: 0.0000e+00\n",
            "Epoch 3/70\n",
            "24/24 [==============================] - 4s 181ms/step - loss: 0.2496 - Dice: 0.0000e+00 - val_loss: 0.2343 - val_Dice: 0.0000e+00\n",
            "Epoch 4/70\n",
            "24/24 [==============================] - 4s 182ms/step - loss: 0.2261 - Dice: 2.2721e-07 - val_loss: 0.2240 - val_Dice: 0.0000e+00\n",
            "Epoch 5/70\n",
            "24/24 [==============================] - 4s 184ms/step - loss: 0.2172 - Dice: 0.0022 - val_loss: 0.2156 - val_Dice: 3.9042e-04\n",
            "Epoch 6/70\n",
            "24/24 [==============================] - 4s 183ms/step - loss: 0.2077 - Dice: 0.0597 - val_loss: 0.2087 - val_Dice: 0.6065\n",
            "Epoch 7/70\n",
            "24/24 [==============================] - 4s 185ms/step - loss: 0.1929 - Dice: 0.3896 - val_loss: 0.2258 - val_Dice: 0.4855\n",
            "Epoch 8/70\n",
            "24/24 [==============================] - 4s 187ms/step - loss: 0.1773 - Dice: 0.6013 - val_loss: 0.2142 - val_Dice: 0.6220\n",
            "Epoch 9/70\n",
            "24/24 [==============================] - 4s 188ms/step - loss: 0.1579 - Dice: 0.6741 - val_loss: 0.1615 - val_Dice: 0.7123\n",
            "Epoch 10/70\n",
            "24/24 [==============================] - 5s 190ms/step - loss: 0.1352 - Dice: 0.7096 - val_loss: 0.1662 - val_Dice: 0.7415\n",
            "Epoch 11/70\n",
            "24/24 [==============================] - 5s 190ms/step - loss: 0.1339 - Dice: 0.7149 - val_loss: 0.1856 - val_Dice: 0.7288\n",
            "Epoch 12/70\n",
            "24/24 [==============================] - 5s 192ms/step - loss: 0.1347 - Dice: 0.7148 - val_loss: 0.1427 - val_Dice: 0.7438\n",
            "Epoch 13/70\n",
            "24/24 [==============================] - 5s 193ms/step - loss: 0.1270 - Dice: 0.7300 - val_loss: 0.1481 - val_Dice: 0.7541\n",
            "Epoch 14/70\n",
            "24/24 [==============================] - 5s 194ms/step - loss: 0.1213 - Dice: 0.7385 - val_loss: 0.1430 - val_Dice: 0.7502\n",
            "Epoch 15/70\n",
            "24/24 [==============================] - 5s 193ms/step - loss: 0.1132 - Dice: 0.7525 - val_loss: 0.1518 - val_Dice: 0.7512\n",
            "Epoch 16/70\n",
            "24/24 [==============================] - 5s 192ms/step - loss: 0.1060 - Dice: 0.7680 - val_loss: 0.1349 - val_Dice: 0.7741\n",
            "Epoch 17/70\n",
            "24/24 [==============================] - 5s 191ms/step - loss: 0.0964 - Dice: 0.7659 - val_loss: 0.1336 - val_Dice: 0.7700\n",
            "Epoch 18/70\n",
            "24/24 [==============================] - 5s 191ms/step - loss: 0.0999 - Dice: 0.7692 - val_loss: 0.1414 - val_Dice: 0.7634\n",
            "Epoch 19/70\n",
            "24/24 [==============================] - 5s 189ms/step - loss: 0.1025 - Dice: 0.7793 - val_loss: 0.1331 - val_Dice: 0.7794\n",
            "Epoch 20/70\n",
            "24/24 [==============================] - 5s 189ms/step - loss: 0.0867 - Dice: 0.8032 - val_loss: 0.1207 - val_Dice: 0.7930\n",
            "Epoch 21/70\n",
            "24/24 [==============================] - 5s 189ms/step - loss: 0.0860 - Dice: 0.7966 - val_loss: 0.1899 - val_Dice: 0.6994\n",
            "Epoch 22/70\n",
            "24/24 [==============================] - 5s 188ms/step - loss: 0.0885 - Dice: 0.7998 - val_loss: 0.1303 - val_Dice: 0.7825\n",
            "Epoch 23/70\n",
            "24/24 [==============================] - 5s 188ms/step - loss: 0.0774 - Dice: 0.8269 - val_loss: 0.1168 - val_Dice: 0.8107\n",
            "Epoch 24/70\n",
            "24/24 [==============================] - 5s 188ms/step - loss: 0.0770 - Dice: 0.8241 - val_loss: 0.1145 - val_Dice: 0.8101\n",
            "Epoch 25/70\n",
            "24/24 [==============================] - 5s 188ms/step - loss: 0.0638 - Dice: 0.8441 - val_loss: 0.1448 - val_Dice: 0.7786\n",
            "Epoch 26/70\n",
            "24/24 [==============================] - 5s 188ms/step - loss: 0.0739 - Dice: 0.8213 - val_loss: 0.1460 - val_Dice: 0.7809\n",
            "Epoch 27/70\n",
            "24/24 [==============================] - 5s 189ms/step - loss: 0.0693 - Dice: 0.8264 - val_loss: 0.1095 - val_Dice: 0.8207\n",
            "Epoch 28/70\n",
            "24/24 [==============================] - 5s 189ms/step - loss: 0.0614 - Dice: 0.8555 - val_loss: 0.1404 - val_Dice: 0.7919\n",
            "Epoch 29/70\n",
            "24/24 [==============================] - 5s 196ms/step - loss: 0.0628 - Dice: 0.8502 - val_loss: 0.1062 - val_Dice: 0.8290\n",
            "Epoch 30/70\n",
            "24/24 [==============================] - 5s 190ms/step - loss: 0.0576 - Dice: 0.8663 - val_loss: 0.1065 - val_Dice: 0.8155\n",
            "Epoch 31/70\n",
            "24/24 [==============================] - 5s 190ms/step - loss: 0.0551 - Dice: 0.8670 - val_loss: 0.1257 - val_Dice: 0.8209\n",
            "Epoch 32/70\n",
            "24/24 [==============================] - 5s 190ms/step - loss: 0.0492 - Dice: 0.8815 - val_loss: 0.1021 - val_Dice: 0.8403\n",
            "Epoch 33/70\n",
            "24/24 [==============================] - 5s 190ms/step - loss: 0.0458 - Dice: 0.8936 - val_loss: 0.1139 - val_Dice: 0.8306\n",
            "Epoch 34/70\n",
            "24/24 [==============================] - 5s 191ms/step - loss: 0.0469 - Dice: 0.8868 - val_loss: 0.1129 - val_Dice: 0.8321\n",
            "Epoch 35/70\n",
            "24/24 [==============================] - 5s 190ms/step - loss: 0.0409 - Dice: 0.8984 - val_loss: 0.1433 - val_Dice: 0.7985\n",
            "Epoch 36/70\n",
            "24/24 [==============================] - 5s 190ms/step - loss: 0.0409 - Dice: 0.8960 - val_loss: 0.1433 - val_Dice: 0.8150\n",
            "Epoch 37/70\n",
            "24/24 [==============================] - 5s 190ms/step - loss: 0.0376 - Dice: 0.9060 - val_loss: 0.0995 - val_Dice: 0.8313\n",
            "Epoch 38/70\n",
            "24/24 [==============================] - 5s 190ms/step - loss: 0.0402 - Dice: 0.9029 - val_loss: 0.1330 - val_Dice: 0.8142\n",
            "Epoch 39/70\n",
            "24/24 [==============================] - 5s 190ms/step - loss: 0.0368 - Dice: 0.9032 - val_loss: 0.1124 - val_Dice: 0.8364\n",
            "Epoch 40/70\n",
            "24/24 [==============================] - 5s 190ms/step - loss: 0.0352 - Dice: 0.9149 - val_loss: 0.1442 - val_Dice: 0.8239\n",
            "Epoch 41/70\n",
            "24/24 [==============================] - 5s 189ms/step - loss: 0.0366 - Dice: 0.9054 - val_loss: 0.1095 - val_Dice: 0.8489\n",
            "Epoch 42/70\n",
            "24/24 [==============================] - 5s 189ms/step - loss: 0.0324 - Dice: 0.9234 - val_loss: 0.1245 - val_Dice: 0.8196\n",
            "Epoch 43/70\n",
            "24/24 [==============================] - 5s 190ms/step - loss: 0.0356 - Dice: 0.9175 - val_loss: 0.1268 - val_Dice: 0.8399\n",
            "Epoch 44/70\n",
            "24/24 [==============================] - 5s 189ms/step - loss: 0.0296 - Dice: 0.9249 - val_loss: 0.1364 - val_Dice: 0.8330\n",
            "Epoch 45/70\n",
            "24/24 [==============================] - 5s 189ms/step - loss: 0.0303 - Dice: 0.9238 - val_loss: 0.1596 - val_Dice: 0.8162\n",
            "Epoch 46/70\n",
            "24/24 [==============================] - 5s 190ms/step - loss: 0.0316 - Dice: 0.9249 - val_loss: 0.1430 - val_Dice: 0.8401\n",
            "Epoch 47/70\n",
            "24/24 [==============================] - 5s 190ms/step - loss: 0.0275 - Dice: 0.9314 - val_loss: 0.1368 - val_Dice: 0.8357\n",
            "Epoch 48/70\n",
            "24/24 [==============================] - 5s 189ms/step - loss: 0.0261 - Dice: 0.9363 - val_loss: 0.1250 - val_Dice: 0.8392\n",
            "Epoch 49/70\n",
            "24/24 [==============================] - 5s 189ms/step - loss: 0.0255 - Dice: 0.9366 - val_loss: 0.1363 - val_Dice: 0.8404\n",
            "Epoch 50/70\n",
            "24/24 [==============================] - 5s 189ms/step - loss: 0.0269 - Dice: 0.9354 - val_loss: 0.1526 - val_Dice: 0.8252\n",
            "Epoch 51/70\n",
            "24/24 [==============================] - 5s 190ms/step - loss: 0.0225 - Dice: 0.9445 - val_loss: 0.1355 - val_Dice: 0.8414\n",
            "Epoch 52/70\n",
            "24/24 [==============================] - 5s 190ms/step - loss: 0.0229 - Dice: 0.9452 - val_loss: 0.1540 - val_Dice: 0.8329\n",
            "Epoch 53/70\n",
            "24/24 [==============================] - 5s 190ms/step - loss: 0.0233 - Dice: 0.9431 - val_loss: 0.1592 - val_Dice: 0.8361\n",
            "Epoch 54/70\n",
            "24/24 [==============================] - 5s 190ms/step - loss: 0.0214 - Dice: 0.9462 - val_loss: 0.1504 - val_Dice: 0.8315\n",
            "Epoch 55/70\n",
            "24/24 [==============================] - 5s 189ms/step - loss: 0.0221 - Dice: 0.9476 - val_loss: 0.1545 - val_Dice: 0.8378\n",
            "Epoch 56/70\n",
            "24/24 [==============================] - 5s 190ms/step - loss: 0.0212 - Dice: 0.9456 - val_loss: 0.1521 - val_Dice: 0.8391\n",
            "Epoch 57/70\n",
            "24/24 [==============================] - 5s 190ms/step - loss: 0.0210 - Dice: 0.9488 - val_loss: 0.1495 - val_Dice: 0.8377\n",
            "Epoch 58/70\n",
            "24/24 [==============================] - 5s 190ms/step - loss: 0.0219 - Dice: 0.9495 - val_loss: 0.1383 - val_Dice: 0.8500\n",
            "Epoch 59/70\n",
            "24/24 [==============================] - 5s 190ms/step - loss: 0.0202 - Dice: 0.9503 - val_loss: 0.1639 - val_Dice: 0.8330\n",
            "Epoch 60/70\n",
            "24/24 [==============================] - 5s 190ms/step - loss: 0.0201 - Dice: 0.9527 - val_loss: 0.1514 - val_Dice: 0.8451\n",
            "Epoch 61/70\n",
            "24/24 [==============================] - 5s 189ms/step - loss: 0.0198 - Dice: 0.9485 - val_loss: 0.1365 - val_Dice: 0.8406\n",
            "Epoch 62/70\n",
            "24/24 [==============================] - 5s 190ms/step - loss: 0.0213 - Dice: 0.9503 - val_loss: 0.1433 - val_Dice: 0.8457\n",
            "Epoch 63/70\n",
            "24/24 [==============================] - 5s 190ms/step - loss: 0.0203 - Dice: 0.9538 - val_loss: 0.1677 - val_Dice: 0.8398\n",
            "Epoch 64/70\n",
            "24/24 [==============================] - 5s 190ms/step - loss: 0.0176 - Dice: 0.9549 - val_loss: 0.1555 - val_Dice: 0.8434\n",
            "Epoch 65/70\n",
            "24/24 [==============================] - 5s 189ms/step - loss: 0.0182 - Dice: 0.9579 - val_loss: 0.1676 - val_Dice: 0.8406\n",
            "Epoch 66/70\n",
            "24/24 [==============================] - 5s 190ms/step - loss: 0.0178 - Dice: 0.9552 - val_loss: 0.1561 - val_Dice: 0.8432\n",
            "Epoch 67/70\n",
            "24/24 [==============================] - 5s 189ms/step - loss: 0.0169 - Dice: 0.9595 - val_loss: 0.1719 - val_Dice: 0.8382\n",
            "Epoch 68/70\n",
            "24/24 [==============================] - 5s 189ms/step - loss: 0.0166 - Dice: 0.9610 - val_loss: 0.1806 - val_Dice: 0.8468\n",
            "Epoch 69/70\n",
            "24/24 [==============================] - 5s 189ms/step - loss: 0.0153 - Dice: 0.9617 - val_loss: 0.1903 - val_Dice: 0.8391\n",
            "Epoch 70/70\n",
            "24/24 [==============================] - 5s 195ms/step - loss: 0.0168 - Dice: 0.9609 - val_loss: 0.1698 - val_Dice: 0.8367\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77alWyEURNWv"
      },
      "source": [
        "loss = results.history['loss']\n",
        "val_loss = results.history['val_Dice']\n",
        "\n",
        "epochs = range(70)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, 'r', label='Training loss Cross entropy')\n",
        "plt.plot(epochs, val_loss, 'bo', label='Validation Dice Metric')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss Value')\n",
        "plt.ylim([0, 1])\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m759RpTUXvlA"
      },
      "source": [
        "def display_mask(i):\n",
        "    \"\"\"Quick utility to display a model's prediction.\"\"\"\n",
        "    mask = np.argmax(val_preds[i], axis=-1)\n",
        "    mask = np.expand_dims(mask, axis=-1)\n",
        "    img = PIL.ImageOps.autocontrast(keras.preprocessing.image.array_to_img(mask))\n",
        "    display(img)\n",
        "\n",
        "pr = model.predict(test_image[:7])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TEFnQPlXvnp"
      },
      "source": [
        "mask1 = np.argmax(pr[2], axis=-1)\n",
        "plt.imshow(mask1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NghUE-MYeDwM"
      },
      "source": [
        "plt.imshow(test_seg_f[2])\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}