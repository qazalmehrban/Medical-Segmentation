{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Untitled1.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/qazalmehrban/Medical-Segmentation/blob/ghazal/Unet_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJeS1cyb1W6E"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "from skimage.transform import resize\n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "import os \n",
        "\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrCxsKNFlhqX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c62ed66-f269-4fc3-c1c7-4d829fe76f16"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-zMk0jg6Dla"
      },
      "source": [
        "samples = '/content/drive/MyDrive/samples/'\n",
        "patients = next(os.walk(samples))[2]\n",
        "labels = '/content/drive/MyDrive/segmentation/'\n",
        "segmentations =next(os.walk(labels))[2]\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5E-zJVeMstRV"
      },
      "source": [
        "patients.sort()\n",
        "segmentations.sort()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDl9zmEWWZMT"
      },
      "source": [
        "def description(samples):\n",
        "  unique_spational = set()\n",
        "  all_spational_slice = []\n",
        "  patients = os.listdir(samples)\n",
        "  patients.sort()\n",
        "  for number_file, image_id  in enumerate(patients):\n",
        "    im = nib.load(os.path.join(samples, image_id))    \n",
        "    im = np.array(im.dataobj)\n",
        "    unique_spational.add(im.shape[:2])\n",
        "    for slices in range(im.shape[2]):\n",
        "\n",
        "      all_spational_slice.append(im.shape[:2])\n",
        "  print(f\"there are {len(unique_spational)} unique spational dimension\")\n",
        "  print(f\"there are {number_file} patient image\")\n",
        "  for i in unique_spational:\n",
        "   print(f'there are {all_spational_slice.count(i)} slice with shape {i}')\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58UGaI2hlxpL"
      },
      "source": [
        "description(samples)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wnwEJNNWZMU"
      },
      "source": [
        "def description_mask(labels):\n",
        "  segmentations = os.listdir(labels)\n",
        "  segmentations.sort()\n",
        "\n",
        "  k = set()\n",
        "  num = []\n",
        "  for i1 in segmentations:\n",
        "    \n",
        "    Masks = nib.load(os.path.join(labels, i1))    \n",
        "    Masks = np.array(Masks.dataobj)\n",
        "    for  j in range(Masks.shape[2]):\n",
        "      u = np.unique(Masks[:,:,j])\n",
        "      u = tuple(u.astype(np.int))\n",
        "      k.add(u)\n",
        "      num.append(u)\n",
        "  for i in k :\n",
        "    print(f'there are {num.count(i)} slice with label {i}')\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Vpm8PzMl5b7"
      },
      "source": [
        "description_mask(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_747rKG6Dlb"
      },
      "source": [
        "def make_box(mask):\n",
        "    box = []\n",
        "    box_bool=[]\n",
        "    obj_ids = np.unique(mask)\n",
        "    if mask.dtype == bool:\n",
        "        if len(np.unique(mask))==2:\n",
        "            \n",
        "            y_min = np.nonzero(mask)[0].min()\n",
        "            y_max = np.nonzero(mask)[0].max()\n",
        "            x_min = np.nonzero(mask)[1].min()\n",
        "            x_max = np.nonzero(mask)[1].max()\n",
        "            box=[x_min, y_min, x_max, y_max]\n",
        "    else :\n",
        "        mask_bool = mask.astype(np.bool)\n",
        "        if len(np.unique(mask_bool))==2:\n",
        "            \n",
        "            y_min = np.nonzero(mask_bool)[0].min()\n",
        "            y_max = np.nonzero(mask_bool)[0].max()\n",
        "            x_min = np.nonzero(mask_bool)[1].min()\n",
        "            x_max = np.nonzero(mask_bool)[1].max()\n",
        "            box_bool=[x_min, y_min, x_max, y_max]\n",
        "        \n",
        "        for i in  obj_ids[1:]:\n",
        "            y_min = np.nonzero(mask==i)[0].min()\n",
        "            y_max = np.nonzero(mask==i)[0].max()\n",
        "            x_min = np.nonzero(mask==i)[1].min()\n",
        "            x_max = np.nonzero(mask==i)[1].max()\n",
        "            box.append([x_min, y_min, x_max, y_max])\n",
        "    return_object = box if mask.dtype ==bool else (dict(zip([f\"label{int(i)}\" for i in obj_ids[1:]],box)), box_bool)\n",
        "    return return_object"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2SuytaH6Uzg"
      },
      "source": [
        "Masks = nib.load((labels + segmentations[0]))    \n",
        "Masks = np.array(Masks.dataobj)\n",
        "print('shape', Masks.shape)\n",
        "slices =7\n",
        "Masks_2d = Masks[:,:,slices]\n",
        "print(f'labels_slice_{slices}', np.unique(Masks_2d))\n",
        "print('bounding_box', make_box(Masks_2d.astype(bool)))\n",
        "plt.imshow(Masks_2d)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBWaB5JgqHOh"
      },
      "source": [
        "Masks = nib.load((labels + segmentations[0]))    \n",
        "Masks = np.array(Masks.dataobj)\n",
        "print('shape', Masks.shape)\n",
        "slices =1\n",
        "Masks_2d = Masks[:,:,slices]\n",
        "print(f'labels_slice_{slices}', np.unique(Masks_2d))\n",
        "print('bounding_box', make_box(Masks_2d))\n",
        "plt.imshow(Masks_2d)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1TUX6dj6U4z"
      },
      "source": [
        "def crop_specific(im, mask, crop_size):\n",
        "        \n",
        "        k=make_box(mask.astype(np.bool))\n",
        "        if len(k)!=0:\n",
        "            b_list = k\n",
        "            x_min, y_min, x_max, y_max = b_list\n",
        "            \n",
        "            length_x = x_max -x_min + 1\n",
        "            length_y = y_max - y_min + 1\n",
        "            del_x = crop_size - length_x \n",
        "            del_y = crop_size - length_y \n",
        "\n",
        "            if del_x%2==0:\n",
        "                kx = del_x//2\n",
        "                sx=0\n",
        "            else:\n",
        "                kx = del_x//2\n",
        "\n",
        "                sx = 1\n",
        "            if del_y%2==0:\n",
        "                ky = del_y//2\n",
        "                sy=0\n",
        "            else:\n",
        "                ky = del_y//2\n",
        "                sy = 1\n",
        "            \n",
        "            crop = mask[ y_min - ky - sy : y_max + ky + 1, x_min - kx - sx : x_max + kx  + 1]\n",
        "            crop_im = im[ y_min - ky - sy : y_max + ky + 1, x_min - kx - sx : x_max + kx  + 1]\n",
        "            return crop_im, crop, \n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOura7TvYgUw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c673e57-8092-4e26-a98a-1823fb42b5b4"
      },
      "source": [
        "len(segmentations)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "53"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3h1lZMG6U7r"
      },
      "source": [
        "crop_size = 192\n",
        "p_seg = []\n",
        "p_im = []\n",
        "for i, i1 in zip(segmentations[:45], patients[:45]):\n",
        "    im = nib.load(os.path.join(samples, i1))    \n",
        "    im = np.array(im.dataobj)\n",
        "\n",
        "    Masks = nib.load(os.path.join(labels, i))    \n",
        "    Masks = np.array(Masks.dataobj)\n",
        "    Masks.shape\n",
        "    for  j in range(Masks.shape[2]):\n",
        "      k=make_box(Masks[:,:,j].astype(np.bool))\n",
        "      if len(k)!=0:\n",
        "        crop_im , crop = crop_specific(im[:,:,j], Masks[:,:,j], crop_size= crop_size)\n",
        "        p_seg.append(crop)\n",
        "        p_im.append(crop_im)\n",
        "\n",
        "\n",
        "    \n",
        "   "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQrg3Z4cad1j"
      },
      "source": [
        "crop_size = 192\n",
        "p_seg_t = []\n",
        "p_im_t = []\n",
        "for i, i1 in zip(segmentations[45:], patients[45:]):\n",
        "    im = nib.load(os.path.join(samples, i1))    \n",
        "    im = np.array(im.dataobj)\n",
        "\n",
        "    Masks = nib.load(os.path.join(labels, i))    \n",
        "    Masks = np.array(Masks.dataobj)\n",
        "    Masks.shape\n",
        "    for  j in range(Masks.shape[2]):\n",
        "      k=make_box(Masks[:,:,j].astype(np.bool))\n",
        "      if len(k)!=0:\n",
        "        crop_im , crop = crop_specific(im[:,:,j], Masks[:,:,j], crop_size= crop_size)\n",
        "        p_seg_t.append(crop)\n",
        "        p_im_t.append(crop_im)\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDUY2DLw6Dld"
      },
      "source": [
        "segment_numpy = np.stack(p_seg,2)\n",
        "image_numpy = np.stack(p_im, 2)\n",
        "\n",
        "segment_numpy_t = np.stack(p_seg_t,2)\n",
        "image_numpy_t = np.stack(p_im_t, 2)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_mcwDyL6Dld"
      },
      "source": [
        "train = image_numpy/image_numpy.max()\n",
        "test = image_numpy_t/image_numpy.max()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLji_MDe6Dle"
      },
      "source": [
        "train_image  = np.transpose(train,(2,0,1))\n",
        "test_image  = np.transpose(test,(2,0,1))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77vNW0js6Dle"
      },
      "source": [
        "train_seg = np.transpose(segment_numpy,(2,0,1))\n",
        "test_seg = np.transpose(segment_numpy_t,(2,0,1))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PftZTqrl6Dle"
      },
      "source": [
        "train_seg_bolean = train_seg.astype(bool)\n",
        "test_seg_bolean = test_seg.astype(bool)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2b6dg-dLTbYU"
      },
      "source": [
        "train_seg_f = train_seg_bolean.astype(float)\n",
        "test_seg_f = test_seg_bolean.astype(float)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fiHgm90TbbG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "243058b9-9640-412c-f702-78a80ba64bad"
      },
      "source": [
        "test_seg_f.shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(122, 192, 192)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9hoyQRSTbgS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qfNgbO9TbjF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANu52n8z6Dlj"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6C8awsS6Dlj"
      },
      "source": [
        "img_size = (crop_size, crop_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FgtbWU36Dlj"
      },
      "source": [
        "\n",
        "\n",
        "def get_model(img_size, num_classes):\n",
        "    inputs = keras.Input(shape=img_size + (1,))\n",
        "\n",
        "    ### [First half of the network: downsampling inputs] ###\n",
        "\n",
        "    # Entry block\n",
        "    x = layers.Conv2D(32, 3, strides=2, padding=\"same\")(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "    previous_block_activation = x  # Set aside residual\n",
        "\n",
        "    # Blocks 1, 2, 3 are identical apart from the feature depth.\n",
        "    for filters in [64, 128, 256]:\n",
        "        x = layers.Activation(\"relu\")(x)\n",
        "        x = layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "\n",
        "        x = layers.Activation(\"relu\")(x)\n",
        "        x = layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "\n",
        "        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
        "\n",
        "        # Project residual\n",
        "        residual = layers.Conv2D(filters, 1, strides=2, padding=\"same\")(\n",
        "            previous_block_activation\n",
        "        )\n",
        "        x = layers.add([x, residual])  # Add back residual\n",
        "        previous_block_activation = x  # Set aside next residual\n",
        "\n",
        "    ### [Second half of the network: upsampling inputs] ###\n",
        "\n",
        "    for filters in [256, 128, 64, 32]:\n",
        "        x = layers.Activation(\"relu\")(x)\n",
        "        x = layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "\n",
        "        x = layers.Activation(\"relu\")(x)\n",
        "        x = layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "\n",
        "        x = layers.UpSampling2D(2)(x)\n",
        "\n",
        "        # Project residual\n",
        "        residual = layers.UpSampling2D(2)(previous_block_activation)\n",
        "        residual = layers.Conv2D(filters, 1, padding=\"same\")(residual)\n",
        "        x = layers.add([x, residual])  # Add back residual\n",
        "        previous_block_activation = x  # Set aside next residual\n",
        "\n",
        "    # Add a per-pixel classification layer\n",
        "    outputs = layers.Conv2D(num_classes, 3, activation=\"softmax\", padding=\"same\")(x)\n",
        "\n",
        "    # Define the model\n",
        "    model = keras.Model(inputs, outputs)\n",
        "    return model\n",
        "\n",
        "\n",
        "# Free up RAM in case the model definition cells were run multiple times\n",
        "keras.backend.clear_session()\n",
        "\n",
        "# Build model\n",
        "model = get_model(img_size, 3)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-iGbhyz6Dll"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxhAdMrk6Dlm"
      },
      "source": [
        "# train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GndrAX_b6Dln"
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "model.compile(optimizer=optimizer, loss=\"sparse_categorical_crossentropy\")\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"unet_seg.h5\", save_best_only=True)\n",
        "]\n",
        "\n",
        "epochs = 50\n",
        "model.fit(tra, seg, epochs=epochs, batch_size=32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvgCH9Qg6Dlp"
      },
      "source": [
        "\n",
        "def display_mask(i):\n",
        "    \"\"\"Quick utility to display a model's prediction.\"\"\"\n",
        "    mask = np.argmax(val_preds[i], axis=-1)\n",
        "    mask = np.expand_dims(mask, axis=-1)\n",
        "    img = PIL.ImageOps.autocontrast(keras.preprocessing.image.array_to_img(mask))\n",
        "    display(img)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QG7thh5H6Dlp"
      },
      "source": [
        "\n",
        "def display_mask(i):\n",
        "    \"\"\"Quick utility to display a model's prediction.\"\"\"\n",
        "    mask = np.argmax(val_preds[i], axis=-1)\n",
        "    mask = np.expand_dims(mask, axis=-1)\n",
        "    img = PIL.ImageOps.autocontrast(keras.preprocessing.image.array_to_img(mask))\n",
        "    display(img)\n",
        "\n",
        "pr = model.predict(tra[:670])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFb6X-2bwfDC"
      },
      "source": [
        "pr.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwiFzQV-6Dlq"
      },
      "source": [
        "mask1 = np.argmax(pr[46], axis=-1)\n",
        "plt.imshow(mask1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNbQGR5J6Dlq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnYE30-RwviK"
      },
      "source": [
        "plt.imshow(seg_f[46])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVJ3hnwLUCXF"
      },
      "source": [
        "np.unique(seg_f[46])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RpQubgdT-Hv"
      },
      "source": [
        "plt.imshow(seg[46])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gk433_XH6Dlq"
      },
      "source": [
        "pr[2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nC9cYCC7WZMd"
      },
      "source": [
        "# Traditional Unet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Blh0OtOiWZMd"
      },
      "source": [
        "IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS = 192, 192, 1\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtDsZLNPtU5z"
      },
      "source": [
        "from tensorflow.keras import layers"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXx7-kecQufp"
      },
      "source": [
        "# Croos entropy loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukefGLzYWZMd"
      },
      "source": [
        "def U_Net_Segmentation(input_size=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)):\n",
        "    \n",
        "    inputs = tf.keras.Input(input_size)\n",
        "    \n",
        "    \n",
        "    c1 = layers.Conv2D(16, (3,3), activation='relu', kernel_initializer='he_normal',\n",
        "                padding='same')(inputs)\n",
        "    c1 = layers.Dropout(0.1)(c1)\n",
        "    c1 = layers.Conv2D(16, (3,3), activation='relu', kernel_initializer='he_normal',\n",
        "                padding='same')(c1)\n",
        "    p1 = layers.MaxPooling2D((2,2))(c1)\n",
        "\n",
        "\n",
        "    c2 = layers.Conv2D(32, (3,3), activation='relu', kernel_initializer='he_normal',\n",
        "                padding='same')(p1)\n",
        "    c2 = layers.Dropout(0.1)(c2)\n",
        "    c2 = layers.Conv2D(32, (3,3), activation='relu', kernel_initializer='he_normal',\n",
        "                padding='same')(c2)\n",
        "    p2 = layers.MaxPooling2D((2,2))(c2)\n",
        "\n",
        "\n",
        "    c3 = layers.Conv2D(64, (3,3), activation='relu', kernel_initializer='he_normal',\n",
        "                padding='same')(p2)\n",
        "    c3 = layers.Dropout(0.2)(c3)\n",
        "    c3 = layers.Conv2D(64, (3,3), activation='relu', kernel_initializer='he_normal',\n",
        "                padding='same')(c3)\n",
        "    p3 = layers.MaxPooling2D((2,2))(c3)\n",
        "\n",
        "\n",
        "    c4 = layers.Conv2D(128, (3,3), activation='relu', kernel_initializer='he_normal',\n",
        "                padding='same')(p3)\n",
        "    c4 = layers.Dropout(0.2)(c4)\n",
        "    c4 = layers.Conv2D(128, (3,3), activation='relu', kernel_initializer='he_normal',\n",
        "                padding='same')(c4)\n",
        "    p4 = layers.MaxPooling2D((2,2))(c4)\n",
        "\n",
        "\n",
        "    c5 = layers.Conv2D(256, (3,3), activation='relu', kernel_initializer='he_normal',\n",
        "                padding='same')(p4)\n",
        "    c5 = layers.Dropout(0.3)(c5)\n",
        "    c5 = layers.Conv2D(256, (3,3), activation='relu', kernel_initializer='he_normal',\n",
        "                padding='same')(c5)\n",
        "\n",
        "\n",
        "\n",
        "    u6 = layers.Conv2DTranspose(128, (2,2), strides=(2,2), padding='same')(c5)\n",
        "    u6 = layers.concatenate([u6, c4])\n",
        "    c6 = layers.Conv2D(128, (3,3), activation='relu', kernel_initializer='he_normal',\n",
        "                padding='same')(u6)\n",
        "    c6 = layers.Dropout(0.2)(c6)\n",
        "    c6 = layers.Conv2D(128, (3,3), activation='relu', kernel_initializer='he_normal',\n",
        "                padding='same')(c6)   \n",
        "\n",
        "\n",
        "    u7 = layers.Conv2DTranspose(64, (2,2), strides=(2,2), padding='same')(c6)\n",
        "    u7 = layers.concatenate([u7, c3])\n",
        "    c7 = layers.Conv2D(64, (3,3), activation='relu', kernel_initializer='he_normal',\n",
        "                padding='same')(u7)\n",
        "    c7 = layers.Dropout(0.2)(c7)\n",
        "    c7 = layers.Conv2D(64, (3,3), activation='relu', kernel_initializer='he_normal',\n",
        "                padding='same')(c7) \n",
        "\n",
        "    u8 = layers.Conv2DTranspose(32, (2,2), strides=(2,2), padding='same')(c7)\n",
        "    u8 = layers.concatenate([u8, c2])\n",
        "    c8 = layers.Conv2D(32, (3,3), activation='relu', kernel_initializer='he_normal',\n",
        "                padding='same')(u8)\n",
        "    c8 = layers.Dropout(0.1)(c8)\n",
        "    c8 = layers.Conv2D(32, (3,3), activation='relu', kernel_initializer='he_normal',\n",
        "                padding='same')(c8) \n",
        "    \n",
        "    \n",
        "    u9 = layers.Conv2DTranspose(16, (2,2), strides=(2,2), padding='same')(c8)\n",
        "    u9 = layers.concatenate([u9, c1], axis = 3)\n",
        "    c9 = layers.Conv2D(16, (3,3), activation='relu', kernel_initializer='he_normal',\n",
        "                padding='same')(u9)\n",
        "    c9 = layers.Dropout(0.1)(c9)\n",
        "    c9 = layers.Conv2D(16, (3,3), activation='relu', kernel_initializer='he_normal',\n",
        "                padding='same')(c9) \n",
        "    \n",
        "    outputs = layers.Conv2D(2,(1,1), activation=\"softmax\",)(c9)\n",
        "    \n",
        "    model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
        "    \n",
        "    model.summary()\n",
        "    return model"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-YTI7SelScc"
      },
      "source": [
        "def iou_coef(y_true, y_pred, smooth=1):\n",
        "  intersection = K.sum(K.abs(y_true * y_pred), axis=[1,2,3])\n",
        "  union = K.sum(y_true,[1,2,3])+K.sum(y_pred,[1,2,3])-intersection\n",
        "  iou = K.mean((intersection + smooth) / (union + smooth), axis=0)\n",
        "  return iou"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4n9fpYpykjx6"
      },
      "source": [
        "class CategoricalTruePositives(keras.metrics.Metric):\n",
        "    def __init__(self, name=\"categorical_true_positives\", **kwargs):\n",
        "        super(CategoricalTruePositives, self).__init__(name=name, **kwargs)\n",
        "        self.true_positives = self.add_weight(name=\"ctp\", initializer=\"zeros\")\n",
        "\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        y_pred = tf.reshape(tf.argmax(y_pred, axis=1), shape=(-1, 1))\n",
        "        values = tf.cast(y_true, \"int32\") == tf.cast(y_pred, \"int32\")\n",
        "        values = tf.cast(values, \"float32\")\n",
        "        if sample_weight is not None:\n",
        "            sample_weight = tf.cast(sample_weight, \"float32\")\n",
        "            values = tf.multiply(values, sample_weight)\n",
        "        self.true_positives.assign_add(tf.reduce_sum(values))\n",
        "\n",
        "    def result(self):\n",
        "        return self.true_positives"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjIL8qN3UTzC",
        "outputId": "768c0bfb-7639-435e-a115-b475c6c0d454",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def Mean_IOU_Evaluator(y_true, y_pred):\n",
        "\n",
        "    \n",
        "    \n",
        "  mask1 = tf.math.argmax(y_pred, axis=-1)\n",
        "\n",
        "  y_pred= tf.cast(mask1, tf.int32)\n",
        "  l = []\n",
        "  for  i,j in zip(y_pred, y_true):\n",
        "    inter = tf.reduce_sum(i, j)\n",
        "    union = tf.reduce_sum(j) + tf.reduce_sum(j)\n",
        "    l.append(inter/union)\n",
        "  des = sum(l)/len(y_pred)\n",
        "       \n",
        "  return des\n",
        "\n",
        "model = U_Net_Segmentation()"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_4 (InputLayer)            [(None, 192, 192, 1) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 192, 192, 16) 160         input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_27 (Dropout)            (None, 192, 192, 16) 0           conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 192, 192, 16) 2320        dropout_27[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling2D) (None, 96, 96, 16)   0           conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 96, 96, 32)   4640        max_pooling2d_12[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dropout_28 (Dropout)            (None, 96, 96, 32)   0           conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 96, 96, 32)   9248        dropout_28[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling2D) (None, 48, 48, 32)   0           conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 48, 48, 64)   18496       max_pooling2d_13[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dropout_29 (Dropout)            (None, 48, 48, 64)   0           conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 48, 48, 64)   36928       dropout_29[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_14 (MaxPooling2D) (None, 24, 24, 64)   0           conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 24, 24, 128)  73856       max_pooling2d_14[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dropout_30 (Dropout)            (None, 24, 24, 128)  0           conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 24, 24, 128)  147584      dropout_30[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_15 (MaxPooling2D) (None, 12, 12, 128)  0           conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 12, 12, 256)  295168      max_pooling2d_15[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dropout_31 (Dropout)            (None, 12, 12, 256)  0           conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 12, 12, 256)  590080      dropout_31[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_12 (Conv2DTran (None, 24, 24, 128)  131200      conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_12 (Concatenate)    (None, 24, 24, 256)  0           conv2d_transpose_12[0][0]        \n",
            "                                                                 conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 24, 24, 128)  295040      concatenate_12[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_32 (Dropout)            (None, 24, 24, 128)  0           conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 24, 24, 128)  147584      dropout_32[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_13 (Conv2DTran (None, 48, 48, 64)   32832       conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_13 (Concatenate)    (None, 48, 48, 128)  0           conv2d_transpose_13[0][0]        \n",
            "                                                                 conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 48, 48, 64)   73792       concatenate_13[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_33 (Dropout)            (None, 48, 48, 64)   0           conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 48, 48, 64)   36928       dropout_33[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_14 (Conv2DTran (None, 96, 96, 32)   8224        conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_14 (Concatenate)    (None, 96, 96, 64)   0           conv2d_transpose_14[0][0]        \n",
            "                                                                 conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 96, 96, 32)   18464       concatenate_14[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_34 (Dropout)            (None, 96, 96, 32)   0           conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 96, 96, 32)   9248        dropout_34[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_15 (Conv2DTran (None, 192, 192, 16) 2064        conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_15 (Concatenate)    (None, 192, 192, 32) 0           conv2d_transpose_15[0][0]        \n",
            "                                                                 conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 192, 192, 16) 4624        concatenate_15[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_35 (Dropout)            (None, 192, 192, 16) 0           conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 192, 192, 16) 2320        dropout_35[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 192, 192, 2)  34          conv2d_74[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 1,940,834\n",
            "Trainable params: 1,940,834\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5yrZv6mq4T7",
        "outputId": "e28c1f85-7af4-4d7d-f740-7aec8037d895",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for i, j in zip(y_pred, y_pred):\n",
        "  print(i)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]], shape=(192, 192), dtype=int32)\n",
            "tf.Tensor(\n",
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]], shape=(192, 192), dtype=int32)\n",
            "tf.Tensor(\n",
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]], shape=(192, 192), dtype=int32)\n",
            "tf.Tensor(\n",
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]], shape=(192, 192), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0n1dij5Xvd0"
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_CY0xwtXvgg"
      },
      "source": [
        "model.compile(optimizer=optimizer, loss=\"sparse_categorical_crossentropy\", metrics=[Mean_IOU_Evaluator])\n",
        "                 "
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dS7V2D1KXvin",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "outputId": "d8cc6336-e4bb-45aa-8d14-23f2dcfaf882"
      },
      "source": [
        "results = model.fit(train_image, train_seg_f,\n",
        "                    shuffle = False,\n",
        "              validation_split = 0.1,\n",
        "                    batch_size=32,\n",
        "                    epochs=50)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-8daa4f8ebb68>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m               \u001b[0mvalidation_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                     epochs=50)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    725\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 726\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    <ipython-input-54-a720e2041a4f>:9 Mean_IOU_Evaluator  *\n        for  i,j in zip(y_pred, y_true):\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/operators/py_builtins.py:414 zip_  **\n        return _py_zip(*iterables)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/operators/py_builtins.py:422 _py_zip\n        return zip(*iterables)\n\n    TypeError: zip argument #1 must support iteration\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m759RpTUXvlA"
      },
      "source": [
        "def display_mask(i):\n",
        "    \"\"\"Quick utility to display a model's prediction.\"\"\"\n",
        "    mask = np.argmax(val_preds[i], axis=-1)\n",
        "    mask = np.expand_dims(mask, axis=-1)\n",
        "    img = PIL.ImageOps.autocontrast(keras.preprocessing.image.array_to_img(mask))\n",
        "    display(img)\n",
        "\n",
        "pr = model.predict(test_image[:7])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TEFnQPlXvnp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "fba98730-6bf4-41b0-fa4c-897a26d51d10"
      },
      "source": [
        "mask1 = np.argmax(pr[2], axis=-1)\n",
        "plt.imshow(mask1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7efc448cdb00>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NghUE-MYeDwM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "1ee3605a-6417-46af-b9e9-fff2b6f020a9"
      },
      "source": [
        "plt.imshow(test_seg_f[2])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7efc448af470>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AE4B7s7Qmd0"
      },
      "source": [
        "# Dice loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlKFqtqvQju5"
      },
      "source": [
        "def U_Net_Segmentation(input_size=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)):\n",
        "    \n",
        "    inputs = tf.keras.Input(input_size)\n",
        "    \n",
        "    \n",
        "    c1 = layers.Conv2D(16, (3,3), activation='relu', kernel_initializer='he_normal',\n",
        "                padding='same')(inputs)\n",
        "    c1 = layers.Dropout(0.1)(c1)\n",
        "    c1 = layers.Conv2D(16, (3,3), activation='relu', kernel_initializer='he_normal',\n",
        "                padding='same')(c1)\n",
        "    p1 = layers.MaxPooling2D((2,2))(c1)\n",
        "\n",
        "\n",
        "    c2 = layers.Conv2D(32, (3,3), activation='relu', kernel_initializer='he_normal',\n",
        "                padding='same')(p1)\n",
        "    c2 = layers.Dropout(0.1)(c2)\n",
        "    c2 = layers.Conv2D(32, (3,3), activation='relu', kernel_initializer='he_normal',\n",
        "                padding='same')(c2)\n",
        "    p2 = layers.MaxPooling2D((2,2))(c2)\n",
        "\n",
        "\n",
        "    c3 = layers.Conv2D(64, (3,3), activation='relu', kernel_initializer='he_normal',\n",
        "                padding='same')(p2)\n",
        "    c3 = layers.Dropout(0.2)(c3)\n",
        "    c3 = layers.Conv2D(64, (3,3), activation='relu', kernel_initializer='he_normal',\n",
        "                padding='same')(c3)\n",
        "    p3 = layers.MaxPooling2D((2,2))(c3)\n",
        "\n",
        "\n",
        "    c4 = layers.Conv2D(128, (3,3), activation='relu', kernel_initializer='he_normal',\n",
        "                padding='same')(p3)\n",
        "    c4 = layers.Dropout(0.2)(c4)\n",
        "    c4 = layers.Conv2D(128, (3,3), activation='relu', kernel_initializer='he_normal',\n",
        "                padding='same')(c4)\n",
        "    p4 = layers.MaxPooling2D((2,2))(c4)\n",
        "\n",
        "\n",
        "    c5 = layers.Conv2D(256, (3,3), activation='relu', kernel_initializer='he_normal',\n",
        "                padding='same')(p4)\n",
        "    c5 = layers.Dropout(0.3)(c5)\n",
        "    c5 = layers.Conv2D(256, (3,3), activation='relu', kernel_initializer='he_normal',\n",
        "                padding='same')(c5)\n",
        "\n",
        "\n",
        "\n",
        "    u6 = layers.Conv2DTranspose(128, (2,2), strides=(2,2), padding='same')(c5)\n",
        "    u6 = layers.concatenate([u6, c4])\n",
        "    c6 = layers.Conv2D(128, (3,3), activation='relu', kernel_initializer='he_normal',\n",
        "                padding='same')(u6)\n",
        "    c6 = layers.Dropout(0.2)(c6)\n",
        "    c6 = layers.Conv2D(128, (3,3), activation='relu', kernel_initializer='he_normal',\n",
        "                padding='same')(c6)   \n",
        "\n",
        "\n",
        "    u7 = layers.Conv2DTranspose(64, (2,2), strides=(2,2), padding='same')(c6)\n",
        "    u7 = layers.concatenate([u7, c3])\n",
        "    c7 = layers.Conv2D(64, (3,3), activation='relu', kernel_initializer='he_normal',\n",
        "                padding='same')(u7)\n",
        "    c7 = layers.Dropout(0.2)(c7)\n",
        "    c7 = layers.Conv2D(64, (3,3), activation='relu', kernel_initializer='he_normal',\n",
        "                padding='same')(c7) \n",
        "\n",
        "    u8 = layers.Conv2DTranspose(32, (2,2), strides=(2,2), padding='same')(c7)\n",
        "    u8 = layers.concatenate([u8, c2])\n",
        "    c8 = layers.Conv2D(32, (3,3), activation='relu', kernel_initializer='he_normal',\n",
        "                padding='same')(u8)\n",
        "    c8 = layers.Dropout(0.1)(c8)\n",
        "    c8 = layers.Conv2D(32, (3,3), activation='relu', kernel_initializer='he_normal',\n",
        "                padding='same')(c8) \n",
        "    \n",
        "    \n",
        "    u9 = layers.Conv2DTranspose(16, (2,2), strides=(2,2), padding='same')(c8)\n",
        "    u9 = layers.concatenate([u9, c1], axis = 3)\n",
        "    c9 = layers.Conv2D(16, (3,3), activation='relu', kernel_initializer='he_normal',\n",
        "                padding='same')(u9)\n",
        "    c9 = layers.Dropout(0.1)(c9)\n",
        "    c9 = layers.Conv2D(16, (3,3), activation='relu', kernel_initializer='he_normal',\n",
        "                padding='same')(c9) \n",
        "    \n",
        "    outputs = layers.Conv2D(1,(1,1), activation=\"softmax\",)(c9)\n",
        "    \n",
        "    model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
        "    \n",
        "    model.summary()\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRryzmcGt_aj"
      },
      "source": [
        "model = U_Net_Segmentation()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBXHJiUsQGas"
      },
      "source": [
        "def dice_loss(y_true, y_pred):\n",
        "  numerator = 2 * tf.reduce_sum(y_true * y_pred)\n",
        "  denominator = tf.reduce_sum(y_true + y_pred)\n",
        "\n",
        "  return 1 - numerator/ denominator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iz1Xcb3Wt5fK"
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zB0yxEaFt0o5"
      },
      "source": [
        "model.compile(optimizer=optimizer, loss=dice_loss\n",
        "                 )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEz4eMXkWZMg"
      },
      "source": [
        "results = model.fit(tra, seg,\n",
        "                    shuffle = False, \n",
        "                    validation_split=0.1, \n",
        "                    batch_size=32,\n",
        "                    epochs=50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mI0x21LQ3Cw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3n0HC5YXsGd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}