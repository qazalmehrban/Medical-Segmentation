{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Untitled1.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/qazalmehrban/Medical-Segmentation/blob/ghazal/Unet_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJeS1cyb1W6E"
      },
      "source": [
        "import numpy as np\n",
        "import nibabel as nib\n",
        "import os \n",
        "import glob\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from skimage.transform import resize\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrCxsKNFlhqX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e235de06-be5e-41ba-e2b6-ef87ed5f4026"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcutt77-66zj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4uvXiQi67Hq"
      },
      "source": [
        "# Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEAdNgTCjMZ2"
      },
      "source": [
        "root = '/content/drive/MyDrive/qazal/new_data'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJF00guR2DC0"
      },
      "source": [
        "val = []\n",
        "test = []\n",
        "val_seg = []\n",
        "test_seg = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jm3WYQJnGf_E"
      },
      "source": [
        "class dat(Dataset):\n",
        "\n",
        "\n",
        "  def __init__(self, crop=192, res =256 ):\n",
        "    super().__init__()\n",
        "    im_add = []\n",
        "    seg_add = []\n",
        "\n",
        "    \n",
        "\n",
        "    for en,i in enumerate(os.walk(root)):\n",
        "      if en==0:\n",
        "        continue\n",
        "      patients_list = glob.glob(i[0] + '/' + '*[0-9].*')\n",
        "      patients_list.sort()\n",
        "\n",
        "\n",
        "      im_add.extend(patients_list)\n",
        "\n",
        "\n",
        "\n",
        "      segment_list = glob.glob(i[0] + '/' + '*n.*')\n",
        "      segment_list.sort()\n",
        "      seg_add.extend(segment_list)\n",
        "\n",
        "    crop_size = crop\n",
        "    p_seg = []\n",
        "    p_im = []\n",
        "    for patient_file, segment_file in zip( im_add, seg_add):\n",
        "      im = nib.load(patient_file).get_fdata()  \n",
        "\n",
        "      Masks = nib.load(segment_file).get_fdata()     \n",
        "      for  j in range(Masks.shape[2]):\n",
        "        k=make_box(Masks[:,:,j].astype(np.bool))\n",
        "        if len(k['bbox_bool'])!=0:\n",
        "          crop_im , crop = crop_specific(im[:,:,j], Masks[:,:,j], crop_size= crop_size)\n",
        "          p_seg.append(crop)\n",
        "          p_im.append(crop_im)\n",
        "    image_numpy = np.stack(p_im, 0)\n",
        "    image_numpy = image_numpy/image_numpy.max()\n",
        "    image_numpy = np.float32(image_numpy)\n",
        "\n",
        "    self.image_numpy = np.expand_dims(image_numpy,1)\n",
        "\n",
        "    segment_numpy = np.stack(p_seg,0)\n",
        "\n",
        "    segment_numpy = segment_numpy.astype(bool)\n",
        "    segment_numpy = np.float32(segment_numpy)\n",
        "    self.segment_numpy = np.expand_dims(segment_numpy,1)\n",
        "\n",
        "  def __len__(self):\n",
        "\n",
        "    return len(self.image_numpy)\n",
        "\n",
        "\n",
        "  def __getitem__(self, key):\n",
        "\n",
        "    return (self.image_numpy[key], self.segment_numpy[key])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    "
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9sDY0pVH4zU"
      },
      "source": [
        "d = dat()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSi_i_lBQmnG"
      },
      "source": [
        "x = torch.utils.data.DataLoader(d, batch_size=32)\n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61Sk_JxNOBw9"
      },
      "source": [
        "def slice_label(masks):\n",
        "\n",
        "  l0 = []\n",
        "  l1_0 =[]\n",
        "  l2_0 = []\n",
        "  l2_1_0 = []\n",
        "  for i in range(masks.shape[-1]):\n",
        "    uni = np.unique(masks[:,:,i])\n",
        "\n",
        "    if len(uni) ==1:\n",
        "      l0.append(i)\n",
        "    elif (0 in uni) and (1 in uni) and not (2 in uni):\n",
        "      l1_0.append(i)\n",
        "    elif (0 in uni) and (2 in uni) and not (1 in uni):\n",
        "      l2_0.append(i)\n",
        "    else :\n",
        "      l2_1_0.append(i)\n",
        "  return {'label_0':l0, 'label_1_0':l1_0,'label_2_0': l2_0, 'label_2_1_0': l2_1_0}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_747rKG6Dlb"
      },
      "source": [
        "def make_box(mask):\n",
        "    '''\n",
        "    this function return dict object contain bounding box of each pixel label and bbox of true value in bolean array\n",
        "    '''\n",
        "    box = []\n",
        "    box_bool=[]\n",
        "    obj_ids = np.unique(mask)\n",
        "    if mask.dtype == bool:\n",
        "        if len(np.unique(mask))==2:\n",
        "            \n",
        "            y_min = np.nonzero(mask)[0].min()\n",
        "            y_max = np.nonzero(mask)[0].max()\n",
        "            x_min = np.nonzero(mask)[1].min()\n",
        "            x_max = np.nonzero(mask)[1].max()\n",
        "            box=[x_min, y_min, x_max, y_max]\n",
        "    else :\n",
        "        mask_bool = mask.astype(np.bool)\n",
        "        if len(np.unique(mask_bool))==2:\n",
        "            \n",
        "            y_min = np.nonzero(mask_bool)[0].min()\n",
        "            y_max = np.nonzero(mask_bool)[0].max()\n",
        "            x_min = np.nonzero(mask_bool)[1].min()\n",
        "            x_max = np.nonzero(mask_bool)[1].max()\n",
        "            box_bool=[x_min, y_min, x_max, y_max]\n",
        "        \n",
        "        for i in  obj_ids[1:]:\n",
        "            y_min = np.nonzero(mask==i)[0].min()\n",
        "            y_max = np.nonzero(mask==i)[0].max()\n",
        "            x_min = np.nonzero(mask==i)[1].min()\n",
        "            x_max = np.nonzero(mask==i)[1].max()\n",
        "            box.append([x_min, y_min, x_max, y_max])\n",
        "    return_object = {'bbox_bool': box} if mask.dtype ==bool else {'bbox_label': dict(zip([f\"label{int(i)}\" for i in obj_ids[1:]],box)), 'bbox_bool' : box_bool}\n",
        "    return return_object"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECG9I6T4JN1e"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iv1RZR4pS8d"
      },
      "source": [
        "def bounding_box_plot(Masks_2d):\n",
        "  \n",
        "  print(f'labels_slice_{slices}', np.unique(Masks_2d))\n",
        "  print('bounding_box', make_box(Masks_2d.astype(bool)))\n",
        "\n",
        "  fig=px.imshow(Masks_2d)\n",
        "\n",
        "  li = make_box(Masks_2d.astype(bool))\n",
        "\n",
        "  k = dict(x0= li[0], x1= li[2], y0= li[1], y1= li[3])\n",
        "  fig.add_shape(\n",
        "    type='rect',\n",
        "    **k,\n",
        "    xref='x', yref='y',\n",
        "    line_color='cyan'\n",
        "  )\n",
        "  fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1TUX6dj6U4z"
      },
      "source": [
        "def crop_specific(im, mask, crop_size):\n",
        "        \n",
        "        k=make_box(mask.astype(np.bool))\n",
        "        if len(k['bbox_bool'])!=0:\n",
        "            b_list = k['bbox_bool']\n",
        "            x_min, y_min, x_max, y_max = b_list\n",
        "            \n",
        "            length_x = x_max -x_min + 1\n",
        "            length_y = y_max - y_min + 1\n",
        "            del_x = crop_size - length_x \n",
        "            del_y = crop_size - length_y \n",
        "\n",
        "            if del_x%2==0:\n",
        "                kx = del_x//2\n",
        "                sx=0\n",
        "            else:\n",
        "                kx = del_x//2\n",
        "\n",
        "                sx = 1\n",
        "            if del_y%2==0:\n",
        "                ky = del_y//2\n",
        "                sy=0\n",
        "            else:\n",
        "                ky = del_y//2\n",
        "                sy = 1\n",
        "            \n",
        "            crop = mask[ y_min - ky - sy : y_max + ky + 1, x_min - kx - sx : x_max + kx  + 1]\n",
        "            crop_im = im[ y_min - ky - sy : y_max + ky + 1, x_min - kx - sx : x_max + kx  + 1]\n",
        "            return crop_im, crop, \n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejmgY4FAojSc"
      },
      "source": [
        "# Pytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yl369LjAZsW"
      },
      "source": [
        "## Resnet Block\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUyUq_e5B6Hu"
      },
      "source": [
        "\n",
        "def model_parameters_numel(model):\n",
        "    list_sum = []\n",
        "    for p in model.parameters():\n",
        "        list_sum.append(p.data.numel())\n",
        "    return sum(list_sum)\n",
        "        \n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMcPK1aQAqwY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "7be4fc77-6160-4a75-f9d3-bd501d168a85"
      },
      "source": [
        "class resnet_block(nn.Module):\n",
        "    \n",
        "    def __init__(self, input_activation, intermediate, expand = 1, stride = 1, down = None):\n",
        "        super().__init__()\n",
        "        self.expand = expand\n",
        "        output = intermediate * self.expand\n",
        "        self.conv1x1_1 = nn.Conv2d(input_activation, intermediate, 1)\n",
        "        self.BN1 = nn.BatchNorm2d(intermediate)\n",
        "        \n",
        "        self.conv3x3 =  nn.Conv2d(intermediate, intermediate, 3, stride=stride, padding=1)\n",
        "        self.BN2 = nn.BatchNorm2d(intermediate)\n",
        "\n",
        "        self.conv1x1_2 =  nn.Conv2d(intermediate, output, 1)\n",
        "        self.BN3 = nn.BatchNorm2d(output)\n",
        "       \n",
        "        self.down = nn.Conv2d(input_activation, output, 1, stride=stride)\n",
        "        \n",
        "    def forward(self , inp):\n",
        "        inp1 = inp\n",
        "        c = F.relu(self.BN1(self.conv1x1_1(inp)))\n",
        "        c = F.relu(self.BN2(self.conv3x3(c)))\n",
        "        c = F.relu(self.BN3(self.conv1x1_2(c)))\n",
        "        if self.down!=None:\n",
        "            inp1 = self.down(inp)\n",
        "        out = F.relu(c + inp1) \n",
        "        \n",
        "        return out"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-6ede940c6d94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mresnet_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_activation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintermediate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdown\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jb5q1WljAwPZ"
      },
      "source": [
        "        \n",
        "class Unet(nn.Module):\n",
        "    def __init__(self, n_class):\n",
        "\n",
        "        \n",
        "        \n",
        "      super().__init__()\n",
        "      self.inp = nn.Conv2d(1,16,3,padding=1)\n",
        "      self.en_block1 = resnet_block(16,32)\n",
        "      self.en_block2 = resnet_block(32,64)\n",
        "      self.en_block3 = resnet_block(64,128)\n",
        "      self.en_block4 = resnet_block(128,256)\n",
        "      self.en_block5 = resnet_block(256,512)\n",
        "      self.en_block6 = resnet_block(512, 1024)\n",
        "\n",
        "        \n",
        "      self.transpose5 = nn.ConvTranspose2d(1024,512,2,2)\n",
        "      self.transpose4 = nn.ConvTranspose2d(512,256,2,2)\n",
        "\n",
        "      self.transpose3 = nn.ConvTranspose2d(256,128,2,2)\n",
        "      self.transpose2 = nn.ConvTranspose2d(128,64,2,2)\n",
        "      self.transpose1 = nn.ConvTranspose2d(64,32,2,2)\n",
        "        \n",
        "      self.de_block1 = resnet_block(64,32)\n",
        "      self.de_block2 = resnet_block(128,64)\n",
        "      self.de_block3 = resnet_block(256,128)\n",
        "\n",
        "      self.de_block4 = resnet_block(512, 256)\n",
        "      self.de_block5 = resnet_block(1024, 512)\n",
        "      self.out_conv = nn.Conv2d(32, n_class, 1)\n",
        "\n",
        "        \n",
        "    \n",
        "\n",
        "    def forward(self, inp):\n",
        "      inp  = self.inp(inp)\n",
        "      el1 = self.en_block1(inp) #  (32,h,w)\n",
        "      max1 = nn.MaxPool2d(2)(el1) # (32,h//2, w//2)\n",
        "\n",
        "      el2 = self.en_block2(max1)    #(64, h//2, w//2)\n",
        "\n",
        "      max2 = nn.MaxPool2d(2)(el2)  #(64, h//4, w//4)\n",
        "\n",
        "      el3 = self.en_block3(max2)    #(128, h//4, w//4)\n",
        "\n",
        "      max3 = nn.MaxPool2d(2)(el3)  #(128, h//8, w//8)\n",
        "\n",
        "\n",
        "      el4 = self.en_block4(max3)    #(256, h//8, w//8)\n",
        "\n",
        "      max4 = nn.MaxPool2d(2)(el4)  #(256, h//16, w//16)\n",
        "\n",
        "      el5 = self.en_block5(max4)  #(512, h//16, w//16)\n",
        "\n",
        "      max5 = nn.MaxPool2d(2)(el5)  #(512, h//32, w//32)\n",
        "\n",
        "        \n",
        "      el6 = self.en_block6(max5)  #(1024, h//32, w//32)\n",
        "\n",
        "\n",
        "      tl5 = self.transpose5(el6)  #(512, h//16, w//16)\n",
        "\n",
        "      cat5 = torch.cat([tl5, el5], 1) #(1024, h//16, h//16 )\n",
        "\n",
        "      d5 =  self.de_block5(cat5)      #(512, h//16, w//16\n",
        "\n",
        "        \n",
        "      tl4 = self.transpose4(d5)       #(256, h//8, w//8)\n",
        "      cat4 = torch.cat([tl4, el4], 1) #(512, h//8, w//8)\n",
        "      d4 =  self.de_block4(cat4)     #(256, h//8, w//8)\n",
        "        \n",
        "      tl3 = self.transpose3(d4)        #(128, h//4, w//4)\n",
        "      cat3 = torch.cat([tl3, el3], 1)  #(256, h//4, w//4)\n",
        "      d3 =  self.de_block3(cat3)        #(128, h//4, w//4)\n",
        "        \n",
        "        \n",
        "      tl2 = self.transpose2(d3)          #(64, h//2, w//2)\n",
        "      cat2 = torch.cat([tl2, el2], 1)   #(128, h//2, w//2)\n",
        "      d2 =  self.de_block2(cat2)         #(64, h//2, w//2)\n",
        "        \n",
        "      tl1 = self.transpose1(d2)          #(32, h, w)\n",
        "      cat1 = torch.cat([tl1, el1], 1) #(64, h, w)\n",
        "      d1 =  self.de_block1(cat1)        #(32, h, w)\n",
        "      output = torch.sigmoid(self.out_conv(d1)) \n",
        "\n",
        "      return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tN_u_GBUBeJp"
      },
      "source": [
        "g = Unet(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWJ7Vd1zB80k"
      },
      "source": [
        "model_parameters_numel(g)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGcbjOm0d0ma"
      },
      "source": [
        "def dice_coef_loss(inputs, target):\n",
        "    smooth = 1.0\n",
        "    intersection = 2.0 * ((target * inputs).sum()) + smooth\n",
        "    union = target.sum() + inputs.sum() + smooth\n",
        "\n",
        "    return 1 - (intersection / union)\n",
        "\n",
        "\n",
        "def bce_dice_loss(inputs, target):\n",
        "    inputs = inputs.to(device)\n",
        "    target = inputs.to(device)\n",
        "\n",
        "    dicescore = dice_coef_loss(inputs, target)\n",
        "    bcescore = nn.BCELoss()\n",
        "    bceloss = dice_coef_loss(inputs, target)\n",
        "\n",
        "    return bceloss + dicescore"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGTX11rrf_VZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "c3692656-e430-44ba-a8c8-3fd17e97deb0"
      },
      "source": [
        "device = torch.device('cuda')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-571ab39f594b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7EbYuFHenH3"
      },
      "source": [
        "def train_step(model, loss = None, device = device, epochs = 30, decay = True, lr = 0.001, best_valid = 0.0):\n",
        "\n",
        "\n",
        "  epochs = epochs\n",
        "  Loss = dice_coef_loss\n",
        "  model.to(device)\n",
        "  opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "  for epoch in range(epochs):\n",
        "    loss_item = []\n",
        "    val_item = []\n",
        "\n",
        "    num_batch = 1\n",
        "    num_batch_v = 1\n",
        "\n",
        "\n",
        "    for batch, (image, segment) in enumerate(x):\n",
        "      num_batch+= batch\n",
        "      image = image.to(device)\n",
        "      segment = segment.to(device)\n",
        "\n",
        "\n",
        "      seg_hat = model(image)\n",
        "      loss = Loss(seg_hat, segment)\n",
        "      loss_item.append(loss.item())\n",
        "\n",
        "      opt.zero_grad()\n",
        "      loss.backward()\n",
        "      opt.step()\n",
        "\n",
        "    \n",
        "      \n",
        "\n",
        "    mean_loss = sum(loss_item)/num_batch\n",
        "    print(f'Loss in epoch{epoch} is :', mean_loss)\n",
        "\n",
        "\n",
        " \n",
        "\n",
        "    #if valid >= best_valid:\n",
        "\n",
        "    #torch.save(model.state_dict(), os.path.join(root, \"model.pt\"))\n",
        "\n",
        "\n"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v94v4tpPgAm2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "1cb6a795-bcea-4895-8ba1-72a73dbc180e"
      },
      "source": [
        "train_step(g)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-cab65cd7226c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-42-6711fc1e0660>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(model, loss, device, epochs, decay, lr, best_valid)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m       \u001b[0mseg_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseg_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m       \u001b[0mloss_item\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-35-cc2a71d3f32d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inp)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m       \u001b[0minp\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m       \u001b[0mel1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0men_block1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#  (32,h,w)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m       \u001b[0mmax1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaxPool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mel1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (32,h//2, w//2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    394\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    395\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 396\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected 4-dimensional input for 4-dimensional weight [16, 1, 3, 3], but got 3-dimensional input of size [32, 192, 192] instead"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_eamETjCFff",
        "outputId": "6152f027-e34e-4ab8-dc5e-74ea3ef537f0"
      },
      "source": [
        "g(torch.from_numpy(train_image_torch[6:7]).to(device))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[1., 1., 1.,  ..., 1., 1., 1.],\n",
              "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
              "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
              "          ...,\n",
              "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
              "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
              "          [1., 1., 1.,  ..., 1., 1., 1.]]]], device='cuda:0',\n",
              "       grad_fn=<SigmoidBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9XeLgcqCsAm",
        "outputId": "ecb3be9d-7e5d-46ab-9c30-2c9455387d94"
      },
      "source": [
        "np.unique(train_seg_torch)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "JfItC_tDC0J0",
        "outputId": "5c6f123d-a819-40d7-cc18-4f290431dc47"
      },
      "source": [
        "plt.imshow(train_seg_torch[34,0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fe3c44d5750>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nl4cBFXPCXoV"
      },
      "source": [
        "## Attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G996uDOpDX1m"
      },
      "source": [
        "class conv_block(nn.Module):\n",
        "    \n",
        "    def __init__(self, input_activation, output_activation):\n",
        "        \n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(input_activation, output_activation, 3, padding=1)\n",
        "        self.BN1 = nn.BatchNorm2d(output_activation)\n",
        "        self.conv2 = nn.Conv2d(input_activation, output_activation, 3, padding=1)\n",
        "        self.BN2 = nn.BatchNorm2d(output_activation)\n",
        "\n",
        "\n",
        "        \n",
        "    def forward(self, x):\n",
        "        l = self.conv1(x)\n",
        "        l = F.relu(self.BN1(l))\n",
        "        l = self.conv2(l)\n",
        "        l = F.relu(self.BN2(l))\n",
        "        return l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDl-AxeEDV68"
      },
      "source": [
        "\n",
        "\n",
        "class up_conv(nn.Module):\n",
        "    def __init__(self,ch_in,ch_out):\n",
        "        super(up_conv,self).__init__()\n",
        "        self.up = nn.Sequential(\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.Conv2d(ch_in,ch_out,kernel_size=3,stride=1,padding=1,bias=True),\n",
        "\t\t    nn.BatchNorm2d(ch_out),\n",
        "\t\t\tnn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.up(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgytYOgVDCYg"
      },
      "source": [
        "class Attention_block(nn.Module):\n",
        "    def __init__(self,F_g,F_l,F_int):\n",
        "        super(Attention_block,self).__init__()\n",
        "        self.W_g = nn.Sequential(\n",
        "            nn.Conv2d(F_g, F_int, kernel_size=1,stride=1,padding=0,bias=True),\n",
        "            nn.BatchNorm2d(F_int)\n",
        "            )\n",
        "        \n",
        "        self.W_x = nn.Sequential(\n",
        "            nn.Conv2d(F_l, F_int, kernel_size=1,stride=1,padding=0,bias=True),\n",
        "            nn.BatchNorm2d(F_int)\n",
        "        )\n",
        "\n",
        "        self.psi = nn.Sequential(\n",
        "            nn.Conv2d(F_int, 1, kernel_size=1,stride=1,padding=0,bias=True),\n",
        "            nn.BatchNorm2d(1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        \n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        \n",
        "    def forward(self,g,x):\n",
        "        g1 = self.W_g(g)\n",
        "        x1 = self.W_x(x)\n",
        "        psi = self.relu(g1+x1)\n",
        "        psi = self.psi(psi)\n",
        "\n",
        "        return x*psi\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4ZPp7wsDPgc"
      },
      "source": [
        "\n",
        "class AttU_Net(nn.Module):\n",
        "    def __init__(self,img_ch=3,output_ch=1):\n",
        "        super(AttU_Net,self).__init__()\n",
        "        \n",
        "        self.Maxpool = nn.MaxPool2d(kernel_size=2,stride=2)\n",
        "\n",
        "        self.Conv1 = conv_block(ch_in=img_ch,ch_out=64)\n",
        "        self.Conv2 = conv_block(ch_in=64,ch_out=128)\n",
        "        self.Conv3 = conv_block(ch_in=128,ch_out=256)\n",
        "        self.Conv4 = conv_block(ch_in=256,ch_out=512)\n",
        "        self.Conv5 = conv_block(ch_in=512,ch_out=1024)\n",
        "\n",
        "        self.Up5 = up_conv(ch_in=1024,ch_out=512)\n",
        "        self.Att5 = Attention_block(F_g=512,F_l=512,F_int=256)\n",
        "        self.Up_conv5 = conv_block(ch_in=1024, ch_out=512)\n",
        "\n",
        "        self.Up4 = up_conv(ch_in=512,ch_out=256)\n",
        "        self.Att4 = Attention_block(F_g=256,F_l=256,F_int=128)\n",
        "        self.Up_conv4 = conv_block(ch_in=512, ch_out=256)\n",
        "        \n",
        "        self.Up3 = up_conv(ch_in=256,ch_out=128)\n",
        "        self.Att3 = Attention_block(F_g=128,F_l=128,F_int=64)\n",
        "        self.Up_conv3 = conv_block(ch_in=256, ch_out=128)\n",
        "        \n",
        "        self.Up2 = up_conv(ch_in=128,ch_out=64)\n",
        "        self.Att2 = Attention_block(F_g=64,F_l=64,F_int=32)\n",
        "        self.Up_conv2 = conv_block(ch_in=128, ch_out=64)\n",
        "\n",
        "        self.Conv_1x1 = nn.Conv2d(64,output_ch,kernel_size=1,stride=1,padding=0)\n",
        "\n",
        "\n",
        "    def forward(self,x):\n",
        "        # encoding path\n",
        "        x1 = self.Conv1(x)\n",
        "\n",
        "        x2 = self.Maxpool(x1)\n",
        "        x2 = self.Conv2(x2)\n",
        "        \n",
        "        x3 = self.Maxpool(x2)\n",
        "        x3 = self.Conv3(x3)\n",
        "\n",
        "        x4 = self.Maxpool(x3)\n",
        "        x4 = self.Conv4(x4)\n",
        "\n",
        "        x5 = self.Maxpool(x4)\n",
        "        x5 = self.Conv5(x5)\n",
        "\n",
        "        # decoding + concat path\n",
        "        d5 = self.Up5(x5)\n",
        "        x4 = self.Att5(g=d5,x=x4)\n",
        "        d5 = torch.cat((x4,d5),dim=1)        \n",
        "        d5 = self.Up_conv5(d5)\n",
        "        \n",
        "        d4 = self.Up4(d5)\n",
        "        x3 = self.Att4(g=d4,x=x3)\n",
        "        d4 = torch.cat((x3,d4),dim=1)\n",
        "        d4 = self.Up_conv4(d4)\n",
        "\n",
        "        d3 = self.Up3(d4)\n",
        "        x2 = self.Att3(g=d3,x=x2)\n",
        "        d3 = torch.cat((x2,d3),dim=1)\n",
        "        d3 = self.Up_conv3(d3)\n",
        "\n",
        "        d2 = self.Up2(d3)\n",
        "        x1 = self.Att2(g=d2,x=x1)\n",
        "        d2 = torch.cat((x1,d2),dim=1)\n",
        "        d2 = self.Up_conv2(d2)\n",
        "\n",
        "        d1 = self.Conv_1x1(d2)\n",
        "\n",
        "        return d1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DieHzziEAjLR"
      },
      "source": [
        "## Traditinal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rxoyUEtpmKL"
      },
      "source": [
        "train_image_torch = np.expand_dims(train,1)\n",
        "train_seg_torch  = np.expand_dims(train_seg_f,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2wi0WLRhzyv"
      },
      "source": [
        "dataloader_image = torch.utils.data.DataLoader(train_image_torch,32)\n",
        "dataloader_segment = torch.utils.data.DataLoader(train_seg_torch,32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OivJflHSDd7J"
      },
      "source": [
        "class conv_block(nn.Module):\n",
        "    \n",
        "    def __init__(self, input_activation, output_activation):\n",
        "        \n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(input_activation, output_activation, 3, padding=1)\n",
        "        self.BN1 = nn.BatchNorm2d(output_activation)\n",
        "        self.conv2 = nn.Conv2d(output_activation, output_activation, 3, padding=1)\n",
        "        self.BN2 = nn.BatchNorm2d(output_activation)\n",
        "\n",
        "\n",
        "        \n",
        "    def forward(self, x):\n",
        "        l = self.conv1(x)\n",
        "        l = F.relu(self.BN1(l))\n",
        "        l = self.conv2(l)\n",
        "        l = F.relu(self.BN2(l))\n",
        "        return l\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODZSxdP-omWt"
      },
      "source": [
        "\n",
        "\n",
        "class Unet(nn.Module):\n",
        "    def __init__(self, n_class):\n",
        "        \n",
        "        super().__init__()\n",
        "        self.en_block1 = conv_block(1,32)\n",
        "        self.en_block2 = conv_block(32,64)\n",
        "        self.en_block3 = conv_block(64,128)\n",
        "        self.en_block4 = conv_block(128,256)\n",
        "        self.en_block5 = conv_block(256,512)\n",
        "        self.en_block6 = conv_block(512, 1024)\n",
        "\n",
        "        \n",
        "        self.transpose5 = nn.ConvTranspose2d(1024,512,2,2)\n",
        "        self.transpose4 = nn.ConvTranspose2d(512,256,2,2)\n",
        "\n",
        "        self.transpose3 = nn.ConvTranspose2d(256,128,2,2)\n",
        "        self.transpose2 = nn.ConvTranspose2d(128,64,2,2)\n",
        "        self.transpose1 = nn.ConvTranspose2d(64,32,2,2)\n",
        "        \n",
        "        self.de_block1 = conv_block(64,32)\n",
        "        self.de_block2 = conv_block(128,64)\n",
        "        self.de_block3 = conv_block(256,128)\n",
        "\n",
        "        self.de_block4 = conv_block(512, 256)\n",
        "        self.de_block5 = conv_block(1024, 512)\n",
        "        self.out_conv = nn.Conv2d(32, 1, 1)\n",
        "\n",
        "        \n",
        "    \n",
        "\n",
        "    def forward(self, inp):\n",
        "        el1 = self.en_block1(inp) #  (32,h,w)\n",
        "        #print('el1',el1.shape)\n",
        "        max1 = nn.MaxPool2d(2)(el1) # (32,h//2, w//2)\n",
        "        #print('max1',max1.shape)\n",
        "\n",
        "        el2 = self.en_block2(max1)    #(64, h//2, w//2)\n",
        "        #print('el2',el2.shape)\n",
        "\n",
        "        max2 = nn.MaxPool2d(2)(el2)  #(64, h//4, w//4)\n",
        "        #print('max2',max2.shape)\n",
        "\n",
        "        el3 = self.en_block3(max2)    #(128, h//4, w//4)\n",
        "        #print('el3',el3.shape)\n",
        "\n",
        "        max3 = nn.MaxPool2d(2)(el3)  #(128, h//8, w//8)\n",
        "        #print('max3',max3.shape)\n",
        "\n",
        "\n",
        "        el4 = self.en_block4(max3)    #(256, h//8, w//8)\n",
        "        #print('el4',el4.shape)\n",
        "\n",
        "        max4 = nn.MaxPool2d(2)(el4)  #(256, h//16, w//16)\n",
        "        #print('max4',max4.shape)\n",
        "\n",
        "        el5 = self.en_block5(max4)  #(512, h//16, w//16)\n",
        "        #print('el5',el5.shape)\n",
        "\n",
        "        max5 = nn.MaxPool2d(2)(el5)  #(512, h//32, w//32)\n",
        "        #print('max5',max5.shape)\n",
        "\n",
        "        \n",
        "        el6 = self.en_block6(max5)  #(1024, h//32, w//32)\n",
        "        #print('el6',el6.shape)\n",
        "\n",
        "\n",
        "        tl5 = self.transpose5(el6)  #(512, h//16, w//16)\n",
        "        #print('tl5',tl5.shape)\n",
        "\n",
        "        cat5 = torch.cat([tl5, el5], 1) #(1024, h//16, h//16 )\n",
        "        #print('cat5',cat5.shape)\n",
        "\n",
        "        d5 =  self.de_block5(cat5)      #(512, h//16, w//16\n",
        "        #print('d5',d5.shape)\n",
        "\n",
        "        \n",
        "        tl4 = self.transpose4(d5)       #(256, h//8, w//8)\n",
        "        cat4 = torch.cat([tl4, el4], 1) #(512, h//8, w//8)\n",
        "        d4 =  self.de_block4(cat4)     #(256, h//8, w//8)\n",
        "        \n",
        "        tl3 = self.transpose3(d4)        #(128, h//4, w//4)\n",
        "        cat3 = torch.cat([tl3, el3], 1)  #(256, h//4, w//4)\n",
        "        d3 =  self.de_block3(cat3)        #(128, h//4, w//4)\n",
        "        \n",
        "        \n",
        "        tl2 = self.transpose2(d3)          #(64, h//2, w//2)\n",
        "        cat2 = torch.cat([tl2, el2], 1)   #(128, h//2, w//2)\n",
        "        d2 =  self.de_block2(cat2)         #(64, h//2, w//2)\n",
        "        \n",
        "        tl1 = self.transpose1(d2)          #(32, h, w)\n",
        "        cat1 = torch.cat([tl1, el1], 1) #(64, h, w)\n",
        "        d1 =  self.de_block1(cat1)        #(32, h, w)\n",
        "        output = torch.sigmoid(self.out_conv(d1)) \n",
        "\n",
        "        return output\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVa5_ABxomZA"
      },
      "source": [
        "model = Unet(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFMO4LZh0i1k"
      },
      "source": [
        "def dice_coef_loss(inputs, target):\n",
        "    smooth = 1.0\n",
        "    intersection = 2.0 * ((target * inputs).sum()) + smooth\n",
        "    union = target.sum() + inputs.sum() + smooth\n",
        "\n",
        "    return 1 - (intersection / union)\n",
        "\n",
        "\n",
        "def bce_dice_loss(inputs, target):\n",
        "    inputs = inputs.to(device)\n",
        "    target = inputs.to(device)\n",
        "\n",
        "    dicescore = dice_coef_loss(inputs, target)\n",
        "    bcescore = nn.BCELoss()\n",
        "    bceloss = dice_coef_loss(inputs, target)\n",
        "\n",
        "    return bceloss + dicescore"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3uVtkvdo5R3"
      },
      "source": [
        "def dice_coef_metric(inputs, target):\n",
        "    intersection = 2.0 * (target * inputs).sum()\n",
        "    union = target.sum() + inputs.sum()\n",
        "    if target.sum() == 0 and inputs.sum() == 0:\n",
        "        return 1.0\n",
        "\n",
        "    return intersection / union"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpmNmtNoo5VP"
      },
      "source": [
        "device = torch.device('cuda')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_YHrdvuW7Pv"
      },
      "source": [
        "loss=None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMHst6GdRwWl"
      },
      "source": [
        "Loss = bce_dice_loss if loss==None else loss\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYz8k5RJUe8X"
      },
      "source": [
        "def train_step(model, loss = None, device = device, epochs = 30, decay = True, lr = 0.001, best_valid = 0.0):\n",
        "\n",
        "\n",
        "  epochs = epochs\n",
        "  Loss = bce_dice_loss if loss==None else loss\n",
        "  model.to(device)\n",
        "  opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "  loss_item = []\n",
        "  for epoch in range(epochs):\n",
        "\n",
        "    num_batch = 1\n",
        "\n",
        "    for batch, (image, segment) in enumerate(zip(dataloader_image, dataloader_segment)):\n",
        "      num_batch+= batch\n",
        "      image = image.to(device)\n",
        "      segment = segment.to(device)\n",
        "\n",
        "\n",
        "      seg_hat = model(image)\n",
        "      loss = Loss(seg_hat, segment)\n",
        "\n",
        "      opt.zero_grad()\n",
        "      loss.backward()\n",
        "      opt.step()\n",
        "      loss_item.append(loss.item())\n",
        "\n",
        "    mean_loss = sum(loss_item)/num_batch\n",
        "    print(f'Loss in epoch{epoch} is :', mean_loss)\n",
        " \n",
        "\n",
        "    #if valid >= best_valid:\n",
        "\n",
        "    #torch.save(model.state_dict(), os.path.join(root, \"model.pt\"))\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rceljBZlcAs9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "14ce19fd-8740-41fb-f58f-fa7ad8d6f086"
      },
      "source": [
        "train_step(model,loss = nn.BCELoss())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-9c5f33ce4188>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBCELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-34-ca697700f950>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(model, loss, device, epochs, decay, lr, best_valid)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m       \u001b[0mseg_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseg_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-cc2a71d3f32d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inp)\u001b[0m\n\u001b[1;32m     81\u001b[0m       \u001b[0mtl1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md2\u001b[0m\u001b[0;34m)\u001b[0m          \u001b[0;31m#(32, h, w)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m       \u001b[0mcat1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtl1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mel1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#(64, h, w)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m       \u001b[0md1\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mde_block1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcat1\u001b[0m\u001b[0;34m)\u001b[0m        \u001b[0;31m#(32, h, w)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m       \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-6ede940c6d94>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inp)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBN3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1x1_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdown\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0minp1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minp1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    394\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    395\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 396\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 144.00 MiB (GPU 0; 14.76 GiB total capacity; 13.49 GiB already allocated; 77.75 MiB free; 13.65 GiB reserved in total by PyTorch)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxAp80mv1xuw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "bbe9477a-488c-4a4b-c1a4-766ba9fab0c7"
      },
      "source": [
        "for epoch in range(20):\n",
        "        model.train() # Enter train mode\n",
        "        \n",
        "        losses = []\n",
        "        train_iou = []\n",
        "        \n",
        "        for i_step, (data, target) in enumerate(zip(dataloader_image, dataloader_segment)):\n",
        "            data = data.to(device)\n",
        "            target = target.to(device)\n",
        "                      \n",
        "            outputs = model(data)\n",
        "            \n",
        "            out_cut = np.copy(outputs.data.cpu().numpy())\n",
        "            out_cut[np.nonzero(out_cut < 0.5)] = 0.0\n",
        "            out_cut[np.nonzero(out_cut >= 0.5)] = 1.0\n",
        "            \n",
        "            train_dice = dice_coef_metric(out_cut, target.data.cpu().numpy())\n",
        "            \n",
        "            loss = train_loss(outputs, target)\n",
        "            \n",
        "            losses.append(loss.item())\n",
        "            train_iou.append(train_dice)\n",
        "            opt.zero_grad()\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "\n",
        "        print(\"Epoch [%d]\" % (epoch))\n",
        "        print(\"Mean loss on train:\", np.array(losses).mean(), \n",
        "              \"\\nMean DICE on train:\", np.array(train_iou).mean())\n",
        "    \n",
        "           \n",
        " \n",
        "       "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-871dc6fe4651>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mout_cut\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-33-a0191d2c8a28>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inp)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mel1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0men_block1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#  (32,h,w)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;31m#print('el1',el1.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mmax1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaxPool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mel1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (32,h//2, w//2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-32-97a1390c9680>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBN1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBN2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    394\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    395\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 396\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 144.00 MiB (GPU 0; 14.76 GiB total capacity; 13.32 GiB already allocated; 3.75 MiB free; 13.72 GiB reserved in total by PyTorch)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtvE06B4o5bg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "00e8094b-f4ae-4ec5-d1ca-c09cfc3415f3"
      },
      "source": [
        "for epoch in range(ep):\n",
        "  for im , segi in zip(d_tr, d_seg):\n",
        "    im = im.to(device=device)\n",
        "    segi =segi.to(device)\n",
        "    yh = m(im)\n",
        "    l = loss(yh, segi)\n",
        "    opt.zero_grad()\n",
        "    l.backward()\n",
        "    opt.step()\n",
        "  print(f\"epoch{epoch} loss is :\", l)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch30 loss is : tensor(0.5245, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "epoch30 loss is : tensor(0.5317, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "epoch30 loss is : tensor(0.5307, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "epoch30 loss is : tensor(0.5326, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-194242e18765>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mim\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0msegi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_seg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0msegi\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0msegi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0myh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGq2CgdbgKmk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e94d343-3505-4aa3-852e-7a0ea04b648b"
      },
      "source": [
        "torch.cuda.current_device()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgJM2fMjg-sd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "736de1fa-6905-449a-de7d-bff2045ce5ec"
      },
      "source": [
        "torch.cuda.is_available()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXx7-kecQufp"
      },
      "source": [
        "# tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oswpYrSC_yyS"
      },
      "source": [
        "IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS  =crop_size, crop_size, 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWAxDkhxixV_"
      },
      "source": [
        "class conv_block(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self, channel, **kwargs):\n",
        "        super(conv_block, self).__init__(**kwargs)\n",
        "        self.c1x1 = layers.Conv2D(channel, (1,1), activation='relu', kernel_initializer='he_normal',\n",
        "                padding='same')\n",
        "        self.c3x3 = layers.Conv2D(channel, (3,3), activation='relu', kernel_initializer='he_normal',\n",
        "                padding='same')\n",
        "        self.c1x1_2 = layers.Conv2D(channel, (1,1), activation='relu', kernel_initializer='he_normal',\n",
        "                padding='same')\n",
        "        self.co =  layers.Conv2D(channel, (1,1), activation='relu', kernel_initializer='he_normal',\n",
        "                padding='same')\n",
        "\n",
        "\n",
        "  def call(self, inputs, training=None):\n",
        "    l1 = self.c1x1(inputs)\n",
        "    l1 = self.c3x3(l1)\n",
        "    l1 = self.c1x1_2(l1)\n",
        "    inp_mod = self.co(inputs)\n",
        "    out = l1 + inp_mod\n",
        "    return out\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxp_ZAJ4tdLI"
      },
      "source": [
        "input_size=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)\n",
        "drop = None\n",
        "l2 = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukefGLzYWZMd"
      },
      "source": [
        "    \n",
        "inputs = tf.keras.Input(input_size)\n",
        "    \n",
        "    \n",
        "c1=conv_block(16, drop=drop, l2=l2)(inputs)\n",
        "p1 = layers.MaxPooling2D((2,2))(c1)\n",
        "\n",
        "\n",
        "c2 = conv_block(32, drop=drop, l2=l2)(p1)\n",
        "p2 = layers.MaxPooling2D((2,2))(c2)\n",
        "\n",
        "\n",
        "c3 = conv_block(64, drop=drop, l2=l2)(p2)\n",
        "p3 = layers.MaxPooling2D((2,2))(c3)\n",
        "\n",
        "\n",
        "c4 = conv_block(128, drop=drop, l2=l2)(p3)\n",
        "p4 = layers.MaxPooling2D((2,2))(c4)\n",
        "\n",
        "\n",
        "c5 = conv_block(256, drop=drop, l2=l2)(p4)\n",
        "p5 = layers.MaxPooling2D((2,2))(c5)\n",
        "\n",
        "c6 = conv_block(256, drop=drop, l2=l2)(p5)\n",
        "\n",
        "\n",
        "\n",
        "u7 = layers.Conv2DTranspose(256, (2,2), strides=(2,2), padding='same')(c6)\n",
        "u7 = layers.concatenate([u7, c5])\n",
        "c7 = layers.Conv2D(256, (3,3), activation='relu', kernel_initializer='he_normal',\n",
        "                padding='same')(u7)\n",
        "\n",
        "c7 = layers.Dropout(0.2)(c7)\n",
        "c7 = layers.Conv2D(256, (3,3), activation='relu', kernel_initializer='he_normal',\n",
        "                padding='same')(c7)   \n",
        "\n",
        "u6 = layers.Conv2DTranspose(128, (2,2), strides=(2,2), padding='same')(c5)\n",
        "u6 = layers.concatenate([u6, c4])\n",
        "c6 = layers.Conv2D(128, (3,3), activation='relu', kernel_initializer='he_normal',\n",
        "                padding='same')(u6)\n",
        "c6 = layers.Dropout(0.2)(c6)\n",
        "c6 = layers.Conv2D(128, (3,3), activation='relu', kernel_initializer='he_normal',\n",
        "                padding='same')(c6)   \n",
        "\n",
        "\n",
        "u7 = layers.Conv2DTranspose(64, (2,2), strides=(2,2), padding='same')(c6)\n",
        "u7 = layers.concatenate([u7, c3])\n",
        "c7 = layers.Conv2D(64, (3,3), activation='relu', kernel_initializer='he_normal',\n",
        "                padding='same')(u7)\n",
        "c7 = layers.Dropout(0.2)(c7)\n",
        "c7 = layers.Conv2D(64, (3,3), activation='relu', kernel_initializer='he_normal',\n",
        "                padding='same')(c7) \n",
        "\n",
        "u8 = layers.Conv2DTranspose(32, (2,2), strides=(2,2), padding='same')(c7)\n",
        "u8 = layers.concatenate([u8, c2])\n",
        "c8 = layers.Conv2D(32, (3,3), activation='relu', kernel_initializer='he_normal',\n",
        "                padding='same')(u8)\n",
        "c8 = layers.Dropout(0.1)(c8)\n",
        "c8 = layers.Conv2D(32, (3,3), activation='relu', kernel_initializer='he_normal',\n",
        "                padding='same')(c8) \n",
        "    \n",
        "    \n",
        "u9 = layers.Conv2DTranspose(16, (2,2), strides=(2,2), padding='same')(c8)\n",
        "u9 = layers.concatenate([u9, c1], axis = 3)\n",
        "c9 = layers.Conv2D(16, (3,3), activation='relu', kernel_initializer='he_normal',\n",
        "                padding='same')(u9)\n",
        "c9 = layers.Dropout(0.1)(c9)\n",
        "c9 = layers.Conv2D(16, (3,3), activation='relu', kernel_initializer='he_normal',\n",
        "                padding='same')(c9) \n",
        "    \n",
        "outputs = layers.Conv2D(2,(1,1), activation=\"softmax\",)(c9)\n",
        "    \n",
        "model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjIL8qN3UTzC"
      },
      "source": [
        "def Dice(y_true, y_pred):\n",
        "\n",
        "    \n",
        "    \n",
        "  mask1 = tf.math.argmax(y_pred, axis=-1)\n",
        "\n",
        "  y_pred= tf.cast(mask1, tf.float32)\n",
        "  inter = tf.reduce_sum(y_pred * y_true, [1,2])\n",
        "  uni = tf.reduce_sum(y_pred , [1,2])+ tf.reduce_sum( y_true, [1,2])\n",
        "\n",
        "  des = tf.reduce_mean(2*inter/uni)\n",
        "       \n",
        "  return 1.- des\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INoHw1gWUgOr"
      },
      "source": [
        "def Dice1(y_true, y_pred):\n",
        "\n",
        "    \n",
        "    \n",
        "  mask1 = tf.math.argmax(y_pred, axis=-1)\n",
        "\n",
        "  y_pred= tf.cast(mask1, tf.float32)\n",
        "  inter = tf.reduce_sum(y_pred * y_true, [1,2])\n",
        "  uni = tf.reduce_sum(y_pred , [1,2])+ tf.reduce_sum( y_true, [1,2])\n",
        "\n",
        "  des = tf.reduce_mean(2*inter/uni)\n",
        "       \n",
        "  return des\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0n1dij5Xvd0"
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PGQgZhUT0tg"
      },
      "source": [
        "cross = \"sparse_categorical_crossentropy\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_CY0xwtXvgg"
      },
      "source": [
        "model.compile(optimizer=optimizer, loss=Dice , metrics=[Dice1])\n",
        "                 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8o9U5SBAznQ"
      },
      "source": [
        "# This function keeps the initial learning rate for the first ten epochs\n",
        "# and decreases it exponentially after that.\n",
        "def scheduler(epoch, lr):\n",
        "  if epoch < 30:\n",
        "    return lr\n",
        "  else:\n",
        "    return lr * 0.1\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAFB8l7DBAWv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "4270a70f-14da-473d-c3fb-1e07d6f81984"
      },
      "source": [
        "callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-0d043c97c611>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcallback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLearningRateScheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'scheduler' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dS7V2D1KXvin",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f130709e-6fdb-468e-9385-4230579f554a"
      },
      "source": [
        "results = model.fit(train, train_seg_f,\n",
        "                    shuffle = True,\n",
        "                    validation_split = 0.1,\n",
        "                    batch_size=32,\n",
        "                    epochs=70)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/70\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d/bias:0', 'conv2d_1/kernel:0', 'conv2d_1/bias:0', 'conv2d_2/bias:0', 'conv2d_3/kernel:0', 'conv2d_3/bias:0', 'conv2d_4/bias:0', 'conv2d_5/kernel:0', 'conv2d_5/bias:0', 'conv2d_6/bias:0', 'conv2d_7/kernel:0', 'conv2d_7/bias:0', 'conv2d_8/bias:0', 'conv2d_9/kernel:0', 'conv2d_9/bias:0', 'conv2d_transpose_1/kernel:0', 'conv2d_transpose_1/bias:0', 'conv2d_14/kernel:0', 'conv2d_14/bias:0', 'conv2d_15/kernel:0', 'conv2d_15/bias:0', 'conv2d_transpose_2/kernel:0', 'conv2d_transpose_2/bias:0', 'conv2d_16/kernel:0', 'conv2d_16/bias:0', 'conv2d_17/kernel:0', 'conv2d_17/bias:0', 'conv2d_transpose_3/kernel:0', 'conv2d_transpose_3/bias:0', 'conv2d_18/kernel:0', 'conv2d_18/bias:0', 'conv2d_19/kernel:0', 'conv2d_19/bias:0', 'conv2d_transpose_4/kernel:0', 'conv2d_transpose_4/bias:0', 'conv2d_20/kernel:0', 'conv2d_20/bias:0', 'conv2d_21/kernel:0', 'conv2d_21/bias:0', 'conv2d_22/kernel:0', 'conv2d_22/bias:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d/bias:0', 'conv2d_1/kernel:0', 'conv2d_1/bias:0', 'conv2d_2/bias:0', 'conv2d_3/kernel:0', 'conv2d_3/bias:0', 'conv2d_4/bias:0', 'conv2d_5/kernel:0', 'conv2d_5/bias:0', 'conv2d_6/bias:0', 'conv2d_7/kernel:0', 'conv2d_7/bias:0', 'conv2d_8/bias:0', 'conv2d_9/kernel:0', 'conv2d_9/bias:0', 'conv2d_transpose_1/kernel:0', 'conv2d_transpose_1/bias:0', 'conv2d_14/kernel:0', 'conv2d_14/bias:0', 'conv2d_15/kernel:0', 'conv2d_15/bias:0', 'conv2d_transpose_2/kernel:0', 'conv2d_transpose_2/bias:0', 'conv2d_16/kernel:0', 'conv2d_16/bias:0', 'conv2d_17/kernel:0', 'conv2d_17/bias:0', 'conv2d_transpose_3/kernel:0', 'conv2d_transpose_3/bias:0', 'conv2d_18/kernel:0', 'conv2d_18/bias:0', 'conv2d_19/kernel:0', 'conv2d_19/bias:0', 'conv2d_transpose_4/kernel:0', 'conv2d_transpose_4/bias:0', 'conv2d_20/kernel:0', 'conv2d_20/bias:0', 'conv2d_21/kernel:0', 'conv2d_21/bias:0', 'conv2d_22/kernel:0', 'conv2d_22/bias:0'] when minimizing the loss.\n",
            "33/33 [==============================] - 7s 156ms/step - loss: 1.1263 - Dice1: 0.0021 - val_loss: 1.1134 - val_Dice1: 0.0000e+00\n",
            "Epoch 2/70\n",
            "33/33 [==============================] - 5s 142ms/step - loss: 1.1069 - Dice1: 0.0023 - val_loss: 1.0976 - val_Dice1: 0.0000e+00\n",
            "Epoch 3/70\n",
            "33/33 [==============================] - 5s 142ms/step - loss: 1.0916 - Dice1: 0.0027 - val_loss: 1.0848 - val_Dice1: 0.0000e+00\n",
            "Epoch 4/70\n",
            "33/33 [==============================] - 5s 142ms/step - loss: 1.0792 - Dice1: 0.0028 - val_loss: 1.0741 - val_Dice1: 0.0000e+00\n",
            "Epoch 5/70\n",
            "33/33 [==============================] - 5s 142ms/step - loss: 1.0687 - Dice1: 0.0030 - val_loss: 1.0649 - val_Dice1: 0.0000e+00\n",
            "Epoch 6/70\n",
            "33/33 [==============================] - 5s 142ms/step - loss: 1.0597 - Dice1: 0.0032 - val_loss: 1.0569 - val_Dice1: 0.0000e+00\n",
            "Epoch 7/70\n",
            "33/33 [==============================] - 5s 141ms/step - loss: 1.0516 - Dice1: 0.0035 - val_loss: 1.0499 - val_Dice1: 0.0000e+00\n",
            "Epoch 8/70\n",
            "33/33 [==============================] - 5s 142ms/step - loss: 1.0445 - Dice1: 0.0038 - val_loss: 1.0437 - val_Dice1: 0.0000e+00\n",
            "Epoch 9/70\n",
            "33/33 [==============================] - 5s 141ms/step - loss: 1.0385 - Dice1: 0.0038 - val_loss: 1.0383 - val_Dice1: 0.0000e+00\n",
            "Epoch 10/70\n",
            "33/33 [==============================] - 5s 142ms/step - loss: 1.0331 - Dice1: 0.0039 - val_loss: 1.0334 - val_Dice1: 0.0000e+00\n",
            "Epoch 11/70\n",
            "33/33 [==============================] - 5s 141ms/step - loss: 1.0283 - Dice1: 0.0040 - val_loss: 1.0292 - val_Dice1: 0.0000e+00\n",
            "Epoch 12/70\n",
            "33/33 [==============================] - 5s 141ms/step - loss: 1.0241 - Dice1: 0.0041 - val_loss: 1.0254 - val_Dice1: 0.0000e+00\n",
            "Epoch 13/70\n",
            "33/33 [==============================] - 5s 143ms/step - loss: 1.0205 - Dice1: 0.0040 - val_loss: 1.0221 - val_Dice1: 0.0000e+00\n",
            "Epoch 14/70\n",
            "33/33 [==============================] - 5s 141ms/step - loss: 1.0171 - Dice1: 0.0043 - val_loss: 1.0192 - val_Dice1: 0.0000e+00\n",
            "Epoch 15/70\n",
            "33/33 [==============================] - 5s 141ms/step - loss: 1.0144 - Dice1: 0.0041 - val_loss: 1.0166 - val_Dice1: 0.0000e+00\n",
            "Epoch 16/70\n",
            "33/33 [==============================] - 5s 142ms/step - loss: 1.0121 - Dice1: 0.0040 - val_loss: 1.0144 - val_Dice1: 0.0000e+00\n",
            "Epoch 17/70\n",
            "33/33 [==============================] - 5s 142ms/step - loss: 1.0099 - Dice1: 0.0040 - val_loss: 1.0124 - val_Dice1: 0.0000e+00\n",
            "Epoch 18/70\n",
            "33/33 [==============================] - 5s 142ms/step - loss: 1.0082 - Dice1: 0.0038 - val_loss: 1.0107 - val_Dice1: 0.0000e+00\n",
            "Epoch 19/70\n",
            "33/33 [==============================] - 5s 141ms/step - loss: 1.0065 - Dice1: 0.0038 - val_loss: 1.0092 - val_Dice1: 0.0000e+00\n",
            "Epoch 20/70\n",
            "33/33 [==============================] - 5s 142ms/step - loss: 1.0051 - Dice1: 0.0037 - val_loss: 1.0079 - val_Dice1: 0.0000e+00\n",
            "Epoch 21/70\n",
            "33/33 [==============================] - 5s 142ms/step - loss: 1.0042 - Dice1: 0.0034 - val_loss: 1.0067 - val_Dice1: 0.0000e+00\n",
            "Epoch 22/70\n",
            "33/33 [==============================] - 5s 142ms/step - loss: 1.0032 - Dice1: 0.0033 - val_loss: 1.0058 - val_Dice1: 0.0000e+00\n",
            "Epoch 23/70\n",
            "33/33 [==============================] - 5s 142ms/step - loss: 1.0024 - Dice1: 0.0031 - val_loss: 1.0049 - val_Dice1: 0.0000e+00\n",
            "Epoch 24/70\n",
            "33/33 [==============================] - 5s 142ms/step - loss: 1.0018 - Dice1: 0.0029 - val_loss: 1.0042 - val_Dice1: 0.0000e+00\n",
            "Epoch 25/70\n",
            "33/33 [==============================] - 5s 141ms/step - loss: 1.0013 - Dice1: 0.0028 - val_loss: 1.0035 - val_Dice1: 0.0000e+00\n",
            "Epoch 26/70\n",
            "33/33 [==============================] - 5s 141ms/step - loss: 1.0007 - Dice1: 0.0027 - val_loss: 1.0030 - val_Dice1: 0.0000e+00\n",
            "Epoch 27/70\n",
            "33/33 [==============================] - 5s 141ms/step - loss: 1.0004 - Dice1: 0.0024 - val_loss: 1.0025 - val_Dice1: 0.0000e+00\n",
            "Epoch 28/70\n",
            "33/33 [==============================] - 5s 142ms/step - loss: 1.0000 - Dice1: 0.0024 - val_loss: 1.0021 - val_Dice1: 0.0000e+00\n",
            "Epoch 29/70\n",
            "33/33 [==============================] - 5s 140ms/step - loss: 1.0000 - Dice1: 0.0021 - val_loss: 1.0018 - val_Dice1: 0.0000e+00\n",
            "Epoch 30/70\n",
            "33/33 [==============================] - 5s 142ms/step - loss: 0.9997 - Dice1: 0.0021 - val_loss: 1.0015 - val_Dice1: 0.0000e+00\n",
            "Epoch 31/70\n",
            "33/33 [==============================] - 5s 143ms/step - loss: 0.9996 - Dice1: 0.0018 - val_loss: 1.0013 - val_Dice1: 0.0000e+00\n",
            "Epoch 32/70\n",
            "21/33 [==================>...........] - ETA: 1s - loss: 0.9994 - Dice1: 0.0019"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-4f391d4bb044>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m                     \u001b[0mvalidation_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                     epochs=70)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77alWyEURNWv"
      },
      "source": [
        "loss = results.history['loss']\n",
        "val_loss = results.history['val_Dice']\n",
        "\n",
        "epochs = range(70)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, 'r', label='Training loss Cross entropy')\n",
        "plt.plot(epochs, val_loss, 'bo', label='Validation Dice Metric')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss Value')\n",
        "plt.ylim([0, 1])\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m759RpTUXvlA"
      },
      "source": [
        "def display_mask(i):\n",
        "    \"\"\"Quick utility to display a model's prediction.\"\"\"\n",
        "    mask = np.argmax(val_preds[i], axis=-1)\n",
        "    mask = np.expand_dims(mask, axis=-1)\n",
        "    img = PIL.ImageOps.autocontrast(keras.preprocessing.image.array_to_img(mask))\n",
        "    display(img)\n",
        "\n",
        "pr = model.predict(test_image[:7])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TEFnQPlXvnp"
      },
      "source": [
        "mask1 = np.argmax(pr[2], axis=-1)\n",
        "plt.imshow(mask1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NghUE-MYeDwM"
      },
      "source": [
        "plt.imshow(test_seg_f[2])\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}